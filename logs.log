2023-08-16 01:01:33,160:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-16 01:01:33,160:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-16 01:01:33,160:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-16 01:01:33,160:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-16 01:16:44,526:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-16 01:16:44,527:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-16 01:16:44,527:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-16 01:16:44,527:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-16 01:17:34,965:INFO:PyCaret ClassificationExperiment
2023-08-16 01:17:34,966:INFO:Logging name: clf-default-name
2023-08-16 01:17:34,966:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-16 01:17:34,966:INFO:version 3.0.4
2023-08-16 01:17:34,966:INFO:Initializing setup()
2023-08-16 01:17:34,966:INFO:self.USI: 853a
2023-08-16 01:17:34,966:INFO:self._variable_keys: {'fix_imbalance', 'is_multiclass', '_available_plots', 'seed', 'y_train', 'n_jobs_param', 'gpu_param', 'exp_id', 'X_test', 'fold_groups_param', 'y_test', 'log_plots_param', 'gpu_n_jobs_param', 'logging_param', 'memory', 'y', 'fold_shuffle_param', 'fold_generator', '_ml_usecase', 'exp_name_log', 'X_train', 'X', 'pipeline', 'target_param', 'USI', 'data', 'idx', 'html_param'}
2023-08-16 01:17:34,966:INFO:Checking environment
2023-08-16 01:17:34,966:INFO:python_version: 3.9.13
2023-08-16 01:17:34,966:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-08-16 01:17:34,966:INFO:machine: AMD64
2023-08-16 01:17:34,966:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-16 01:17:34,966:INFO:Memory: svmem(total=16905969664, available=3126448128, percent=81.5, used=13779521536, free=3126448128)
2023-08-16 01:17:34,966:INFO:Physical Core: 8
2023-08-16 01:17:34,966:INFO:Logical Core: 16
2023-08-16 01:17:34,966:INFO:Checking libraries
2023-08-16 01:17:34,966:INFO:System:
2023-08-16 01:17:34,966:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-08-16 01:17:34,966:INFO:executable: c:\Users\lmacciomaretto\anaconda3\python.exe
2023-08-16 01:17:34,966:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-16 01:17:34,966:INFO:PyCaret required dependencies:
2023-08-16 01:17:35,143:INFO:                 pip: 22.2.2
2023-08-16 01:17:35,143:INFO:          setuptools: 63.4.1
2023-08-16 01:17:35,143:INFO:             pycaret: 3.0.4
2023-08-16 01:17:35,143:INFO:             IPython: 7.31.1
2023-08-16 01:17:35,143:INFO:          ipywidgets: 7.6.5
2023-08-16 01:17:35,143:INFO:                tqdm: 4.64.1
2023-08-16 01:17:35,143:INFO:               numpy: 1.21.5
2023-08-16 01:17:35,143:INFO:              pandas: 1.4.4
2023-08-16 01:17:35,143:INFO:              jinja2: 2.11.3
2023-08-16 01:17:35,143:INFO:               scipy: 1.9.1
2023-08-16 01:17:35,143:INFO:              joblib: 1.3.2
2023-08-16 01:17:35,143:INFO:             sklearn: 1.0.2
2023-08-16 01:17:35,143:INFO:                pyod: 1.1.0
2023-08-16 01:17:35,143:INFO:            imblearn: 0.11.0
2023-08-16 01:17:35,143:INFO:   category_encoders: 2.6.2
2023-08-16 01:17:35,143:INFO:            lightgbm: 4.0.0
2023-08-16 01:17:35,143:INFO:               numba: 0.55.1
2023-08-16 01:17:35,143:INFO:            requests: 2.28.1
2023-08-16 01:17:35,143:INFO:          matplotlib: 3.5.2
2023-08-16 01:17:35,143:INFO:          scikitplot: 0.3.7
2023-08-16 01:17:35,143:INFO:         yellowbrick: 1.5
2023-08-16 01:17:35,143:INFO:              plotly: 5.9.0
2023-08-16 01:17:35,143:INFO:    plotly-resampler: Not installed
2023-08-16 01:17:35,144:INFO:             kaleido: 0.2.1
2023-08-16 01:17:35,144:INFO:           schemdraw: 0.15
2023-08-16 01:17:35,144:INFO:         statsmodels: 0.13.2
2023-08-16 01:17:35,144:INFO:              sktime: 0.21.0
2023-08-16 01:17:35,144:INFO:               tbats: 1.1.3
2023-08-16 01:17:35,144:INFO:            pmdarima: 2.0.3
2023-08-16 01:17:35,144:INFO:              psutil: 5.9.0
2023-08-16 01:17:35,144:INFO:          markupsafe: 2.0.1
2023-08-16 01:17:35,144:INFO:             pickle5: Not installed
2023-08-16 01:17:35,144:INFO:         cloudpickle: 2.0.0
2023-08-16 01:17:35,144:INFO:         deprecation: 2.1.0
2023-08-16 01:17:35,144:INFO:              xxhash: 3.3.0
2023-08-16 01:17:35,144:INFO:           wurlitzer: Not installed
2023-08-16 01:17:35,144:INFO:PyCaret optional dependencies:
2023-08-16 01:17:35,152:INFO:                shap: Not installed
2023-08-16 01:17:35,152:INFO:           interpret: Not installed
2023-08-16 01:17:35,153:INFO:                umap: Not installed
2023-08-16 01:17:35,153:INFO:    pandas_profiling: Not installed
2023-08-16 01:17:35,153:INFO:  explainerdashboard: Not installed
2023-08-16 01:17:35,153:INFO:             autoviz: Not installed
2023-08-16 01:17:35,153:INFO:           fairlearn: Not installed
2023-08-16 01:17:35,153:INFO:          deepchecks: Not installed
2023-08-16 01:17:35,153:INFO:             xgboost: Not installed
2023-08-16 01:17:35,153:INFO:            catboost: Not installed
2023-08-16 01:17:35,153:INFO:              kmodes: Not installed
2023-08-16 01:17:35,153:INFO:             mlxtend: Not installed
2023-08-16 01:17:35,153:INFO:       statsforecast: Not installed
2023-08-16 01:17:35,153:INFO:        tune_sklearn: Not installed
2023-08-16 01:17:35,153:INFO:                 ray: Not installed
2023-08-16 01:17:35,153:INFO:            hyperopt: Not installed
2023-08-16 01:17:35,153:INFO:              optuna: Not installed
2023-08-16 01:17:35,153:INFO:               skopt: Not installed
2023-08-16 01:17:35,153:INFO:              mlflow: Not installed
2023-08-16 01:17:35,153:INFO:              gradio: Not installed
2023-08-16 01:17:35,153:INFO:             fastapi: Not installed
2023-08-16 01:17:35,153:INFO:             uvicorn: Not installed
2023-08-16 01:17:35,153:INFO:              m2cgen: Not installed
2023-08-16 01:17:35,153:INFO:           evidently: Not installed
2023-08-16 01:17:35,153:INFO:               fugue: Not installed
2023-08-16 01:17:35,153:INFO:           streamlit: Not installed
2023-08-16 01:17:35,153:INFO:             prophet: Not installed
2023-08-16 01:17:35,153:INFO:None
2023-08-16 01:17:35,153:INFO:Set up data.
2023-08-16 01:17:35,169:INFO:Set up train/test split.
2023-08-16 01:17:35,185:INFO:Set up index.
2023-08-16 01:17:35,186:INFO:Set up folding strategy.
2023-08-16 01:17:35,186:INFO:Assigning column types.
2023-08-16 01:17:35,191:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-16 01:17:35,224:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-16 01:17:35,226:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:17:35,256:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:17:35,256:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:17:35,288:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-16 01:17:35,288:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:17:35,308:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:17:35,308:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:17:35,309:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-16 01:17:35,341:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:17:35,362:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:17:35,362:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:17:35,396:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:17:35,415:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:17:35,415:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:17:35,415:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-16 01:17:35,467:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:17:35,467:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:17:35,519:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:17:35,519:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:17:35,525:INFO:Preparing preprocessing pipeline...
2023-08-16 01:17:35,528:INFO:Set up simple imputation.
2023-08-16 01:17:35,558:INFO:Finished creating preprocessing pipeline.
2023-08-16 01:17:35,563:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\LMACCI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['CATAG3', 'HEALTH2', 'ANYHLTI2',
                                             'INCOME', 'POVERTY3', 'TOBFLAG',
                                             'MRJFLAG', 'PYUD5MRJ', 'MJYRTOT',
                                             'ALCFLAG', 'COCFLAG', 'CRKFLAG',
                                             'HERFLAG', 'LSDFLAG',
                                             'METHAMFLAG'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose=0))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose=0)))],
         verbose=False)
2023-08-16 01:17:35,563:INFO:Creating final display dataframe.
2023-08-16 01:17:35,633:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          ADSMMDEA
2                   Target type            Binary
3           Original data shape       (33177, 16)
4        Transformed data shape       (33177, 16)
5   Transformed train set shape       (23223, 16)
6    Transformed test set shape        (9954, 16)
7              Numeric features                15
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              853a
2023-08-16 01:17:35,698:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:17:35,698:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:17:35,755:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:17:35,755:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:17:35,756:INFO:setup() successfully completed in 0.79s...............
2023-08-16 01:17:54,968:INFO:PyCaret ClassificationExperiment
2023-08-16 01:17:54,968:INFO:Logging name: clf-default-name
2023-08-16 01:17:54,968:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-16 01:17:54,968:INFO:version 3.0.4
2023-08-16 01:17:54,968:INFO:Initializing setup()
2023-08-16 01:17:54,968:INFO:self.USI: dd2a
2023-08-16 01:17:54,968:INFO:self._variable_keys: {'fix_imbalance', 'is_multiclass', '_available_plots', 'seed', 'y_train', 'n_jobs_param', 'gpu_param', 'exp_id', 'X_test', 'fold_groups_param', 'y_test', 'log_plots_param', 'gpu_n_jobs_param', 'logging_param', 'memory', 'y', 'fold_shuffle_param', 'fold_generator', '_ml_usecase', 'exp_name_log', 'X_train', 'X', 'pipeline', 'target_param', 'USI', 'data', 'idx', 'html_param'}
2023-08-16 01:17:54,968:INFO:Checking environment
2023-08-16 01:17:54,968:INFO:python_version: 3.9.13
2023-08-16 01:17:54,968:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-08-16 01:17:54,968:INFO:machine: AMD64
2023-08-16 01:17:54,968:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-16 01:17:54,968:INFO:Memory: svmem(total=16905969664, available=3139301376, percent=81.4, used=13766668288, free=3139301376)
2023-08-16 01:17:54,968:INFO:Physical Core: 8
2023-08-16 01:17:54,968:INFO:Logical Core: 16
2023-08-16 01:17:54,969:INFO:Checking libraries
2023-08-16 01:17:54,969:INFO:System:
2023-08-16 01:17:54,969:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-08-16 01:17:54,969:INFO:executable: c:\Users\lmacciomaretto\anaconda3\python.exe
2023-08-16 01:17:54,969:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-16 01:17:54,969:INFO:PyCaret required dependencies:
2023-08-16 01:17:54,969:INFO:                 pip: 22.2.2
2023-08-16 01:17:54,969:INFO:          setuptools: 63.4.1
2023-08-16 01:17:54,969:INFO:             pycaret: 3.0.4
2023-08-16 01:17:54,969:INFO:             IPython: 7.31.1
2023-08-16 01:17:54,969:INFO:          ipywidgets: 7.6.5
2023-08-16 01:17:54,969:INFO:                tqdm: 4.64.1
2023-08-16 01:17:54,969:INFO:               numpy: 1.21.5
2023-08-16 01:17:54,969:INFO:              pandas: 1.4.4
2023-08-16 01:17:54,969:INFO:              jinja2: 2.11.3
2023-08-16 01:17:54,969:INFO:               scipy: 1.9.1
2023-08-16 01:17:54,969:INFO:              joblib: 1.3.2
2023-08-16 01:17:54,969:INFO:             sklearn: 1.0.2
2023-08-16 01:17:54,969:INFO:                pyod: 1.1.0
2023-08-16 01:17:54,969:INFO:            imblearn: 0.11.0
2023-08-16 01:17:54,969:INFO:   category_encoders: 2.6.2
2023-08-16 01:17:54,969:INFO:            lightgbm: 4.0.0
2023-08-16 01:17:54,969:INFO:               numba: 0.55.1
2023-08-16 01:17:54,969:INFO:            requests: 2.28.1
2023-08-16 01:17:54,969:INFO:          matplotlib: 3.5.2
2023-08-16 01:17:54,969:INFO:          scikitplot: 0.3.7
2023-08-16 01:17:54,969:INFO:         yellowbrick: 1.5
2023-08-16 01:17:54,969:INFO:              plotly: 5.9.0
2023-08-16 01:17:54,969:INFO:    plotly-resampler: Not installed
2023-08-16 01:17:54,969:INFO:             kaleido: 0.2.1
2023-08-16 01:17:54,969:INFO:           schemdraw: 0.15
2023-08-16 01:17:54,969:INFO:         statsmodels: 0.13.2
2023-08-16 01:17:54,969:INFO:              sktime: 0.21.0
2023-08-16 01:17:54,969:INFO:               tbats: 1.1.3
2023-08-16 01:17:54,969:INFO:            pmdarima: 2.0.3
2023-08-16 01:17:54,969:INFO:              psutil: 5.9.0
2023-08-16 01:17:54,969:INFO:          markupsafe: 2.0.1
2023-08-16 01:17:54,970:INFO:             pickle5: Not installed
2023-08-16 01:17:54,970:INFO:         cloudpickle: 2.0.0
2023-08-16 01:17:54,970:INFO:         deprecation: 2.1.0
2023-08-16 01:17:54,970:INFO:              xxhash: 3.3.0
2023-08-16 01:17:54,970:INFO:           wurlitzer: Not installed
2023-08-16 01:17:54,970:INFO:PyCaret optional dependencies:
2023-08-16 01:17:54,970:INFO:                shap: Not installed
2023-08-16 01:17:54,970:INFO:           interpret: Not installed
2023-08-16 01:17:54,970:INFO:                umap: Not installed
2023-08-16 01:17:54,970:INFO:    pandas_profiling: Not installed
2023-08-16 01:17:54,970:INFO:  explainerdashboard: Not installed
2023-08-16 01:17:54,970:INFO:             autoviz: Not installed
2023-08-16 01:17:54,970:INFO:           fairlearn: Not installed
2023-08-16 01:17:54,970:INFO:          deepchecks: Not installed
2023-08-16 01:17:54,970:INFO:             xgboost: Not installed
2023-08-16 01:17:54,970:INFO:            catboost: Not installed
2023-08-16 01:17:54,970:INFO:              kmodes: Not installed
2023-08-16 01:17:54,970:INFO:             mlxtend: Not installed
2023-08-16 01:17:54,970:INFO:       statsforecast: Not installed
2023-08-16 01:17:54,970:INFO:        tune_sklearn: Not installed
2023-08-16 01:17:54,970:INFO:                 ray: Not installed
2023-08-16 01:17:54,970:INFO:            hyperopt: Not installed
2023-08-16 01:17:54,970:INFO:              optuna: Not installed
2023-08-16 01:17:54,970:INFO:               skopt: Not installed
2023-08-16 01:17:54,970:INFO:              mlflow: Not installed
2023-08-16 01:17:54,970:INFO:              gradio: Not installed
2023-08-16 01:17:54,970:INFO:             fastapi: Not installed
2023-08-16 01:17:54,970:INFO:             uvicorn: Not installed
2023-08-16 01:17:54,970:INFO:              m2cgen: Not installed
2023-08-16 01:17:54,970:INFO:           evidently: Not installed
2023-08-16 01:17:54,970:INFO:               fugue: Not installed
2023-08-16 01:17:54,970:INFO:           streamlit: Not installed
2023-08-16 01:17:54,970:INFO:             prophet: Not installed
2023-08-16 01:17:54,970:INFO:None
2023-08-16 01:17:54,970:INFO:Set up data.
2023-08-16 01:17:54,986:INFO:Set up train/test split.
2023-08-16 01:17:54,998:INFO:Set up index.
2023-08-16 01:17:54,999:INFO:Set up folding strategy.
2023-08-16 01:17:54,999:INFO:Assigning column types.
2023-08-16 01:17:55,009:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-16 01:17:55,062:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-16 01:17:55,062:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:17:55,085:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:17:55,085:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:17:55,120:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-16 01:17:55,121:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:17:55,143:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:17:55,143:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:17:55,143:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-16 01:17:55,179:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:17:55,201:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:17:55,202:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:17:55,239:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:17:55,261:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:17:55,261:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:17:55,261:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-16 01:17:55,319:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:17:55,320:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:17:55,379:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:17:55,379:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:17:55,380:INFO:Preparing preprocessing pipeline...
2023-08-16 01:17:55,381:INFO:Set up simple imputation.
2023-08-16 01:17:55,406:INFO:Finished creating preprocessing pipeline.
2023-08-16 01:17:55,408:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\LMACCI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['CATAG3', 'HEALTH2', 'ANYHLTI2',
                                             'INCOME', 'POVERTY3', 'TOBFLAG',
                                             'MRJFLAG', 'PYUD5MRJ', 'MJYRTOT',
                                             'ALCFLAG', 'COCFLAG', 'CRKFLAG',
                                             'HERFLAG', 'LSDFLAG',
                                             'METHAMFLAG'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose=0))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose=0)))],
         verbose=False)
2023-08-16 01:17:55,408:INFO:Creating final display dataframe.
2023-08-16 01:17:55,486:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          ADSMMDEA
2                   Target type            Binary
3           Original data shape       (33177, 16)
4        Transformed data shape       (33177, 16)
5   Transformed train set shape       (23223, 16)
6    Transformed test set shape        (9954, 16)
7              Numeric features                15
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              dd2a
2023-08-16 01:17:55,552:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:17:55,552:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:17:55,610:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:17:55,610:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:17:55,610:INFO:setup() successfully completed in 0.64s...............
2023-08-16 01:18:03,797:INFO:Initializing compare_models()
2023-08-16 01:18:03,798:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B23F1760>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000195B23F1760>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-16 01:18:03,798:INFO:Checking exceptions
2023-08-16 01:18:03,815:INFO:Preparing display monitor
2023-08-16 01:18:03,867:INFO:Initializing Logistic Regression
2023-08-16 01:18:03,868:INFO:Total runtime is 1.6899903615315757e-05 minutes
2023-08-16 01:18:03,870:INFO:SubProcess create_model() called ==================================
2023-08-16 01:18:03,870:INFO:Initializing create_model()
2023-08-16 01:18:03,870:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B23F1760>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000195B1B25B50>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:18:03,870:INFO:Checking exceptions
2023-08-16 01:18:03,870:INFO:Importing libraries
2023-08-16 01:18:03,870:INFO:Copying training dataset
2023-08-16 01:18:03,880:INFO:Defining folds
2023-08-16 01:18:03,880:INFO:Declaring metric variables
2023-08-16 01:18:03,883:INFO:Importing untrained model
2023-08-16 01:18:03,885:INFO:Logistic Regression Imported successfully
2023-08-16 01:18:03,890:INFO:Starting cross validation
2023-08-16 01:18:03,891:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:18:20,864:INFO:Calculating mean and std
2023-08-16 01:18:20,868:INFO:Creating metrics dataframe
2023-08-16 01:18:20,878:INFO:Uploading results into container
2023-08-16 01:18:20,879:INFO:Uploading model into container now
2023-08-16 01:18:20,880:INFO:_master_model_container: 1
2023-08-16 01:18:20,880:INFO:_display_container: 2
2023-08-16 01:18:20,880:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-16 01:18:20,880:INFO:create_model() successfully completed......................................
2023-08-16 01:18:20,966:INFO:SubProcess create_model() end ==================================
2023-08-16 01:18:20,966:INFO:Creating metrics dataframe
2023-08-16 01:18:20,973:INFO:Initializing K Neighbors Classifier
2023-08-16 01:18:20,974:INFO:Total runtime is 0.285122803846995 minutes
2023-08-16 01:18:20,976:INFO:SubProcess create_model() called ==================================
2023-08-16 01:18:20,976:INFO:Initializing create_model()
2023-08-16 01:18:20,976:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B23F1760>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000195B1B25B50>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:18:20,976:INFO:Checking exceptions
2023-08-16 01:18:20,976:INFO:Importing libraries
2023-08-16 01:18:20,976:INFO:Copying training dataset
2023-08-16 01:18:20,986:INFO:Defining folds
2023-08-16 01:18:20,986:INFO:Declaring metric variables
2023-08-16 01:18:20,989:INFO:Importing untrained model
2023-08-16 01:18:20,991:INFO:K Neighbors Classifier Imported successfully
2023-08-16 01:18:20,996:INFO:Starting cross validation
2023-08-16 01:18:20,997:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:18:21,284:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:18:21,322:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:18:21,324:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:18:21,339:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:18:27,874:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:18:27,887:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:18:27,887:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:18:27,887:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:18:27,888:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:18:27,901:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:18:28,168:INFO:Calculating mean and std
2023-08-16 01:18:28,170:INFO:Creating metrics dataframe
2023-08-16 01:18:28,179:INFO:Uploading results into container
2023-08-16 01:18:28,179:INFO:Uploading model into container now
2023-08-16 01:18:28,180:INFO:_master_model_container: 2
2023-08-16 01:18:28,180:INFO:_display_container: 2
2023-08-16 01:18:28,180:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-16 01:18:28,180:INFO:create_model() successfully completed......................................
2023-08-16 01:18:28,254:INFO:SubProcess create_model() end ==================================
2023-08-16 01:18:28,254:INFO:Creating metrics dataframe
2023-08-16 01:18:28,260:INFO:Initializing Naive Bayes
2023-08-16 01:18:28,260:INFO:Total runtime is 0.40656175613403317 minutes
2023-08-16 01:18:28,263:INFO:SubProcess create_model() called ==================================
2023-08-16 01:18:28,263:INFO:Initializing create_model()
2023-08-16 01:18:28,263:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B23F1760>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000195B1B25B50>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:18:28,263:INFO:Checking exceptions
2023-08-16 01:18:28,263:INFO:Importing libraries
2023-08-16 01:18:28,263:INFO:Copying training dataset
2023-08-16 01:18:28,273:INFO:Defining folds
2023-08-16 01:18:28,273:INFO:Declaring metric variables
2023-08-16 01:18:28,276:INFO:Importing untrained model
2023-08-16 01:18:28,279:INFO:Naive Bayes Imported successfully
2023-08-16 01:18:28,284:INFO:Starting cross validation
2023-08-16 01:18:28,285:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:18:28,470:INFO:Calculating mean and std
2023-08-16 01:18:28,471:INFO:Creating metrics dataframe
2023-08-16 01:18:28,477:INFO:Uploading results into container
2023-08-16 01:18:28,478:INFO:Uploading model into container now
2023-08-16 01:18:28,478:INFO:_master_model_container: 3
2023-08-16 01:18:28,478:INFO:_display_container: 2
2023-08-16 01:18:28,478:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-16 01:18:28,478:INFO:create_model() successfully completed......................................
2023-08-16 01:18:28,551:INFO:SubProcess create_model() end ==================================
2023-08-16 01:18:28,551:INFO:Creating metrics dataframe
2023-08-16 01:18:28,558:INFO:Initializing Decision Tree Classifier
2023-08-16 01:18:28,558:INFO:Total runtime is 0.4115256388982137 minutes
2023-08-16 01:18:28,561:INFO:SubProcess create_model() called ==================================
2023-08-16 01:18:28,561:INFO:Initializing create_model()
2023-08-16 01:18:28,561:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B23F1760>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000195B1B25B50>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:18:28,561:INFO:Checking exceptions
2023-08-16 01:18:28,561:INFO:Importing libraries
2023-08-16 01:18:28,561:INFO:Copying training dataset
2023-08-16 01:18:28,570:INFO:Defining folds
2023-08-16 01:18:28,570:INFO:Declaring metric variables
2023-08-16 01:18:28,573:INFO:Importing untrained model
2023-08-16 01:18:28,575:INFO:Decision Tree Classifier Imported successfully
2023-08-16 01:18:28,581:INFO:Starting cross validation
2023-08-16 01:18:28,582:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:18:28,768:INFO:Calculating mean and std
2023-08-16 01:18:28,768:INFO:Creating metrics dataframe
2023-08-16 01:18:28,775:INFO:Uploading results into container
2023-08-16 01:18:28,776:INFO:Uploading model into container now
2023-08-16 01:18:28,776:INFO:_master_model_container: 4
2023-08-16 01:18:28,777:INFO:_display_container: 2
2023-08-16 01:18:28,777:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-08-16 01:18:28,777:INFO:create_model() successfully completed......................................
2023-08-16 01:18:28,846:INFO:SubProcess create_model() end ==================================
2023-08-16 01:18:28,846:INFO:Creating metrics dataframe
2023-08-16 01:18:28,854:INFO:Initializing SVM - Linear Kernel
2023-08-16 01:18:28,854:INFO:Total runtime is 0.4164636452992757 minutes
2023-08-16 01:18:28,857:INFO:SubProcess create_model() called ==================================
2023-08-16 01:18:28,858:INFO:Initializing create_model()
2023-08-16 01:18:28,858:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B23F1760>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000195B1B25B50>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:18:28,858:INFO:Checking exceptions
2023-08-16 01:18:28,858:INFO:Importing libraries
2023-08-16 01:18:28,858:INFO:Copying training dataset
2023-08-16 01:18:28,866:INFO:Defining folds
2023-08-16 01:18:28,866:INFO:Declaring metric variables
2023-08-16 01:18:28,869:INFO:Importing untrained model
2023-08-16 01:18:28,872:INFO:SVM - Linear Kernel Imported successfully
2023-08-16 01:18:28,877:INFO:Starting cross validation
2023-08-16 01:18:28,877:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:18:29,271:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:18:29,271:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:18:29,271:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:18:29,275:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:18:29,277:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:18:29,278:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:18:29,302:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:18:29,326:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:18:29,354:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:18:29,371:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:18:29,386:INFO:Calculating mean and std
2023-08-16 01:18:29,387:INFO:Creating metrics dataframe
2023-08-16 01:18:29,396:INFO:Uploading results into container
2023-08-16 01:18:29,397:INFO:Uploading model into container now
2023-08-16 01:18:29,397:INFO:_master_model_container: 5
2023-08-16 01:18:29,397:INFO:_display_container: 2
2023-08-16 01:18:29,397:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-16 01:18:29,397:INFO:create_model() successfully completed......................................
2023-08-16 01:18:29,464:INFO:SubProcess create_model() end ==================================
2023-08-16 01:18:29,464:INFO:Creating metrics dataframe
2023-08-16 01:18:29,471:INFO:Initializing Ridge Classifier
2023-08-16 01:18:29,471:INFO:Total runtime is 0.42674320538838706 minutes
2023-08-16 01:18:29,474:INFO:SubProcess create_model() called ==================================
2023-08-16 01:18:29,474:INFO:Initializing create_model()
2023-08-16 01:18:29,474:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B23F1760>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000195B1B25B50>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:18:29,474:INFO:Checking exceptions
2023-08-16 01:18:29,474:INFO:Importing libraries
2023-08-16 01:18:29,474:INFO:Copying training dataset
2023-08-16 01:18:29,483:INFO:Defining folds
2023-08-16 01:18:29,483:INFO:Declaring metric variables
2023-08-16 01:18:29,486:INFO:Importing untrained model
2023-08-16 01:18:29,489:INFO:Ridge Classifier Imported successfully
2023-08-16 01:18:29,494:INFO:Starting cross validation
2023-08-16 01:18:29,495:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:18:29,961:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:18:29,964:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:18:29,964:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:18:29,964:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:18:29,969:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:18:29,970:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:18:29,970:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:18:29,971:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:18:29,972:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:18:29,973:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:18:30,077:INFO:Calculating mean and std
2023-08-16 01:18:30,078:INFO:Creating metrics dataframe
2023-08-16 01:18:30,091:INFO:Uploading results into container
2023-08-16 01:18:30,092:INFO:Uploading model into container now
2023-08-16 01:18:30,092:INFO:_master_model_container: 6
2023-08-16 01:18:30,092:INFO:_display_container: 2
2023-08-16 01:18:30,093:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=123, solver='auto', tol=0.001)
2023-08-16 01:18:30,093:INFO:create_model() successfully completed......................................
2023-08-16 01:18:30,173:INFO:SubProcess create_model() end ==================================
2023-08-16 01:18:30,173:INFO:Creating metrics dataframe
2023-08-16 01:18:30,181:INFO:Initializing Random Forest Classifier
2023-08-16 01:18:30,181:INFO:Total runtime is 0.4385767420132955 minutes
2023-08-16 01:18:30,183:INFO:SubProcess create_model() called ==================================
2023-08-16 01:18:30,183:INFO:Initializing create_model()
2023-08-16 01:18:30,183:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B23F1760>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000195B1B25B50>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:18:30,183:INFO:Checking exceptions
2023-08-16 01:18:30,183:INFO:Importing libraries
2023-08-16 01:18:30,183:INFO:Copying training dataset
2023-08-16 01:18:30,192:INFO:Defining folds
2023-08-16 01:18:30,192:INFO:Declaring metric variables
2023-08-16 01:18:30,195:INFO:Importing untrained model
2023-08-16 01:18:30,197:INFO:Random Forest Classifier Imported successfully
2023-08-16 01:18:30,203:INFO:Starting cross validation
2023-08-16 01:18:30,203:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:18:34,618:INFO:Calculating mean and std
2023-08-16 01:18:34,618:INFO:Creating metrics dataframe
2023-08-16 01:18:34,637:INFO:Uploading results into container
2023-08-16 01:18:34,638:INFO:Uploading model into container now
2023-08-16 01:18:34,639:INFO:_master_model_container: 7
2023-08-16 01:18:34,639:INFO:_display_container: 2
2023-08-16 01:18:34,639:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-08-16 01:18:34,639:INFO:create_model() successfully completed......................................
2023-08-16 01:18:34,713:INFO:SubProcess create_model() end ==================================
2023-08-16 01:18:34,713:INFO:Creating metrics dataframe
2023-08-16 01:18:34,721:INFO:Initializing Quadratic Discriminant Analysis
2023-08-16 01:18:34,721:INFO:Total runtime is 0.5142443815867106 minutes
2023-08-16 01:18:34,723:INFO:SubProcess create_model() called ==================================
2023-08-16 01:18:34,724:INFO:Initializing create_model()
2023-08-16 01:18:34,724:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B23F1760>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000195B1B25B50>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:18:34,724:INFO:Checking exceptions
2023-08-16 01:18:34,724:INFO:Importing libraries
2023-08-16 01:18:34,724:INFO:Copying training dataset
2023-08-16 01:18:34,733:INFO:Defining folds
2023-08-16 01:18:34,733:INFO:Declaring metric variables
2023-08-16 01:18:34,735:INFO:Importing untrained model
2023-08-16 01:18:34,737:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-16 01:18:34,742:INFO:Starting cross validation
2023-08-16 01:18:34,743:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:18:35,029:INFO:Calculating mean and std
2023-08-16 01:18:35,030:INFO:Creating metrics dataframe
2023-08-16 01:18:35,044:INFO:Uploading results into container
2023-08-16 01:18:35,045:INFO:Uploading model into container now
2023-08-16 01:18:35,045:INFO:_master_model_container: 8
2023-08-16 01:18:35,046:INFO:_display_container: 2
2023-08-16 01:18:35,046:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-16 01:18:35,046:INFO:create_model() successfully completed......................................
2023-08-16 01:18:35,117:INFO:SubProcess create_model() end ==================================
2023-08-16 01:18:35,117:INFO:Creating metrics dataframe
2023-08-16 01:18:35,125:INFO:Initializing Ada Boost Classifier
2023-08-16 01:18:35,125:INFO:Total runtime is 0.5209689776102702 minutes
2023-08-16 01:18:35,127:INFO:SubProcess create_model() called ==================================
2023-08-16 01:18:35,128:INFO:Initializing create_model()
2023-08-16 01:18:35,128:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B23F1760>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000195B1B25B50>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:18:35,128:INFO:Checking exceptions
2023-08-16 01:18:35,128:INFO:Importing libraries
2023-08-16 01:18:35,128:INFO:Copying training dataset
2023-08-16 01:18:35,137:INFO:Defining folds
2023-08-16 01:18:35,138:INFO:Declaring metric variables
2023-08-16 01:18:35,140:INFO:Importing untrained model
2023-08-16 01:18:35,143:INFO:Ada Boost Classifier Imported successfully
2023-08-16 01:18:35,147:INFO:Starting cross validation
2023-08-16 01:18:35,148:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:18:36,250:INFO:Calculating mean and std
2023-08-16 01:18:36,251:INFO:Creating metrics dataframe
2023-08-16 01:18:36,274:INFO:Uploading results into container
2023-08-16 01:18:36,274:INFO:Uploading model into container now
2023-08-16 01:18:36,275:INFO:_master_model_container: 9
2023-08-16 01:18:36,275:INFO:_display_container: 2
2023-08-16 01:18:36,275:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2023-08-16 01:18:36,275:INFO:create_model() successfully completed......................................
2023-08-16 01:18:36,345:INFO:SubProcess create_model() end ==================================
2023-08-16 01:18:36,345:INFO:Creating metrics dataframe
2023-08-16 01:18:36,353:INFO:Initializing Gradient Boosting Classifier
2023-08-16 01:18:36,353:INFO:Total runtime is 0.5414381146430969 minutes
2023-08-16 01:18:36,356:INFO:SubProcess create_model() called ==================================
2023-08-16 01:18:36,356:INFO:Initializing create_model()
2023-08-16 01:18:36,356:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B23F1760>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000195B1B25B50>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:18:36,356:INFO:Checking exceptions
2023-08-16 01:18:36,356:INFO:Importing libraries
2023-08-16 01:18:36,356:INFO:Copying training dataset
2023-08-16 01:18:36,366:INFO:Defining folds
2023-08-16 01:18:36,366:INFO:Declaring metric variables
2023-08-16 01:18:36,368:INFO:Importing untrained model
2023-08-16 01:18:36,371:INFO:Gradient Boosting Classifier Imported successfully
2023-08-16 01:18:36,375:INFO:Starting cross validation
2023-08-16 01:18:36,376:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:18:38,069:INFO:Calculating mean and std
2023-08-16 01:18:38,070:INFO:Creating metrics dataframe
2023-08-16 01:18:38,099:INFO:Uploading results into container
2023-08-16 01:18:38,100:INFO:Uploading model into container now
2023-08-16 01:18:38,100:INFO:_master_model_container: 10
2023-08-16 01:18:38,100:INFO:_display_container: 2
2023-08-16 01:18:38,100:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-16 01:18:38,100:INFO:create_model() successfully completed......................................
2023-08-16 01:18:38,167:INFO:SubProcess create_model() end ==================================
2023-08-16 01:18:38,167:INFO:Creating metrics dataframe
2023-08-16 01:18:38,175:INFO:Initializing Linear Discriminant Analysis
2023-08-16 01:18:38,175:INFO:Total runtime is 0.5718029061953226 minutes
2023-08-16 01:18:38,179:INFO:SubProcess create_model() called ==================================
2023-08-16 01:18:38,179:INFO:Initializing create_model()
2023-08-16 01:18:38,179:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B23F1760>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000195B1B25B50>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:18:38,179:INFO:Checking exceptions
2023-08-16 01:18:38,180:INFO:Importing libraries
2023-08-16 01:18:38,180:INFO:Copying training dataset
2023-08-16 01:18:38,198:INFO:Defining folds
2023-08-16 01:18:38,198:INFO:Declaring metric variables
2023-08-16 01:18:38,204:INFO:Importing untrained model
2023-08-16 01:18:38,208:INFO:Linear Discriminant Analysis Imported successfully
2023-08-16 01:18:38,214:INFO:Starting cross validation
2023-08-16 01:18:38,214:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:18:38,532:INFO:Calculating mean and std
2023-08-16 01:18:38,533:INFO:Creating metrics dataframe
2023-08-16 01:18:38,559:INFO:Uploading results into container
2023-08-16 01:18:38,560:INFO:Uploading model into container now
2023-08-16 01:18:38,560:INFO:_master_model_container: 11
2023-08-16 01:18:38,561:INFO:_display_container: 2
2023-08-16 01:18:38,561:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-16 01:18:38,561:INFO:create_model() successfully completed......................................
2023-08-16 01:18:38,628:INFO:SubProcess create_model() end ==================================
2023-08-16 01:18:38,628:INFO:Creating metrics dataframe
2023-08-16 01:18:38,637:INFO:Initializing Extra Trees Classifier
2023-08-16 01:18:38,637:INFO:Total runtime is 0.5794991652170817 minutes
2023-08-16 01:18:38,639:INFO:SubProcess create_model() called ==================================
2023-08-16 01:18:38,640:INFO:Initializing create_model()
2023-08-16 01:18:38,640:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B23F1760>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000195B1B25B50>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:18:38,640:INFO:Checking exceptions
2023-08-16 01:18:38,640:INFO:Importing libraries
2023-08-16 01:18:38,640:INFO:Copying training dataset
2023-08-16 01:18:38,650:INFO:Defining folds
2023-08-16 01:18:38,650:INFO:Declaring metric variables
2023-08-16 01:18:38,653:INFO:Importing untrained model
2023-08-16 01:18:38,656:INFO:Extra Trees Classifier Imported successfully
2023-08-16 01:18:38,661:INFO:Starting cross validation
2023-08-16 01:18:38,662:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:18:51,039:INFO:Calculating mean and std
2023-08-16 01:18:51,040:INFO:Creating metrics dataframe
2023-08-16 01:18:51,065:INFO:Uploading results into container
2023-08-16 01:18:51,066:INFO:Uploading model into container now
2023-08-16 01:18:51,066:INFO:_master_model_container: 12
2023-08-16 01:18:51,066:INFO:_display_container: 2
2023-08-16 01:18:51,066:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-08-16 01:18:51,066:INFO:create_model() successfully completed......................................
2023-08-16 01:18:51,132:INFO:SubProcess create_model() end ==================================
2023-08-16 01:18:51,132:INFO:Creating metrics dataframe
2023-08-16 01:18:51,141:INFO:Initializing Light Gradient Boosting Machine
2023-08-16 01:18:51,141:INFO:Total runtime is 0.7878994743029276 minutes
2023-08-16 01:18:51,143:INFO:SubProcess create_model() called ==================================
2023-08-16 01:18:51,144:INFO:Initializing create_model()
2023-08-16 01:18:51,144:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B23F1760>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000195B1B25B50>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:18:51,144:INFO:Checking exceptions
2023-08-16 01:18:51,144:INFO:Importing libraries
2023-08-16 01:18:51,144:INFO:Copying training dataset
2023-08-16 01:18:51,153:INFO:Defining folds
2023-08-16 01:18:51,153:INFO:Declaring metric variables
2023-08-16 01:18:51,155:INFO:Importing untrained model
2023-08-16 01:18:51,158:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-16 01:18:51,163:INFO:Starting cross validation
2023-08-16 01:18:51,164:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:18:52,445:INFO:Calculating mean and std
2023-08-16 01:18:52,447:INFO:Creating metrics dataframe
2023-08-16 01:18:52,495:INFO:Uploading results into container
2023-08-16 01:18:52,496:INFO:Uploading model into container now
2023-08-16 01:18:52,496:INFO:_master_model_container: 13
2023-08-16 01:18:52,496:INFO:_display_container: 2
2023-08-16 01:18:52,497:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-16 01:18:52,497:INFO:create_model() successfully completed......................................
2023-08-16 01:18:52,588:INFO:SubProcess create_model() end ==================================
2023-08-16 01:18:52,588:INFO:Creating metrics dataframe
2023-08-16 01:18:52,598:INFO:Initializing Dummy Classifier
2023-08-16 01:18:52,598:INFO:Total runtime is 0.8121871590614318 minutes
2023-08-16 01:18:52,601:INFO:SubProcess create_model() called ==================================
2023-08-16 01:18:52,601:INFO:Initializing create_model()
2023-08-16 01:18:52,601:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B23F1760>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000195B1B25B50>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:18:52,601:INFO:Checking exceptions
2023-08-16 01:18:52,601:INFO:Importing libraries
2023-08-16 01:18:52,601:INFO:Copying training dataset
2023-08-16 01:18:52,611:INFO:Defining folds
2023-08-16 01:18:52,611:INFO:Declaring metric variables
2023-08-16 01:18:52,614:INFO:Importing untrained model
2023-08-16 01:18:52,617:INFO:Dummy Classifier Imported successfully
2023-08-16 01:18:52,622:INFO:Starting cross validation
2023-08-16 01:18:52,623:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:18:52,710:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:18:52,718:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:18:52,723:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:18:52,740:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:18:52,743:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:18:52,745:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:18:52,759:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:18:52,764:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:18:52,769:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:18:52,772:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:18:52,987:INFO:Calculating mean and std
2023-08-16 01:18:52,989:INFO:Creating metrics dataframe
2023-08-16 01:18:53,025:INFO:Uploading results into container
2023-08-16 01:18:53,026:INFO:Uploading model into container now
2023-08-16 01:18:53,026:INFO:_master_model_container: 14
2023-08-16 01:18:53,026:INFO:_display_container: 2
2023-08-16 01:18:53,027:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-08-16 01:18:53,027:INFO:create_model() successfully completed......................................
2023-08-16 01:18:53,094:INFO:SubProcess create_model() end ==================================
2023-08-16 01:18:53,094:INFO:Creating metrics dataframe
2023-08-16 01:18:53,109:INFO:Initializing create_model()
2023-08-16 01:18:53,110:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B23F1760>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:18:53,110:INFO:Checking exceptions
2023-08-16 01:18:53,111:INFO:Importing libraries
2023-08-16 01:18:53,111:INFO:Copying training dataset
2023-08-16 01:18:53,119:INFO:Defining folds
2023-08-16 01:18:53,119:INFO:Declaring metric variables
2023-08-16 01:18:53,119:INFO:Importing untrained model
2023-08-16 01:18:53,119:INFO:Declaring custom model
2023-08-16 01:18:53,120:INFO:Gradient Boosting Classifier Imported successfully
2023-08-16 01:18:53,120:INFO:Cross validation set to False
2023-08-16 01:18:53,120:INFO:Fitting Model
2023-08-16 01:18:54,002:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-16 01:18:54,002:INFO:create_model() successfully completed......................................
2023-08-16 01:18:54,087:INFO:_master_model_container: 14
2023-08-16 01:18:54,087:INFO:_display_container: 2
2023-08-16 01:18:54,088:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-16 01:18:54,088:INFO:compare_models() successfully completed......................................
2023-08-16 01:19:16,920:INFO:Initializing compare_models()
2023-08-16 01:19:16,920:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B23E3EE0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000195B23E3EE0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-16 01:19:16,920:INFO:Checking exceptions
2023-08-16 01:19:16,927:INFO:Preparing display monitor
2023-08-16 01:19:16,954:INFO:Initializing Logistic Regression
2023-08-16 01:19:16,954:INFO:Total runtime is 0.0 minutes
2023-08-16 01:19:16,956:INFO:SubProcess create_model() called ==================================
2023-08-16 01:19:16,956:INFO:Initializing create_model()
2023-08-16 01:19:16,957:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B23E3EE0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000195B353ABB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:19:16,957:INFO:Checking exceptions
2023-08-16 01:19:16,957:INFO:Importing libraries
2023-08-16 01:19:16,957:INFO:Copying training dataset
2023-08-16 01:19:16,968:INFO:Defining folds
2023-08-16 01:19:16,968:INFO:Declaring metric variables
2023-08-16 01:19:16,971:INFO:Importing untrained model
2023-08-16 01:19:16,974:INFO:Logistic Regression Imported successfully
2023-08-16 01:19:16,981:INFO:Starting cross validation
2023-08-16 01:19:16,982:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:19:17,367:INFO:Calculating mean and std
2023-08-16 01:19:17,367:INFO:Creating metrics dataframe
2023-08-16 01:19:17,398:INFO:Uploading results into container
2023-08-16 01:19:17,399:INFO:Uploading model into container now
2023-08-16 01:19:17,399:INFO:_master_model_container: 1
2023-08-16 01:19:17,399:INFO:_display_container: 2
2023-08-16 01:19:17,399:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-16 01:19:17,399:INFO:create_model() successfully completed......................................
2023-08-16 01:19:17,463:INFO:SubProcess create_model() end ==================================
2023-08-16 01:19:17,463:INFO:Creating metrics dataframe
2023-08-16 01:19:17,469:INFO:Initializing K Neighbors Classifier
2023-08-16 01:19:17,469:INFO:Total runtime is 0.008579059441884359 minutes
2023-08-16 01:19:17,471:INFO:SubProcess create_model() called ==================================
2023-08-16 01:19:17,472:INFO:Initializing create_model()
2023-08-16 01:19:17,472:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B23E3EE0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000195B353ABB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:19:17,472:INFO:Checking exceptions
2023-08-16 01:19:17,472:INFO:Importing libraries
2023-08-16 01:19:17,472:INFO:Copying training dataset
2023-08-16 01:19:17,480:INFO:Defining folds
2023-08-16 01:19:17,480:INFO:Declaring metric variables
2023-08-16 01:19:17,483:INFO:Importing untrained model
2023-08-16 01:19:17,485:INFO:K Neighbors Classifier Imported successfully
2023-08-16 01:19:17,490:INFO:Starting cross validation
2023-08-16 01:19:17,491:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:19:17,777:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:19:17,780:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:19:17,833:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:19:17,898:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:19:17,943:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:19:17,946:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:19:17,961:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:19:18,034:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:19:18,037:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:19:18,087:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:19:18,477:INFO:Calculating mean and std
2023-08-16 01:19:18,478:INFO:Creating metrics dataframe
2023-08-16 01:19:18,514:INFO:Uploading results into container
2023-08-16 01:19:18,514:INFO:Uploading model into container now
2023-08-16 01:19:18,514:INFO:_master_model_container: 2
2023-08-16 01:19:18,515:INFO:_display_container: 2
2023-08-16 01:19:18,515:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-16 01:19:18,515:INFO:create_model() successfully completed......................................
2023-08-16 01:19:18,582:INFO:SubProcess create_model() end ==================================
2023-08-16 01:19:18,582:INFO:Creating metrics dataframe
2023-08-16 01:19:18,588:INFO:Initializing Naive Bayes
2023-08-16 01:19:18,588:INFO:Total runtime is 0.02722986141840617 minutes
2023-08-16 01:19:18,591:INFO:SubProcess create_model() called ==================================
2023-08-16 01:19:18,591:INFO:Initializing create_model()
2023-08-16 01:19:18,591:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B23E3EE0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000195B353ABB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:19:18,591:INFO:Checking exceptions
2023-08-16 01:19:18,591:INFO:Importing libraries
2023-08-16 01:19:18,591:INFO:Copying training dataset
2023-08-16 01:19:18,601:INFO:Defining folds
2023-08-16 01:19:18,601:INFO:Declaring metric variables
2023-08-16 01:19:18,604:INFO:Importing untrained model
2023-08-16 01:19:18,606:INFO:Naive Bayes Imported successfully
2023-08-16 01:19:18,611:INFO:Starting cross validation
2023-08-16 01:19:18,612:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:19:18,985:INFO:Calculating mean and std
2023-08-16 01:19:18,986:INFO:Creating metrics dataframe
2023-08-16 01:19:19,016:INFO:Uploading results into container
2023-08-16 01:19:19,017:INFO:Uploading model into container now
2023-08-16 01:19:19,017:INFO:_master_model_container: 3
2023-08-16 01:19:19,018:INFO:_display_container: 2
2023-08-16 01:19:19,018:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-16 01:19:19,018:INFO:create_model() successfully completed......................................
2023-08-16 01:19:19,086:INFO:SubProcess create_model() end ==================================
2023-08-16 01:19:19,086:INFO:Creating metrics dataframe
2023-08-16 01:19:19,093:INFO:Initializing Decision Tree Classifier
2023-08-16 01:19:19,093:INFO:Total runtime is 0.035656138261159265 minutes
2023-08-16 01:19:19,095:INFO:SubProcess create_model() called ==================================
2023-08-16 01:19:19,095:INFO:Initializing create_model()
2023-08-16 01:19:19,095:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B23E3EE0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000195B353ABB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:19:19,095:INFO:Checking exceptions
2023-08-16 01:19:19,095:INFO:Importing libraries
2023-08-16 01:19:19,095:INFO:Copying training dataset
2023-08-16 01:19:19,104:INFO:Defining folds
2023-08-16 01:19:19,104:INFO:Declaring metric variables
2023-08-16 01:19:19,107:INFO:Importing untrained model
2023-08-16 01:19:19,110:INFO:Decision Tree Classifier Imported successfully
2023-08-16 01:19:19,114:INFO:Starting cross validation
2023-08-16 01:19:19,115:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:19:19,478:INFO:Calculating mean and std
2023-08-16 01:19:19,479:INFO:Creating metrics dataframe
2023-08-16 01:19:19,514:INFO:Uploading results into container
2023-08-16 01:19:19,515:INFO:Uploading model into container now
2023-08-16 01:19:19,515:INFO:_master_model_container: 4
2023-08-16 01:19:19,515:INFO:_display_container: 2
2023-08-16 01:19:19,515:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-08-16 01:19:19,515:INFO:create_model() successfully completed......................................
2023-08-16 01:19:19,582:INFO:SubProcess create_model() end ==================================
2023-08-16 01:19:19,583:INFO:Creating metrics dataframe
2023-08-16 01:19:19,590:INFO:Initializing SVM - Linear Kernel
2023-08-16 01:19:19,590:INFO:Total runtime is 0.04394092162450155 minutes
2023-08-16 01:19:19,592:INFO:SubProcess create_model() called ==================================
2023-08-16 01:19:19,592:INFO:Initializing create_model()
2023-08-16 01:19:19,592:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B23E3EE0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000195B353ABB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:19:19,593:INFO:Checking exceptions
2023-08-16 01:19:19,593:INFO:Importing libraries
2023-08-16 01:19:19,593:INFO:Copying training dataset
2023-08-16 01:19:19,601:INFO:Defining folds
2023-08-16 01:19:19,601:INFO:Declaring metric variables
2023-08-16 01:19:19,604:INFO:Importing untrained model
2023-08-16 01:19:19,606:INFO:SVM - Linear Kernel Imported successfully
2023-08-16 01:19:19,611:INFO:Starting cross validation
2023-08-16 01:19:19,611:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:19:19,691:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:19:19,701:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:19:19,704:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:19:19,712:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:19:19,722:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:19:19,726:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:19:19,732:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:19:19,736:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:19:19,746:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:19:19,747:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:19:19,954:INFO:Calculating mean and std
2023-08-16 01:19:19,956:INFO:Creating metrics dataframe
2023-08-16 01:19:19,985:INFO:Uploading results into container
2023-08-16 01:19:19,986:INFO:Uploading model into container now
2023-08-16 01:19:19,987:INFO:_master_model_container: 5
2023-08-16 01:19:19,987:INFO:_display_container: 2
2023-08-16 01:19:19,987:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-16 01:19:19,987:INFO:create_model() successfully completed......................................
2023-08-16 01:19:20,055:INFO:SubProcess create_model() end ==================================
2023-08-16 01:19:20,055:INFO:Creating metrics dataframe
2023-08-16 01:19:20,062:INFO:Initializing Ridge Classifier
2023-08-16 01:19:20,062:INFO:Total runtime is 0.05179966688156128 minutes
2023-08-16 01:19:20,064:INFO:SubProcess create_model() called ==================================
2023-08-16 01:19:20,064:INFO:Initializing create_model()
2023-08-16 01:19:20,064:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B23E3EE0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000195B353ABB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:19:20,064:INFO:Checking exceptions
2023-08-16 01:19:20,064:INFO:Importing libraries
2023-08-16 01:19:20,064:INFO:Copying training dataset
2023-08-16 01:19:20,079:INFO:Defining folds
2023-08-16 01:19:20,079:INFO:Declaring metric variables
2023-08-16 01:19:20,083:INFO:Importing untrained model
2023-08-16 01:19:20,085:INFO:Ridge Classifier Imported successfully
2023-08-16 01:19:20,091:INFO:Starting cross validation
2023-08-16 01:19:20,092:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:19:20,174:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:19:20,178:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:19:20,189:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:19:20,197:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:19:20,203:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:19:20,210:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:19:20,215:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:19:20,230:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:19:20,233:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:19:20,235:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:19:20,444:INFO:Calculating mean and std
2023-08-16 01:19:20,445:INFO:Creating metrics dataframe
2023-08-16 01:19:20,476:INFO:Uploading results into container
2023-08-16 01:19:20,476:INFO:Uploading model into container now
2023-08-16 01:19:20,477:INFO:_master_model_container: 6
2023-08-16 01:19:20,477:INFO:_display_container: 2
2023-08-16 01:19:20,477:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=123, solver='auto', tol=0.001)
2023-08-16 01:19:20,477:INFO:create_model() successfully completed......................................
2023-08-16 01:19:20,544:INFO:SubProcess create_model() end ==================================
2023-08-16 01:19:20,544:INFO:Creating metrics dataframe
2023-08-16 01:19:20,551:INFO:Initializing Random Forest Classifier
2023-08-16 01:19:20,551:INFO:Total runtime is 0.059958696365356445 minutes
2023-08-16 01:19:20,554:INFO:SubProcess create_model() called ==================================
2023-08-16 01:19:20,554:INFO:Initializing create_model()
2023-08-16 01:19:20,554:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B23E3EE0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000195B353ABB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:19:20,554:INFO:Checking exceptions
2023-08-16 01:19:20,554:INFO:Importing libraries
2023-08-16 01:19:20,554:INFO:Copying training dataset
2023-08-16 01:19:20,563:INFO:Defining folds
2023-08-16 01:19:20,563:INFO:Declaring metric variables
2023-08-16 01:19:20,566:INFO:Importing untrained model
2023-08-16 01:19:20,569:INFO:Random Forest Classifier Imported successfully
2023-08-16 01:19:20,574:INFO:Starting cross validation
2023-08-16 01:19:20,575:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:19:21,426:INFO:Calculating mean and std
2023-08-16 01:19:21,427:INFO:Creating metrics dataframe
2023-08-16 01:19:21,465:INFO:Uploading results into container
2023-08-16 01:19:21,466:INFO:Uploading model into container now
2023-08-16 01:19:21,466:INFO:_master_model_container: 7
2023-08-16 01:19:21,466:INFO:_display_container: 2
2023-08-16 01:19:21,467:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-08-16 01:19:21,467:INFO:create_model() successfully completed......................................
2023-08-16 01:19:21,548:INFO:SubProcess create_model() end ==================================
2023-08-16 01:19:21,548:INFO:Creating metrics dataframe
2023-08-16 01:19:21,555:INFO:Initializing Quadratic Discriminant Analysis
2023-08-16 01:19:21,556:INFO:Total runtime is 0.07670127153396607 minutes
2023-08-16 01:19:21,558:INFO:SubProcess create_model() called ==================================
2023-08-16 01:19:21,558:INFO:Initializing create_model()
2023-08-16 01:19:21,558:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B23E3EE0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000195B353ABB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:19:21,558:INFO:Checking exceptions
2023-08-16 01:19:21,558:INFO:Importing libraries
2023-08-16 01:19:21,558:INFO:Copying training dataset
2023-08-16 01:19:21,570:INFO:Defining folds
2023-08-16 01:19:21,570:INFO:Declaring metric variables
2023-08-16 01:19:21,573:INFO:Importing untrained model
2023-08-16 01:19:21,575:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-16 01:19:21,580:INFO:Starting cross validation
2023-08-16 01:19:21,580:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:19:21,967:INFO:Calculating mean and std
2023-08-16 01:19:21,968:INFO:Creating metrics dataframe
2023-08-16 01:19:22,006:INFO:Uploading results into container
2023-08-16 01:19:22,007:INFO:Uploading model into container now
2023-08-16 01:19:22,007:INFO:_master_model_container: 8
2023-08-16 01:19:22,007:INFO:_display_container: 2
2023-08-16 01:19:22,008:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-16 01:19:22,008:INFO:create_model() successfully completed......................................
2023-08-16 01:19:22,075:INFO:SubProcess create_model() end ==================================
2023-08-16 01:19:22,075:INFO:Creating metrics dataframe
2023-08-16 01:19:22,083:INFO:Initializing Ada Boost Classifier
2023-08-16 01:19:22,083:INFO:Total runtime is 0.0854937752087911 minutes
2023-08-16 01:19:22,086:INFO:SubProcess create_model() called ==================================
2023-08-16 01:19:22,086:INFO:Initializing create_model()
2023-08-16 01:19:22,086:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B23E3EE0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000195B353ABB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:19:22,086:INFO:Checking exceptions
2023-08-16 01:19:22,086:INFO:Importing libraries
2023-08-16 01:19:22,086:INFO:Copying training dataset
2023-08-16 01:19:22,096:INFO:Defining folds
2023-08-16 01:19:22,096:INFO:Declaring metric variables
2023-08-16 01:19:22,098:INFO:Importing untrained model
2023-08-16 01:19:22,100:INFO:Ada Boost Classifier Imported successfully
2023-08-16 01:19:22,105:INFO:Starting cross validation
2023-08-16 01:19:22,106:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:19:22,520:INFO:Calculating mean and std
2023-08-16 01:19:22,521:INFO:Creating metrics dataframe
2023-08-16 01:19:22,551:INFO:Uploading results into container
2023-08-16 01:19:22,551:INFO:Uploading model into container now
2023-08-16 01:19:22,552:INFO:_master_model_container: 9
2023-08-16 01:19:22,552:INFO:_display_container: 2
2023-08-16 01:19:22,552:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2023-08-16 01:19:22,552:INFO:create_model() successfully completed......................................
2023-08-16 01:19:22,619:INFO:SubProcess create_model() end ==================================
2023-08-16 01:19:22,619:INFO:Creating metrics dataframe
2023-08-16 01:19:22,626:INFO:Initializing Gradient Boosting Classifier
2023-08-16 01:19:22,626:INFO:Total runtime is 0.09454008340835572 minutes
2023-08-16 01:19:22,628:INFO:SubProcess create_model() called ==================================
2023-08-16 01:19:22,628:INFO:Initializing create_model()
2023-08-16 01:19:22,628:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B23E3EE0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000195B353ABB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:19:22,628:INFO:Checking exceptions
2023-08-16 01:19:22,629:INFO:Importing libraries
2023-08-16 01:19:22,629:INFO:Copying training dataset
2023-08-16 01:19:22,639:INFO:Defining folds
2023-08-16 01:19:22,639:INFO:Declaring metric variables
2023-08-16 01:19:22,641:INFO:Importing untrained model
2023-08-16 01:19:22,644:INFO:Gradient Boosting Classifier Imported successfully
2023-08-16 01:19:22,649:INFO:Starting cross validation
2023-08-16 01:19:22,650:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:19:23,061:INFO:Calculating mean and std
2023-08-16 01:19:23,062:INFO:Creating metrics dataframe
2023-08-16 01:19:23,091:INFO:Uploading results into container
2023-08-16 01:19:23,092:INFO:Uploading model into container now
2023-08-16 01:19:23,092:INFO:_master_model_container: 10
2023-08-16 01:19:23,092:INFO:_display_container: 2
2023-08-16 01:19:23,092:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-16 01:19:23,092:INFO:create_model() successfully completed......................................
2023-08-16 01:19:23,160:INFO:SubProcess create_model() end ==================================
2023-08-16 01:19:23,160:INFO:Creating metrics dataframe
2023-08-16 01:19:23,169:INFO:Initializing Linear Discriminant Analysis
2023-08-16 01:19:23,169:INFO:Total runtime is 0.10357986291249593 minutes
2023-08-16 01:19:23,171:INFO:SubProcess create_model() called ==================================
2023-08-16 01:19:23,171:INFO:Initializing create_model()
2023-08-16 01:19:23,171:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B23E3EE0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000195B353ABB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:19:23,172:INFO:Checking exceptions
2023-08-16 01:19:23,172:INFO:Importing libraries
2023-08-16 01:19:23,172:INFO:Copying training dataset
2023-08-16 01:19:23,181:INFO:Defining folds
2023-08-16 01:19:23,181:INFO:Declaring metric variables
2023-08-16 01:19:23,184:INFO:Importing untrained model
2023-08-16 01:19:23,187:INFO:Linear Discriminant Analysis Imported successfully
2023-08-16 01:19:23,191:INFO:Starting cross validation
2023-08-16 01:19:23,192:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:19:23,567:INFO:Calculating mean and std
2023-08-16 01:19:23,568:INFO:Creating metrics dataframe
2023-08-16 01:19:23,599:INFO:Uploading results into container
2023-08-16 01:19:23,599:INFO:Uploading model into container now
2023-08-16 01:19:23,600:INFO:_master_model_container: 11
2023-08-16 01:19:23,600:INFO:_display_container: 2
2023-08-16 01:19:23,600:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-16 01:19:23,600:INFO:create_model() successfully completed......................................
2023-08-16 01:19:23,666:INFO:SubProcess create_model() end ==================================
2023-08-16 01:19:23,666:INFO:Creating metrics dataframe
2023-08-16 01:19:23,674:INFO:Initializing Extra Trees Classifier
2023-08-16 01:19:23,674:INFO:Total runtime is 0.11200433572133382 minutes
2023-08-16 01:19:23,676:INFO:SubProcess create_model() called ==================================
2023-08-16 01:19:23,677:INFO:Initializing create_model()
2023-08-16 01:19:23,677:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B23E3EE0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000195B353ABB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:19:23,677:INFO:Checking exceptions
2023-08-16 01:19:23,677:INFO:Importing libraries
2023-08-16 01:19:23,677:INFO:Copying training dataset
2023-08-16 01:19:23,686:INFO:Defining folds
2023-08-16 01:19:23,686:INFO:Declaring metric variables
2023-08-16 01:19:23,689:INFO:Importing untrained model
2023-08-16 01:19:23,691:INFO:Extra Trees Classifier Imported successfully
2023-08-16 01:19:23,696:INFO:Starting cross validation
2023-08-16 01:19:23,697:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:19:24,766:INFO:Calculating mean and std
2023-08-16 01:19:24,767:INFO:Creating metrics dataframe
2023-08-16 01:19:24,801:INFO:Uploading results into container
2023-08-16 01:19:24,802:INFO:Uploading model into container now
2023-08-16 01:19:24,802:INFO:_master_model_container: 12
2023-08-16 01:19:24,802:INFO:_display_container: 2
2023-08-16 01:19:24,803:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-08-16 01:19:24,803:INFO:create_model() successfully completed......................................
2023-08-16 01:19:24,886:INFO:SubProcess create_model() end ==================================
2023-08-16 01:19:24,886:INFO:Creating metrics dataframe
2023-08-16 01:19:24,895:INFO:Initializing Light Gradient Boosting Machine
2023-08-16 01:19:24,895:INFO:Total runtime is 0.13236089944839477 minutes
2023-08-16 01:19:24,898:INFO:SubProcess create_model() called ==================================
2023-08-16 01:19:24,899:INFO:Initializing create_model()
2023-08-16 01:19:24,900:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B23E3EE0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000195B353ABB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:19:24,900:INFO:Checking exceptions
2023-08-16 01:19:24,900:INFO:Importing libraries
2023-08-16 01:19:24,900:INFO:Copying training dataset
2023-08-16 01:19:24,908:INFO:Defining folds
2023-08-16 01:19:24,909:INFO:Declaring metric variables
2023-08-16 01:19:24,913:INFO:Importing untrained model
2023-08-16 01:19:24,916:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-16 01:19:24,920:INFO:Starting cross validation
2023-08-16 01:19:24,921:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:19:25,384:INFO:Calculating mean and std
2023-08-16 01:19:25,385:INFO:Creating metrics dataframe
2023-08-16 01:19:25,415:INFO:Uploading results into container
2023-08-16 01:19:25,415:INFO:Uploading model into container now
2023-08-16 01:19:25,416:INFO:_master_model_container: 13
2023-08-16 01:19:25,416:INFO:_display_container: 2
2023-08-16 01:19:25,416:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-16 01:19:25,416:INFO:create_model() successfully completed......................................
2023-08-16 01:19:25,483:INFO:SubProcess create_model() end ==================================
2023-08-16 01:19:25,483:INFO:Creating metrics dataframe
2023-08-16 01:19:25,491:INFO:Initializing Dummy Classifier
2023-08-16 01:19:25,491:INFO:Total runtime is 0.14228072961171467 minutes
2023-08-16 01:19:25,494:INFO:SubProcess create_model() called ==================================
2023-08-16 01:19:25,494:INFO:Initializing create_model()
2023-08-16 01:19:25,494:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B23E3EE0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000195B353ABB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:19:25,494:INFO:Checking exceptions
2023-08-16 01:19:25,494:INFO:Importing libraries
2023-08-16 01:19:25,494:INFO:Copying training dataset
2023-08-16 01:19:25,504:INFO:Defining folds
2023-08-16 01:19:25,504:INFO:Declaring metric variables
2023-08-16 01:19:25,506:INFO:Importing untrained model
2023-08-16 01:19:25,509:INFO:Dummy Classifier Imported successfully
2023-08-16 01:19:25,515:INFO:Starting cross validation
2023-08-16 01:19:25,515:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:19:25,602:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:19:25,607:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:19:25,619:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:19:25,625:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:19:25,630:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:19:25,633:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:19:25,647:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:19:25,649:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:19:25,659:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:19:25,660:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:19:25,860:INFO:Calculating mean and std
2023-08-16 01:19:25,861:INFO:Creating metrics dataframe
2023-08-16 01:19:25,892:INFO:Uploading results into container
2023-08-16 01:19:25,892:INFO:Uploading model into container now
2023-08-16 01:19:25,893:INFO:_master_model_container: 14
2023-08-16 01:19:25,893:INFO:_display_container: 2
2023-08-16 01:19:25,893:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-08-16 01:19:25,893:INFO:create_model() successfully completed......................................
2023-08-16 01:19:25,960:INFO:SubProcess create_model() end ==================================
2023-08-16 01:19:25,960:INFO:Creating metrics dataframe
2023-08-16 01:19:25,975:INFO:Initializing create_model()
2023-08-16 01:19:25,975:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B23E3EE0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:19:25,975:INFO:Checking exceptions
2023-08-16 01:19:25,977:INFO:Importing libraries
2023-08-16 01:19:25,977:INFO:Copying training dataset
2023-08-16 01:19:25,984:INFO:Defining folds
2023-08-16 01:19:25,984:INFO:Declaring metric variables
2023-08-16 01:19:25,985:INFO:Importing untrained model
2023-08-16 01:19:25,985:INFO:Declaring custom model
2023-08-16 01:19:25,985:INFO:Gradient Boosting Classifier Imported successfully
2023-08-16 01:19:25,985:INFO:Cross validation set to False
2023-08-16 01:19:25,986:INFO:Fitting Model
2023-08-16 01:19:26,039:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-16 01:19:26,039:INFO:create_model() successfully completed......................................
2023-08-16 01:19:26,135:INFO:_master_model_container: 14
2023-08-16 01:19:26,135:INFO:_display_container: 2
2023-08-16 01:19:26,135:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-16 01:19:26,135:INFO:compare_models() successfully completed......................................
2023-08-16 01:19:59,006:INFO:Initializing plot_model()
2023-08-16 01:19:59,007:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B23F1760>, system=True)
2023-08-16 01:19:59,007:INFO:Checking exceptions
2023-08-16 01:19:59,015:INFO:Preloading libraries
2023-08-16 01:19:59,021:INFO:Copying training dataset
2023-08-16 01:19:59,021:INFO:Plot type: confusion_matrix
2023-08-16 01:19:59,103:INFO:Fitting Model
2023-08-16 01:19:59,106:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2023-08-16 01:19:59,106:INFO:Scoring test/hold-out set
2023-08-16 01:19:59,272:INFO:Visual Rendered Successfully
2023-08-16 01:19:59,352:INFO:plot_model() successfully completed......................................
2023-08-16 01:20:10,189:INFO:Initializing plot_model()
2023-08-16 01:20:10,189:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B23F1760>, system=True)
2023-08-16 01:20:10,189:INFO:Checking exceptions
2023-08-16 01:20:10,197:INFO:Preloading libraries
2023-08-16 01:20:10,202:INFO:Copying training dataset
2023-08-16 01:20:10,202:INFO:Plot type: auc
2023-08-16 01:20:10,274:INFO:Fitting Model
2023-08-16 01:20:10,274:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2023-08-16 01:20:10,274:INFO:Scoring test/hold-out set
2023-08-16 01:20:10,415:INFO:Visual Rendered Successfully
2023-08-16 01:20:10,481:INFO:plot_model() successfully completed......................................
2023-08-16 01:20:22,159:INFO:Initializing plot_model()
2023-08-16 01:20:22,159:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B23F1760>, system=True)
2023-08-16 01:20:22,159:INFO:Checking exceptions
2023-08-16 01:20:22,166:INFO:Preloading libraries
2023-08-16 01:20:22,171:INFO:Copying training dataset
2023-08-16 01:20:22,172:INFO:Plot type: feature
2023-08-16 01:20:22,172:WARNING:No coef_ found. Trying feature_importances_
2023-08-16 01:20:22,276:INFO:Visual Rendered Successfully
2023-08-16 01:20:22,344:INFO:plot_model() successfully completed......................................
2023-08-16 01:21:15,739:INFO:PyCaret ClassificationExperiment
2023-08-16 01:21:15,740:INFO:Logging name: clf-default-name
2023-08-16 01:21:15,740:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-16 01:21:15,740:INFO:version 3.0.4
2023-08-16 01:21:15,740:INFO:Initializing setup()
2023-08-16 01:21:15,740:INFO:self.USI: ab01
2023-08-16 01:21:15,740:INFO:self._variable_keys: {'fix_imbalance', 'is_multiclass', '_available_plots', 'seed', 'y_train', 'n_jobs_param', 'gpu_param', 'exp_id', 'X_test', 'fold_groups_param', 'y_test', 'log_plots_param', 'gpu_n_jobs_param', 'logging_param', 'memory', 'y', 'fold_shuffle_param', 'fold_generator', '_ml_usecase', 'exp_name_log', 'X_train', 'X', 'pipeline', 'target_param', 'USI', 'data', 'idx', 'html_param'}
2023-08-16 01:21:15,740:INFO:Checking environment
2023-08-16 01:21:15,740:INFO:python_version: 3.9.13
2023-08-16 01:21:15,740:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-08-16 01:21:15,740:INFO:machine: AMD64
2023-08-16 01:21:15,740:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-16 01:21:15,740:INFO:Memory: svmem(total=16905969664, available=1715486720, percent=89.9, used=15190482944, free=1715486720)
2023-08-16 01:21:15,740:INFO:Physical Core: 8
2023-08-16 01:21:15,740:INFO:Logical Core: 16
2023-08-16 01:21:15,740:INFO:Checking libraries
2023-08-16 01:21:15,740:INFO:System:
2023-08-16 01:21:15,740:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-08-16 01:21:15,740:INFO:executable: c:\Users\lmacciomaretto\anaconda3\python.exe
2023-08-16 01:21:15,740:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-16 01:21:15,740:INFO:PyCaret required dependencies:
2023-08-16 01:21:15,740:INFO:                 pip: 22.2.2
2023-08-16 01:21:15,740:INFO:          setuptools: 63.4.1
2023-08-16 01:21:15,740:INFO:             pycaret: 3.0.4
2023-08-16 01:21:15,740:INFO:             IPython: 7.31.1
2023-08-16 01:21:15,740:INFO:          ipywidgets: 7.6.5
2023-08-16 01:21:15,740:INFO:                tqdm: 4.64.1
2023-08-16 01:21:15,740:INFO:               numpy: 1.21.5
2023-08-16 01:21:15,740:INFO:              pandas: 1.4.4
2023-08-16 01:21:15,740:INFO:              jinja2: 2.11.3
2023-08-16 01:21:15,740:INFO:               scipy: 1.9.1
2023-08-16 01:21:15,740:INFO:              joblib: 1.3.2
2023-08-16 01:21:15,740:INFO:             sklearn: 1.0.2
2023-08-16 01:21:15,740:INFO:                pyod: 1.1.0
2023-08-16 01:21:15,741:INFO:            imblearn: 0.11.0
2023-08-16 01:21:15,741:INFO:   category_encoders: 2.6.2
2023-08-16 01:21:15,741:INFO:            lightgbm: 4.0.0
2023-08-16 01:21:15,741:INFO:               numba: 0.55.1
2023-08-16 01:21:15,741:INFO:            requests: 2.28.1
2023-08-16 01:21:15,741:INFO:          matplotlib: 3.5.2
2023-08-16 01:21:15,741:INFO:          scikitplot: 0.3.7
2023-08-16 01:21:15,741:INFO:         yellowbrick: 1.5
2023-08-16 01:21:15,741:INFO:              plotly: 5.9.0
2023-08-16 01:21:15,741:INFO:    plotly-resampler: Not installed
2023-08-16 01:21:15,741:INFO:             kaleido: 0.2.1
2023-08-16 01:21:15,741:INFO:           schemdraw: 0.15
2023-08-16 01:21:15,741:INFO:         statsmodels: 0.13.2
2023-08-16 01:21:15,741:INFO:              sktime: 0.21.0
2023-08-16 01:21:15,741:INFO:               tbats: 1.1.3
2023-08-16 01:21:15,741:INFO:            pmdarima: 2.0.3
2023-08-16 01:21:15,741:INFO:              psutil: 5.9.0
2023-08-16 01:21:15,741:INFO:          markupsafe: 2.0.1
2023-08-16 01:21:15,741:INFO:             pickle5: Not installed
2023-08-16 01:21:15,741:INFO:         cloudpickle: 2.0.0
2023-08-16 01:21:15,741:INFO:         deprecation: 2.1.0
2023-08-16 01:21:15,741:INFO:              xxhash: 3.3.0
2023-08-16 01:21:15,741:INFO:           wurlitzer: Not installed
2023-08-16 01:21:15,741:INFO:PyCaret optional dependencies:
2023-08-16 01:21:15,741:INFO:                shap: Not installed
2023-08-16 01:21:15,741:INFO:           interpret: Not installed
2023-08-16 01:21:15,741:INFO:                umap: Not installed
2023-08-16 01:21:15,741:INFO:    pandas_profiling: Not installed
2023-08-16 01:21:15,741:INFO:  explainerdashboard: Not installed
2023-08-16 01:21:15,741:INFO:             autoviz: Not installed
2023-08-16 01:21:15,741:INFO:           fairlearn: Not installed
2023-08-16 01:21:15,741:INFO:          deepchecks: Not installed
2023-08-16 01:21:15,741:INFO:             xgboost: Not installed
2023-08-16 01:21:15,741:INFO:            catboost: Not installed
2023-08-16 01:21:15,741:INFO:              kmodes: Not installed
2023-08-16 01:21:15,741:INFO:             mlxtend: Not installed
2023-08-16 01:21:15,741:INFO:       statsforecast: Not installed
2023-08-16 01:21:15,741:INFO:        tune_sklearn: Not installed
2023-08-16 01:21:15,741:INFO:                 ray: Not installed
2023-08-16 01:21:15,741:INFO:            hyperopt: Not installed
2023-08-16 01:21:15,742:INFO:              optuna: Not installed
2023-08-16 01:21:15,742:INFO:               skopt: Not installed
2023-08-16 01:21:15,742:INFO:              mlflow: Not installed
2023-08-16 01:21:15,742:INFO:              gradio: Not installed
2023-08-16 01:21:15,742:INFO:             fastapi: Not installed
2023-08-16 01:21:15,742:INFO:             uvicorn: Not installed
2023-08-16 01:21:15,742:INFO:              m2cgen: Not installed
2023-08-16 01:21:15,742:INFO:           evidently: Not installed
2023-08-16 01:21:15,742:INFO:               fugue: Not installed
2023-08-16 01:21:15,742:INFO:           streamlit: Not installed
2023-08-16 01:21:15,742:INFO:             prophet: Not installed
2023-08-16 01:21:15,742:INFO:None
2023-08-16 01:21:15,742:INFO:Set up data.
2023-08-16 01:21:15,749:INFO:Set up train/test split.
2023-08-16 01:21:15,754:INFO:Set up index.
2023-08-16 01:21:15,754:INFO:Set up folding strategy.
2023-08-16 01:21:15,755:INFO:Assigning column types.
2023-08-16 01:21:15,758:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-16 01:21:15,790:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-16 01:21:15,791:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:21:15,811:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:21:15,812:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:21:15,845:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-16 01:21:15,845:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:21:15,865:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:21:15,865:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:21:15,866:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-16 01:21:15,898:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:21:15,918:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:21:15,918:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:21:15,952:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:21:15,972:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:21:15,973:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:21:15,973:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-16 01:21:16,026:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:21:16,026:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:21:16,079:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:21:16,079:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:21:16,080:INFO:Preparing preprocessing pipeline...
2023-08-16 01:21:16,081:INFO:Set up simple imputation.
2023-08-16 01:21:16,093:INFO:Finished creating preprocessing pipeline.
2023-08-16 01:21:16,095:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\LMACCI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['CATAG3', 'HEALTH2', 'ANYHLTI2',
                                             'INCOME', 'POVERTY3', 'TOBFLAG',
                                             'MRJFLAG', 'PYUD5MRJ', 'MJYRTOT',
                                             'ALCFLAG', 'COCFLAG', 'CRKFLAG',
                                             'HERFLAG', 'LSDFLAG',
                                             'METHAMFLAG'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose=0))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose=0)))],
         verbose=False)
2023-08-16 01:21:16,095:INFO:Creating final display dataframe.
2023-08-16 01:21:16,137:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          YODSMMDE
2                   Target type            Binary
3           Original data shape       (10241, 16)
4        Transformed data shape       (10241, 16)
5   Transformed train set shape        (7168, 16)
6    Transformed test set shape        (3073, 16)
7              Numeric features                15
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              ab01
2023-08-16 01:21:16,198:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:21:16,198:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:21:16,251:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:21:16,252:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:21:16,252:INFO:setup() successfully completed in 0.53s...............
2023-08-16 01:21:22,469:INFO:PyCaret ClassificationExperiment
2023-08-16 01:21:22,469:INFO:Logging name: clf-default-name
2023-08-16 01:21:22,469:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-16 01:21:22,469:INFO:version 3.0.4
2023-08-16 01:21:22,469:INFO:Initializing setup()
2023-08-16 01:21:22,469:INFO:self.USI: 33e4
2023-08-16 01:21:22,469:INFO:self._variable_keys: {'fix_imbalance', 'is_multiclass', '_available_plots', 'seed', 'y_train', 'n_jobs_param', 'gpu_param', 'exp_id', 'X_test', 'fold_groups_param', 'y_test', 'log_plots_param', 'gpu_n_jobs_param', 'logging_param', 'memory', 'y', 'fold_shuffle_param', 'fold_generator', '_ml_usecase', 'exp_name_log', 'X_train', 'X', 'pipeline', 'target_param', 'USI', 'data', 'idx', 'html_param'}
2023-08-16 01:21:22,469:INFO:Checking environment
2023-08-16 01:21:22,469:INFO:python_version: 3.9.13
2023-08-16 01:21:22,469:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-08-16 01:21:22,469:INFO:machine: AMD64
2023-08-16 01:21:22,469:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-16 01:21:22,470:INFO:Memory: svmem(total=16905969664, available=1725988864, percent=89.8, used=15179980800, free=1725988864)
2023-08-16 01:21:22,470:INFO:Physical Core: 8
2023-08-16 01:21:22,470:INFO:Logical Core: 16
2023-08-16 01:21:22,470:INFO:Checking libraries
2023-08-16 01:21:22,470:INFO:System:
2023-08-16 01:21:22,470:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-08-16 01:21:22,470:INFO:executable: c:\Users\lmacciomaretto\anaconda3\python.exe
2023-08-16 01:21:22,470:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-16 01:21:22,470:INFO:PyCaret required dependencies:
2023-08-16 01:21:22,470:INFO:                 pip: 22.2.2
2023-08-16 01:21:22,470:INFO:          setuptools: 63.4.1
2023-08-16 01:21:22,470:INFO:             pycaret: 3.0.4
2023-08-16 01:21:22,470:INFO:             IPython: 7.31.1
2023-08-16 01:21:22,470:INFO:          ipywidgets: 7.6.5
2023-08-16 01:21:22,470:INFO:                tqdm: 4.64.1
2023-08-16 01:21:22,470:INFO:               numpy: 1.21.5
2023-08-16 01:21:22,470:INFO:              pandas: 1.4.4
2023-08-16 01:21:22,470:INFO:              jinja2: 2.11.3
2023-08-16 01:21:22,470:INFO:               scipy: 1.9.1
2023-08-16 01:21:22,470:INFO:              joblib: 1.3.2
2023-08-16 01:21:22,470:INFO:             sklearn: 1.0.2
2023-08-16 01:21:22,470:INFO:                pyod: 1.1.0
2023-08-16 01:21:22,470:INFO:            imblearn: 0.11.0
2023-08-16 01:21:22,470:INFO:   category_encoders: 2.6.2
2023-08-16 01:21:22,470:INFO:            lightgbm: 4.0.0
2023-08-16 01:21:22,470:INFO:               numba: 0.55.1
2023-08-16 01:21:22,470:INFO:            requests: 2.28.1
2023-08-16 01:21:22,470:INFO:          matplotlib: 3.5.2
2023-08-16 01:21:22,470:INFO:          scikitplot: 0.3.7
2023-08-16 01:21:22,470:INFO:         yellowbrick: 1.5
2023-08-16 01:21:22,470:INFO:              plotly: 5.9.0
2023-08-16 01:21:22,470:INFO:    plotly-resampler: Not installed
2023-08-16 01:21:22,470:INFO:             kaleido: 0.2.1
2023-08-16 01:21:22,470:INFO:           schemdraw: 0.15
2023-08-16 01:21:22,470:INFO:         statsmodels: 0.13.2
2023-08-16 01:21:22,471:INFO:              sktime: 0.21.0
2023-08-16 01:21:22,471:INFO:               tbats: 1.1.3
2023-08-16 01:21:22,471:INFO:            pmdarima: 2.0.3
2023-08-16 01:21:22,471:INFO:              psutil: 5.9.0
2023-08-16 01:21:22,471:INFO:          markupsafe: 2.0.1
2023-08-16 01:21:22,471:INFO:             pickle5: Not installed
2023-08-16 01:21:22,471:INFO:         cloudpickle: 2.0.0
2023-08-16 01:21:22,471:INFO:         deprecation: 2.1.0
2023-08-16 01:21:22,471:INFO:              xxhash: 3.3.0
2023-08-16 01:21:22,471:INFO:           wurlitzer: Not installed
2023-08-16 01:21:22,471:INFO:PyCaret optional dependencies:
2023-08-16 01:21:22,471:INFO:                shap: Not installed
2023-08-16 01:21:22,471:INFO:           interpret: Not installed
2023-08-16 01:21:22,471:INFO:                umap: Not installed
2023-08-16 01:21:22,471:INFO:    pandas_profiling: Not installed
2023-08-16 01:21:22,471:INFO:  explainerdashboard: Not installed
2023-08-16 01:21:22,471:INFO:             autoviz: Not installed
2023-08-16 01:21:22,471:INFO:           fairlearn: Not installed
2023-08-16 01:21:22,471:INFO:          deepchecks: Not installed
2023-08-16 01:21:22,471:INFO:             xgboost: Not installed
2023-08-16 01:21:22,471:INFO:            catboost: Not installed
2023-08-16 01:21:22,471:INFO:              kmodes: Not installed
2023-08-16 01:21:22,471:INFO:             mlxtend: Not installed
2023-08-16 01:21:22,471:INFO:       statsforecast: Not installed
2023-08-16 01:21:22,471:INFO:        tune_sklearn: Not installed
2023-08-16 01:21:22,471:INFO:                 ray: Not installed
2023-08-16 01:21:22,471:INFO:            hyperopt: Not installed
2023-08-16 01:21:22,471:INFO:              optuna: Not installed
2023-08-16 01:21:22,471:INFO:               skopt: Not installed
2023-08-16 01:21:22,471:INFO:              mlflow: Not installed
2023-08-16 01:21:22,471:INFO:              gradio: Not installed
2023-08-16 01:21:22,471:INFO:             fastapi: Not installed
2023-08-16 01:21:22,471:INFO:             uvicorn: Not installed
2023-08-16 01:21:22,471:INFO:              m2cgen: Not installed
2023-08-16 01:21:22,471:INFO:           evidently: Not installed
2023-08-16 01:21:22,471:INFO:               fugue: Not installed
2023-08-16 01:21:22,471:INFO:           streamlit: Not installed
2023-08-16 01:21:22,471:INFO:             prophet: Not installed
2023-08-16 01:21:22,471:INFO:None
2023-08-16 01:21:22,471:INFO:Set up data.
2023-08-16 01:21:22,479:INFO:Set up train/test split.
2023-08-16 01:21:22,486:INFO:Set up index.
2023-08-16 01:21:22,487:INFO:Set up folding strategy.
2023-08-16 01:21:22,487:INFO:Assigning column types.
2023-08-16 01:21:22,494:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-16 01:21:22,533:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-16 01:21:22,534:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:21:22,555:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:21:22,555:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:21:22,589:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-16 01:21:22,589:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:21:22,609:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:21:22,610:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:21:22,610:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-16 01:21:22,643:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:21:22,663:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:21:22,663:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:21:22,698:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:21:22,718:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:21:22,718:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:21:22,719:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-16 01:21:22,772:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:21:22,772:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:21:22,826:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:21:22,826:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:21:22,827:INFO:Preparing preprocessing pipeline...
2023-08-16 01:21:22,828:INFO:Set up simple imputation.
2023-08-16 01:21:22,840:INFO:Finished creating preprocessing pipeline.
2023-08-16 01:21:22,842:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\LMACCI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['CATAG3', 'HEALTH2', 'ANYHLTI2',
                                             'INCOME', 'POVERTY3', 'TOBFLAG',
                                             'MRJFLAG', 'PYUD5MRJ', 'MJYRTOT',
                                             'ALCFLAG', 'COCFLAG', 'CRKFLAG',
                                             'HERFLAG', 'LSDFLAG',
                                             'METHAMFLAG'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose=0))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose=0)))],
         verbose=False)
2023-08-16 01:21:22,842:INFO:Creating final display dataframe.
2023-08-16 01:21:22,884:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          YODSMMDE
2                   Target type            Binary
3           Original data shape       (10241, 16)
4        Transformed data shape       (10241, 16)
5   Transformed train set shape        (7168, 16)
6    Transformed test set shape        (3073, 16)
7              Numeric features                15
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              33e4
2023-08-16 01:21:22,945:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:21:22,945:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:21:22,999:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:21:22,999:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:21:23,000:INFO:setup() successfully completed in 0.56s...............
2023-08-16 01:21:44,483:INFO:Initializing compare_models()
2023-08-16 01:21:44,483:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B3F43040>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000195B3F43040>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-16 01:21:44,483:INFO:Checking exceptions
2023-08-16 01:21:44,487:INFO:Preparing display monitor
2023-08-16 01:21:44,513:INFO:Initializing Logistic Regression
2023-08-16 01:21:44,514:INFO:Total runtime is 1.6661485036214194e-05 minutes
2023-08-16 01:21:44,516:INFO:SubProcess create_model() called ==================================
2023-08-16 01:21:44,516:INFO:Initializing create_model()
2023-08-16 01:21:44,516:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B3F43040>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000195B352CBB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:21:44,516:INFO:Checking exceptions
2023-08-16 01:21:44,517:INFO:Importing libraries
2023-08-16 01:21:44,517:INFO:Copying training dataset
2023-08-16 01:21:44,521:INFO:Defining folds
2023-08-16 01:21:44,521:INFO:Declaring metric variables
2023-08-16 01:21:44,525:INFO:Importing untrained model
2023-08-16 01:21:44,528:INFO:Logistic Regression Imported successfully
2023-08-16 01:21:44,533:INFO:Starting cross validation
2023-08-16 01:21:44,533:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:21:45,076:INFO:Calculating mean and std
2023-08-16 01:21:45,076:INFO:Creating metrics dataframe
2023-08-16 01:21:45,115:INFO:Uploading results into container
2023-08-16 01:21:45,115:INFO:Uploading model into container now
2023-08-16 01:21:45,116:INFO:_master_model_container: 1
2023-08-16 01:21:45,116:INFO:_display_container: 2
2023-08-16 01:21:45,116:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-16 01:21:45,116:INFO:create_model() successfully completed......................................
2023-08-16 01:21:45,200:INFO:SubProcess create_model() end ==================================
2023-08-16 01:21:45,200:INFO:Creating metrics dataframe
2023-08-16 01:21:45,206:INFO:Initializing K Neighbors Classifier
2023-08-16 01:21:45,206:INFO:Total runtime is 0.011549035708109537 minutes
2023-08-16 01:21:45,208:INFO:SubProcess create_model() called ==================================
2023-08-16 01:21:45,208:INFO:Initializing create_model()
2023-08-16 01:21:45,208:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B3F43040>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000195B352CBB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:21:45,209:INFO:Checking exceptions
2023-08-16 01:21:45,209:INFO:Importing libraries
2023-08-16 01:21:45,209:INFO:Copying training dataset
2023-08-16 01:21:45,213:INFO:Defining folds
2023-08-16 01:21:45,213:INFO:Declaring metric variables
2023-08-16 01:21:45,215:INFO:Importing untrained model
2023-08-16 01:21:45,217:INFO:K Neighbors Classifier Imported successfully
2023-08-16 01:21:45,223:INFO:Starting cross validation
2023-08-16 01:21:45,223:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:21:45,340:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:21:45,351:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:21:45,351:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:21:45,351:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:21:45,352:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:21:45,371:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:21:45,379:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:21:45,381:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:21:45,393:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:21:45,723:INFO:Calculating mean and std
2023-08-16 01:21:45,725:INFO:Creating metrics dataframe
2023-08-16 01:21:45,759:INFO:Uploading results into container
2023-08-16 01:21:45,760:INFO:Uploading model into container now
2023-08-16 01:21:45,760:INFO:_master_model_container: 2
2023-08-16 01:21:45,760:INFO:_display_container: 2
2023-08-16 01:21:45,760:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-16 01:21:45,760:INFO:create_model() successfully completed......................................
2023-08-16 01:21:45,846:INFO:SubProcess create_model() end ==================================
2023-08-16 01:21:45,847:INFO:Creating metrics dataframe
2023-08-16 01:21:45,853:INFO:Initializing Naive Bayes
2023-08-16 01:21:45,853:INFO:Total runtime is 0.022341700394948323 minutes
2023-08-16 01:21:45,856:INFO:SubProcess create_model() called ==================================
2023-08-16 01:21:45,856:INFO:Initializing create_model()
2023-08-16 01:21:45,856:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B3F43040>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000195B352CBB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:21:45,856:INFO:Checking exceptions
2023-08-16 01:21:45,856:INFO:Importing libraries
2023-08-16 01:21:45,856:INFO:Copying training dataset
2023-08-16 01:21:45,861:INFO:Defining folds
2023-08-16 01:21:45,861:INFO:Declaring metric variables
2023-08-16 01:21:45,864:INFO:Importing untrained model
2023-08-16 01:21:45,867:INFO:Naive Bayes Imported successfully
2023-08-16 01:21:45,872:INFO:Starting cross validation
2023-08-16 01:21:45,873:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:21:46,247:INFO:Calculating mean and std
2023-08-16 01:21:46,249:INFO:Creating metrics dataframe
2023-08-16 01:21:46,291:INFO:Uploading results into container
2023-08-16 01:21:46,291:INFO:Uploading model into container now
2023-08-16 01:21:46,291:INFO:_master_model_container: 3
2023-08-16 01:21:46,292:INFO:_display_container: 2
2023-08-16 01:21:46,292:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-16 01:21:46,292:INFO:create_model() successfully completed......................................
2023-08-16 01:21:46,403:INFO:SubProcess create_model() end ==================================
2023-08-16 01:21:46,403:INFO:Creating metrics dataframe
2023-08-16 01:21:46,411:INFO:Initializing Decision Tree Classifier
2023-08-16 01:21:46,411:INFO:Total runtime is 0.031641805171966554 minutes
2023-08-16 01:21:46,414:INFO:SubProcess create_model() called ==================================
2023-08-16 01:21:46,414:INFO:Initializing create_model()
2023-08-16 01:21:46,414:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B3F43040>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000195B352CBB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:21:46,414:INFO:Checking exceptions
2023-08-16 01:21:46,414:INFO:Importing libraries
2023-08-16 01:21:46,414:INFO:Copying training dataset
2023-08-16 01:21:46,419:INFO:Defining folds
2023-08-16 01:21:46,419:INFO:Declaring metric variables
2023-08-16 01:21:46,422:INFO:Importing untrained model
2023-08-16 01:21:46,426:INFO:Decision Tree Classifier Imported successfully
2023-08-16 01:21:46,432:INFO:Starting cross validation
2023-08-16 01:21:46,433:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:21:46,801:INFO:Calculating mean and std
2023-08-16 01:21:46,803:INFO:Creating metrics dataframe
2023-08-16 01:21:46,843:INFO:Uploading results into container
2023-08-16 01:21:46,844:INFO:Uploading model into container now
2023-08-16 01:21:46,844:INFO:_master_model_container: 4
2023-08-16 01:21:46,844:INFO:_display_container: 2
2023-08-16 01:21:46,844:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-08-16 01:21:46,844:INFO:create_model() successfully completed......................................
2023-08-16 01:21:46,930:INFO:SubProcess create_model() end ==================================
2023-08-16 01:21:46,930:INFO:Creating metrics dataframe
2023-08-16 01:21:46,938:INFO:Initializing SVM - Linear Kernel
2023-08-16 01:21:46,938:INFO:Total runtime is 0.04041960636774699 minutes
2023-08-16 01:21:46,940:INFO:SubProcess create_model() called ==================================
2023-08-16 01:21:46,941:INFO:Initializing create_model()
2023-08-16 01:21:46,941:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B3F43040>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000195B352CBB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:21:46,941:INFO:Checking exceptions
2023-08-16 01:21:46,941:INFO:Importing libraries
2023-08-16 01:21:46,941:INFO:Copying training dataset
2023-08-16 01:21:46,945:INFO:Defining folds
2023-08-16 01:21:46,945:INFO:Declaring metric variables
2023-08-16 01:21:46,949:INFO:Importing untrained model
2023-08-16 01:21:46,952:INFO:SVM - Linear Kernel Imported successfully
2023-08-16 01:21:46,957:INFO:Starting cross validation
2023-08-16 01:21:46,958:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:21:47,027:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:21:47,038:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:21:47,040:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:21:47,053:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:21:47,059:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:21:47,063:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:21:47,066:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:21:47,066:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:21:47,072:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:21:47,076:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:21:47,309:INFO:Calculating mean and std
2023-08-16 01:21:47,310:INFO:Creating metrics dataframe
2023-08-16 01:21:47,351:INFO:Uploading results into container
2023-08-16 01:21:47,352:INFO:Uploading model into container now
2023-08-16 01:21:47,352:INFO:_master_model_container: 5
2023-08-16 01:21:47,352:INFO:_display_container: 2
2023-08-16 01:21:47,353:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-16 01:21:47,353:INFO:create_model() successfully completed......................................
2023-08-16 01:21:47,424:INFO:SubProcess create_model() end ==================================
2023-08-16 01:21:47,424:INFO:Creating metrics dataframe
2023-08-16 01:21:47,431:INFO:Initializing Ridge Classifier
2023-08-16 01:21:47,431:INFO:Total runtime is 0.04863150119781494 minutes
2023-08-16 01:21:47,434:INFO:SubProcess create_model() called ==================================
2023-08-16 01:21:47,435:INFO:Initializing create_model()
2023-08-16 01:21:47,435:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B3F43040>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000195B352CBB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:21:47,435:INFO:Checking exceptions
2023-08-16 01:21:47,435:INFO:Importing libraries
2023-08-16 01:21:47,435:INFO:Copying training dataset
2023-08-16 01:21:47,440:INFO:Defining folds
2023-08-16 01:21:47,440:INFO:Declaring metric variables
2023-08-16 01:21:47,443:INFO:Importing untrained model
2023-08-16 01:21:47,446:INFO:Ridge Classifier Imported successfully
2023-08-16 01:21:47,451:INFO:Starting cross validation
2023-08-16 01:21:47,451:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:21:47,505:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:21:47,519:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:21:47,522:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:21:47,523:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:21:47,526:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:21:47,537:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:21:47,537:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:21:47,548:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:21:47,553:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:21:47,554:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:21:47,833:INFO:Calculating mean and std
2023-08-16 01:21:47,835:INFO:Creating metrics dataframe
2023-08-16 01:21:47,867:INFO:Uploading results into container
2023-08-16 01:21:47,868:INFO:Uploading model into container now
2023-08-16 01:21:47,868:INFO:_master_model_container: 6
2023-08-16 01:21:47,868:INFO:_display_container: 2
2023-08-16 01:21:47,869:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=123, solver='auto', tol=0.001)
2023-08-16 01:21:47,869:INFO:create_model() successfully completed......................................
2023-08-16 01:21:47,950:INFO:SubProcess create_model() end ==================================
2023-08-16 01:21:47,950:INFO:Creating metrics dataframe
2023-08-16 01:21:47,957:INFO:Initializing Random Forest Classifier
2023-08-16 01:21:47,957:INFO:Total runtime is 0.05739818016688029 minutes
2023-08-16 01:21:47,959:INFO:SubProcess create_model() called ==================================
2023-08-16 01:21:47,959:INFO:Initializing create_model()
2023-08-16 01:21:47,960:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B3F43040>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000195B352CBB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:21:47,960:INFO:Checking exceptions
2023-08-16 01:21:47,960:INFO:Importing libraries
2023-08-16 01:21:47,960:INFO:Copying training dataset
2023-08-16 01:21:47,965:INFO:Defining folds
2023-08-16 01:21:47,965:INFO:Declaring metric variables
2023-08-16 01:21:47,967:INFO:Importing untrained model
2023-08-16 01:21:47,970:INFO:Random Forest Classifier Imported successfully
2023-08-16 01:21:47,974:INFO:Starting cross validation
2023-08-16 01:21:47,975:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:21:48,956:INFO:Calculating mean and std
2023-08-16 01:21:48,957:INFO:Creating metrics dataframe
2023-08-16 01:21:49,000:INFO:Uploading results into container
2023-08-16 01:21:49,001:INFO:Uploading model into container now
2023-08-16 01:21:49,001:INFO:_master_model_container: 7
2023-08-16 01:21:49,001:INFO:_display_container: 2
2023-08-16 01:21:49,002:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-08-16 01:21:49,002:INFO:create_model() successfully completed......................................
2023-08-16 01:21:49,081:INFO:SubProcess create_model() end ==================================
2023-08-16 01:21:49,081:INFO:Creating metrics dataframe
2023-08-16 01:21:49,089:INFO:Initializing Quadratic Discriminant Analysis
2023-08-16 01:21:49,089:INFO:Total runtime is 0.0762738029162089 minutes
2023-08-16 01:21:49,092:INFO:SubProcess create_model() called ==================================
2023-08-16 01:21:49,092:INFO:Initializing create_model()
2023-08-16 01:21:49,092:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B3F43040>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000195B352CBB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:21:49,092:INFO:Checking exceptions
2023-08-16 01:21:49,092:INFO:Importing libraries
2023-08-16 01:21:49,092:INFO:Copying training dataset
2023-08-16 01:21:49,098:INFO:Defining folds
2023-08-16 01:21:49,098:INFO:Declaring metric variables
2023-08-16 01:21:49,101:INFO:Importing untrained model
2023-08-16 01:21:49,104:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-16 01:21:49,108:INFO:Starting cross validation
2023-08-16 01:21:49,109:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:21:49,148:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:21:49,155:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:21:49,171:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:21:49,171:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:21:49,172:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:21:49,172:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:21:49,172:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:21:49,173:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:21:49,181:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:21:49,181:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:21:49,182:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:21:49,184:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:21:49,192:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:21:49,193:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:21:49,194:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:21:49,197:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:21:49,197:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:21:49,198:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:21:49,198:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:21:49,198:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:21:49,198:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:21:49,199:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:21:49,199:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:21:49,199:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:21:49,202:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:21:49,203:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:21:49,203:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:21:49,203:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:21:49,204:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:21:49,205:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:21:49,205:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:21:49,205:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:21:49,205:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:21:49,206:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:21:49,207:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:21:49,207:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:21:49,208:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:21:49,209:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:21:49,210:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:21:49,212:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:21:49,215:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:21:49,216:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:21:49,218:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:21:49,218:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:21:49,219:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:21:49,219:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:21:49,219:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:21:49,219:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:21:49,220:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:21:49,220:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:21:49,220:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:21:49,220:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:21:49,220:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:21:49,220:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:21:49,221:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:21:49,222:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:21:49,222:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:21:49,222:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:21:49,222:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:21:49,222:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:21:49,222:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:21:49,222:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:21:49,225:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:21:49,225:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:21:49,225:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:21:49,230:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:21:49,233:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:21:49,233:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:21:49,233:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:21:49,233:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:21:49,233:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:21:49,234:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:21:49,235:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:21:49,235:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:21:49,235:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:21:49,236:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:21:49,237:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:21:49,237:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:21:49,237:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:21:49,237:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:21:49,238:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:21:49,239:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:21:49,239:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:21:49,242:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:21:49,246:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:21:49,246:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:21:49,246:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:21:49,248:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:21:49,250:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:21:49,525:INFO:Calculating mean and std
2023-08-16 01:21:49,526:INFO:Creating metrics dataframe
2023-08-16 01:21:49,563:INFO:Uploading results into container
2023-08-16 01:21:49,564:INFO:Uploading model into container now
2023-08-16 01:21:49,564:INFO:_master_model_container: 8
2023-08-16 01:21:49,564:INFO:_display_container: 2
2023-08-16 01:21:49,564:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-16 01:21:49,564:INFO:create_model() successfully completed......................................
2023-08-16 01:21:49,634:INFO:SubProcess create_model() end ==================================
2023-08-16 01:21:49,634:INFO:Creating metrics dataframe
2023-08-16 01:21:49,642:INFO:Initializing Ada Boost Classifier
2023-08-16 01:21:49,642:INFO:Total runtime is 0.08547905286153157 minutes
2023-08-16 01:21:49,644:INFO:SubProcess create_model() called ==================================
2023-08-16 01:21:49,644:INFO:Initializing create_model()
2023-08-16 01:21:49,644:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B3F43040>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000195B352CBB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:21:49,644:INFO:Checking exceptions
2023-08-16 01:21:49,645:INFO:Importing libraries
2023-08-16 01:21:49,645:INFO:Copying training dataset
2023-08-16 01:21:49,650:INFO:Defining folds
2023-08-16 01:21:49,650:INFO:Declaring metric variables
2023-08-16 01:21:49,652:INFO:Importing untrained model
2023-08-16 01:21:49,655:INFO:Ada Boost Classifier Imported successfully
2023-08-16 01:21:49,660:INFO:Starting cross validation
2023-08-16 01:21:49,661:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:21:50,382:INFO:Calculating mean and std
2023-08-16 01:21:50,383:INFO:Creating metrics dataframe
2023-08-16 01:21:50,424:INFO:Uploading results into container
2023-08-16 01:21:50,425:INFO:Uploading model into container now
2023-08-16 01:21:50,426:INFO:_master_model_container: 9
2023-08-16 01:21:50,426:INFO:_display_container: 2
2023-08-16 01:21:50,426:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2023-08-16 01:21:50,426:INFO:create_model() successfully completed......................................
2023-08-16 01:21:50,511:INFO:SubProcess create_model() end ==================================
2023-08-16 01:21:50,512:INFO:Creating metrics dataframe
2023-08-16 01:21:50,519:INFO:Initializing Gradient Boosting Classifier
2023-08-16 01:21:50,519:INFO:Total runtime is 0.10010679960250854 minutes
2023-08-16 01:21:50,523:INFO:SubProcess create_model() called ==================================
2023-08-16 01:21:50,523:INFO:Initializing create_model()
2023-08-16 01:21:50,523:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B3F43040>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000195B352CBB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:21:50,524:INFO:Checking exceptions
2023-08-16 01:21:50,524:INFO:Importing libraries
2023-08-16 01:21:50,524:INFO:Copying training dataset
2023-08-16 01:21:50,530:INFO:Defining folds
2023-08-16 01:21:50,530:INFO:Declaring metric variables
2023-08-16 01:21:50,533:INFO:Importing untrained model
2023-08-16 01:21:50,536:INFO:Gradient Boosting Classifier Imported successfully
2023-08-16 01:21:50,541:INFO:Starting cross validation
2023-08-16 01:21:50,543:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:21:51,365:INFO:Calculating mean and std
2023-08-16 01:21:51,366:INFO:Creating metrics dataframe
2023-08-16 01:21:51,414:INFO:Uploading results into container
2023-08-16 01:21:51,414:INFO:Uploading model into container now
2023-08-16 01:21:51,415:INFO:_master_model_container: 10
2023-08-16 01:21:51,415:INFO:_display_container: 2
2023-08-16 01:21:51,415:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-16 01:21:51,415:INFO:create_model() successfully completed......................................
2023-08-16 01:21:51,490:INFO:SubProcess create_model() end ==================================
2023-08-16 01:21:51,490:INFO:Creating metrics dataframe
2023-08-16 01:21:51,498:INFO:Initializing Linear Discriminant Analysis
2023-08-16 01:21:51,498:INFO:Total runtime is 0.11642333269119262 minutes
2023-08-16 01:21:51,501:INFO:SubProcess create_model() called ==================================
2023-08-16 01:21:51,501:INFO:Initializing create_model()
2023-08-16 01:21:51,501:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B3F43040>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000195B352CBB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:21:51,501:INFO:Checking exceptions
2023-08-16 01:21:51,501:INFO:Importing libraries
2023-08-16 01:21:51,501:INFO:Copying training dataset
2023-08-16 01:21:51,507:INFO:Defining folds
2023-08-16 01:21:51,507:INFO:Declaring metric variables
2023-08-16 01:21:51,510:INFO:Importing untrained model
2023-08-16 01:21:51,512:INFO:Linear Discriminant Analysis Imported successfully
2023-08-16 01:21:51,516:INFO:Starting cross validation
2023-08-16 01:21:51,517:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:21:51,968:INFO:Calculating mean and std
2023-08-16 01:21:51,970:INFO:Creating metrics dataframe
2023-08-16 01:21:52,017:INFO:Uploading results into container
2023-08-16 01:21:52,017:INFO:Uploading model into container now
2023-08-16 01:21:52,018:INFO:_master_model_container: 11
2023-08-16 01:21:52,018:INFO:_display_container: 2
2023-08-16 01:21:52,018:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-16 01:21:52,018:INFO:create_model() successfully completed......................................
2023-08-16 01:21:52,089:INFO:SubProcess create_model() end ==================================
2023-08-16 01:21:52,090:INFO:Creating metrics dataframe
2023-08-16 01:21:52,097:INFO:Initializing Extra Trees Classifier
2023-08-16 01:21:52,097:INFO:Total runtime is 0.1264038840929667 minutes
2023-08-16 01:21:52,099:INFO:SubProcess create_model() called ==================================
2023-08-16 01:21:52,099:INFO:Initializing create_model()
2023-08-16 01:21:52,099:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B3F43040>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000195B352CBB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:21:52,099:INFO:Checking exceptions
2023-08-16 01:21:52,100:INFO:Importing libraries
2023-08-16 01:21:52,100:INFO:Copying training dataset
2023-08-16 01:21:52,105:INFO:Defining folds
2023-08-16 01:21:52,105:INFO:Declaring metric variables
2023-08-16 01:21:52,107:INFO:Importing untrained model
2023-08-16 01:21:52,110:INFO:Extra Trees Classifier Imported successfully
2023-08-16 01:21:52,114:INFO:Starting cross validation
2023-08-16 01:21:52,114:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:21:53,171:INFO:Calculating mean and std
2023-08-16 01:21:53,173:INFO:Creating metrics dataframe
2023-08-16 01:21:53,220:INFO:Uploading results into container
2023-08-16 01:21:53,220:INFO:Uploading model into container now
2023-08-16 01:21:53,221:INFO:_master_model_container: 12
2023-08-16 01:21:53,221:INFO:_display_container: 2
2023-08-16 01:21:53,221:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-08-16 01:21:53,221:INFO:create_model() successfully completed......................................
2023-08-16 01:21:53,292:INFO:SubProcess create_model() end ==================================
2023-08-16 01:21:53,292:INFO:Creating metrics dataframe
2023-08-16 01:21:53,304:INFO:Initializing Light Gradient Boosting Machine
2023-08-16 01:21:53,304:INFO:Total runtime is 0.14652493000030517 minutes
2023-08-16 01:21:53,307:INFO:SubProcess create_model() called ==================================
2023-08-16 01:21:53,307:INFO:Initializing create_model()
2023-08-16 01:21:53,307:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B3F43040>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000195B352CBB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:21:53,307:INFO:Checking exceptions
2023-08-16 01:21:53,307:INFO:Importing libraries
2023-08-16 01:21:53,307:INFO:Copying training dataset
2023-08-16 01:21:53,312:INFO:Defining folds
2023-08-16 01:21:53,312:INFO:Declaring metric variables
2023-08-16 01:21:53,315:INFO:Importing untrained model
2023-08-16 01:21:53,318:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-16 01:21:53,322:INFO:Starting cross validation
2023-08-16 01:21:53,322:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:21:54,718:INFO:Calculating mean and std
2023-08-16 01:21:54,719:INFO:Creating metrics dataframe
2023-08-16 01:21:54,771:INFO:Uploading results into container
2023-08-16 01:21:54,772:INFO:Uploading model into container now
2023-08-16 01:21:54,772:INFO:_master_model_container: 13
2023-08-16 01:21:54,772:INFO:_display_container: 2
2023-08-16 01:21:54,773:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-16 01:21:54,773:INFO:create_model() successfully completed......................................
2023-08-16 01:21:54,847:INFO:SubProcess create_model() end ==================================
2023-08-16 01:21:54,847:INFO:Creating metrics dataframe
2023-08-16 01:21:54,855:INFO:Initializing Dummy Classifier
2023-08-16 01:21:54,856:INFO:Total runtime is 0.17238253752390542 minutes
2023-08-16 01:21:54,858:INFO:SubProcess create_model() called ==================================
2023-08-16 01:21:54,858:INFO:Initializing create_model()
2023-08-16 01:21:54,858:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B3F43040>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000195B352CBB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:21:54,859:INFO:Checking exceptions
2023-08-16 01:21:54,859:INFO:Importing libraries
2023-08-16 01:21:54,859:INFO:Copying training dataset
2023-08-16 01:21:54,864:INFO:Defining folds
2023-08-16 01:21:54,864:INFO:Declaring metric variables
2023-08-16 01:21:54,867:INFO:Importing untrained model
2023-08-16 01:21:54,870:INFO:Dummy Classifier Imported successfully
2023-08-16 01:21:54,874:INFO:Starting cross validation
2023-08-16 01:21:54,875:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:21:54,950:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:21:54,962:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:21:54,963:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:21:54,968:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:21:54,979:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:21:54,985:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:21:54,985:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:21:54,988:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:21:54,992:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:21:54,993:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:21:55,409:INFO:Calculating mean and std
2023-08-16 01:21:55,411:INFO:Creating metrics dataframe
2023-08-16 01:21:55,470:INFO:Uploading results into container
2023-08-16 01:21:55,470:INFO:Uploading model into container now
2023-08-16 01:21:55,471:INFO:_master_model_container: 14
2023-08-16 01:21:55,471:INFO:_display_container: 2
2023-08-16 01:21:55,471:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-08-16 01:21:55,471:INFO:create_model() successfully completed......................................
2023-08-16 01:21:55,570:INFO:SubProcess create_model() end ==================================
2023-08-16 01:21:55,570:INFO:Creating metrics dataframe
2023-08-16 01:21:55,588:INFO:Initializing create_model()
2023-08-16 01:21:55,588:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B3F43040>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:21:55,588:INFO:Checking exceptions
2023-08-16 01:21:55,590:INFO:Importing libraries
2023-08-16 01:21:55,590:INFO:Copying training dataset
2023-08-16 01:21:55,596:INFO:Defining folds
2023-08-16 01:21:55,596:INFO:Declaring metric variables
2023-08-16 01:21:55,596:INFO:Importing untrained model
2023-08-16 01:21:55,596:INFO:Declaring custom model
2023-08-16 01:21:55,597:INFO:Gradient Boosting Classifier Imported successfully
2023-08-16 01:21:55,599:INFO:Cross validation set to False
2023-08-16 01:21:55,599:INFO:Fitting Model
2023-08-16 01:21:55,914:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-16 01:21:55,914:INFO:create_model() successfully completed......................................
2023-08-16 01:21:56,012:INFO:_master_model_container: 14
2023-08-16 01:21:56,012:INFO:_display_container: 2
2023-08-16 01:21:56,012:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-16 01:21:56,013:INFO:compare_models() successfully completed......................................
2023-08-16 01:22:17,572:INFO:Initializing plot_model()
2023-08-16 01:22:17,573:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B3F43040>, system=True)
2023-08-16 01:22:17,573:INFO:Checking exceptions
2023-08-16 01:22:17,578:INFO:Preloading libraries
2023-08-16 01:22:17,584:INFO:Copying training dataset
2023-08-16 01:22:17,584:INFO:Plot type: confusion_matrix
2023-08-16 01:22:17,662:INFO:Fitting Model
2023-08-16 01:22:17,662:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2023-08-16 01:22:17,662:INFO:Scoring test/hold-out set
2023-08-16 01:22:17,746:INFO:Visual Rendered Successfully
2023-08-16 01:22:17,840:INFO:plot_model() successfully completed......................................
2023-08-16 01:22:25,990:INFO:Initializing plot_model()
2023-08-16 01:22:25,990:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B3F43040>, system=True)
2023-08-16 01:22:25,990:INFO:Checking exceptions
2023-08-16 01:22:25,995:INFO:Preloading libraries
2023-08-16 01:22:26,001:INFO:Copying training dataset
2023-08-16 01:22:26,001:INFO:Plot type: auc
2023-08-16 01:22:26,052:INFO:Fitting Model
2023-08-16 01:22:26,053:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2023-08-16 01:22:26,053:INFO:Scoring test/hold-out set
2023-08-16 01:22:26,163:INFO:Visual Rendered Successfully
2023-08-16 01:22:26,252:INFO:plot_model() successfully completed......................................
2023-08-16 01:23:34,886:INFO:Initializing plot_model()
2023-08-16 01:23:34,886:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B3F43040>, system=True)
2023-08-16 01:23:34,886:INFO:Checking exceptions
2023-08-16 01:23:34,891:INFO:Preloading libraries
2023-08-16 01:23:34,896:INFO:Copying training dataset
2023-08-16 01:23:34,896:INFO:Plot type: feature
2023-08-16 01:23:34,897:WARNING:No coef_ found. Trying feature_importances_
2023-08-16 01:23:35,010:INFO:Visual Rendered Successfully
2023-08-16 01:23:35,076:INFO:plot_model() successfully completed......................................
2023-08-16 01:25:04,630:INFO:Initializing plot_model()
2023-08-16 01:25:04,630:INFO:plot_model(plot=accuracy, fold=None, verbose=True, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000195B3F43040>, system=True)
2023-08-16 01:25:04,630:INFO:Checking exceptions
2023-08-16 01:29:30,231:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-16 01:29:30,231:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-16 01:29:30,231:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-16 01:29:30,231:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-16 01:35:26,574:INFO:PyCaret ClassificationExperiment
2023-08-16 01:35:26,574:INFO:Logging name: clf-default-name
2023-08-16 01:35:26,574:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-16 01:35:26,574:INFO:version 3.0.4
2023-08-16 01:35:26,575:INFO:Initializing setup()
2023-08-16 01:35:26,575:INFO:self.USI: 3bc1
2023-08-16 01:35:26,575:INFO:self._variable_keys: {'logging_param', '_ml_usecase', 'n_jobs_param', 'exp_id', 'y_train', 'idx', 'fold_generator', 'memory', 'data', 'pipeline', 'fold_groups_param', 'fix_imbalance', 'USI', 'gpu_param', 'exp_name_log', 'gpu_n_jobs_param', 'X_train', 'X_test', 'X', 'y_test', '_available_plots', 'target_param', 'html_param', 'is_multiclass', 'fold_shuffle_param', 'log_plots_param', 'seed', 'y'}
2023-08-16 01:35:26,575:INFO:Checking environment
2023-08-16 01:35:26,575:INFO:python_version: 3.9.13
2023-08-16 01:35:26,575:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-08-16 01:35:26,575:INFO:machine: AMD64
2023-08-16 01:35:26,575:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-16 01:35:26,575:INFO:Memory: svmem(total=16905969664, available=3598360576, percent=78.7, used=13307609088, free=3598360576)
2023-08-16 01:35:26,575:INFO:Physical Core: 8
2023-08-16 01:35:26,575:INFO:Logical Core: 16
2023-08-16 01:35:26,575:INFO:Checking libraries
2023-08-16 01:35:26,575:INFO:System:
2023-08-16 01:35:26,575:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-08-16 01:35:26,576:INFO:executable: c:\Users\lmacciomaretto\anaconda3\python.exe
2023-08-16 01:35:26,576:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-16 01:35:26,576:INFO:PyCaret required dependencies:
2023-08-16 01:35:26,721:INFO:                 pip: 22.2.2
2023-08-16 01:35:26,721:INFO:          setuptools: 63.4.1
2023-08-16 01:35:26,721:INFO:             pycaret: 3.0.4
2023-08-16 01:35:26,721:INFO:             IPython: 7.31.1
2023-08-16 01:35:26,721:INFO:          ipywidgets: 7.6.5
2023-08-16 01:35:26,721:INFO:                tqdm: 4.64.1
2023-08-16 01:35:26,721:INFO:               numpy: 1.21.5
2023-08-16 01:35:26,721:INFO:              pandas: 1.4.4
2023-08-16 01:35:26,721:INFO:              jinja2: 2.11.3
2023-08-16 01:35:26,721:INFO:               scipy: 1.9.1
2023-08-16 01:35:26,721:INFO:              joblib: 1.3.2
2023-08-16 01:35:26,721:INFO:             sklearn: 1.0.2
2023-08-16 01:35:26,721:INFO:                pyod: 1.1.0
2023-08-16 01:35:26,721:INFO:            imblearn: 0.11.0
2023-08-16 01:35:26,722:INFO:   category_encoders: 2.6.2
2023-08-16 01:35:26,722:INFO:            lightgbm: 4.0.0
2023-08-16 01:35:26,722:INFO:               numba: 0.55.1
2023-08-16 01:35:26,722:INFO:            requests: 2.28.1
2023-08-16 01:35:26,722:INFO:          matplotlib: 3.5.2
2023-08-16 01:35:26,722:INFO:          scikitplot: 0.3.7
2023-08-16 01:35:26,722:INFO:         yellowbrick: 1.5
2023-08-16 01:35:26,722:INFO:              plotly: 5.9.0
2023-08-16 01:35:26,722:INFO:    plotly-resampler: Not installed
2023-08-16 01:35:26,722:INFO:             kaleido: 0.2.1
2023-08-16 01:35:26,722:INFO:           schemdraw: 0.15
2023-08-16 01:35:26,722:INFO:         statsmodels: 0.13.2
2023-08-16 01:35:26,722:INFO:              sktime: 0.21.0
2023-08-16 01:35:26,722:INFO:               tbats: 1.1.3
2023-08-16 01:35:26,722:INFO:            pmdarima: 2.0.3
2023-08-16 01:35:26,722:INFO:              psutil: 5.9.0
2023-08-16 01:35:26,722:INFO:          markupsafe: 2.0.1
2023-08-16 01:35:26,722:INFO:             pickle5: Not installed
2023-08-16 01:35:26,722:INFO:         cloudpickle: 2.0.0
2023-08-16 01:35:26,722:INFO:         deprecation: 2.1.0
2023-08-16 01:35:26,722:INFO:              xxhash: 3.3.0
2023-08-16 01:35:26,722:INFO:           wurlitzer: Not installed
2023-08-16 01:35:26,722:INFO:PyCaret optional dependencies:
2023-08-16 01:35:26,731:INFO:                shap: Not installed
2023-08-16 01:35:26,731:INFO:           interpret: Not installed
2023-08-16 01:35:26,731:INFO:                umap: Not installed
2023-08-16 01:35:26,731:INFO:    pandas_profiling: Not installed
2023-08-16 01:35:26,731:INFO:  explainerdashboard: Not installed
2023-08-16 01:35:26,731:INFO:             autoviz: Not installed
2023-08-16 01:35:26,731:INFO:           fairlearn: Not installed
2023-08-16 01:35:26,731:INFO:          deepchecks: Not installed
2023-08-16 01:35:26,731:INFO:             xgboost: Not installed
2023-08-16 01:35:26,731:INFO:            catboost: Not installed
2023-08-16 01:35:26,731:INFO:              kmodes: Not installed
2023-08-16 01:35:26,731:INFO:             mlxtend: Not installed
2023-08-16 01:35:26,731:INFO:       statsforecast: Not installed
2023-08-16 01:35:26,731:INFO:        tune_sklearn: Not installed
2023-08-16 01:35:26,731:INFO:                 ray: Not installed
2023-08-16 01:35:26,731:INFO:            hyperopt: Not installed
2023-08-16 01:35:26,731:INFO:              optuna: Not installed
2023-08-16 01:35:26,731:INFO:               skopt: Not installed
2023-08-16 01:35:26,731:INFO:              mlflow: Not installed
2023-08-16 01:35:26,731:INFO:              gradio: Not installed
2023-08-16 01:35:26,731:INFO:             fastapi: Not installed
2023-08-16 01:35:26,731:INFO:             uvicorn: Not installed
2023-08-16 01:35:26,731:INFO:              m2cgen: Not installed
2023-08-16 01:35:26,731:INFO:           evidently: Not installed
2023-08-16 01:35:26,731:INFO:               fugue: Not installed
2023-08-16 01:35:26,731:INFO:           streamlit: Not installed
2023-08-16 01:35:26,731:INFO:             prophet: Not installed
2023-08-16 01:35:26,731:INFO:None
2023-08-16 01:35:26,732:INFO:Set up data.
2023-08-16 01:35:26,739:INFO:Set up train/test split.
2023-08-16 01:35:26,745:INFO:Set up index.
2023-08-16 01:35:26,745:INFO:Set up folding strategy.
2023-08-16 01:35:26,745:INFO:Assigning column types.
2023-08-16 01:35:26,748:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-16 01:35:26,781:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-16 01:35:26,782:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:35:26,808:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:35:26,809:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:35:26,841:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-16 01:35:26,842:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:35:26,862:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:35:26,862:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:35:26,862:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-16 01:35:26,895:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:35:26,916:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:35:26,916:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:35:26,950:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:35:26,970:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:35:26,970:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:35:26,970:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-16 01:35:27,024:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:35:27,025:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:35:27,079:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:35:27,079:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:35:27,082:INFO:Preparing preprocessing pipeline...
2023-08-16 01:35:27,083:INFO:Set up simple imputation.
2023-08-16 01:35:27,099:INFO:Finished creating preprocessing pipeline.
2023-08-16 01:35:27,104:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\LMACCI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['CATAG3', 'HEALTH2', 'ANYHLTI2',
                                             'INCOME', 'POVERTY3', 'TOBFLAG',
                                             'MRJFLAG', 'PYUD5MRJ', 'MJYRTOT',
                                             'ALCFLAG', 'COCFLAG', 'CRKFLAG',
                                             'HERFLAG', 'LSDFLAG',
                                             'METHAMFLAG'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose=0))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose=0)))],
         verbose=False)
2023-08-16 01:35:27,104:INFO:Creating final display dataframe.
2023-08-16 01:35:27,156:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          ADSMMDEA
2                   Target type            Binary
3           Original data shape       (12654, 16)
4        Transformed data shape       (12654, 16)
5   Transformed train set shape        (8857, 16)
6    Transformed test set shape        (3797, 16)
7              Numeric features                15
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              3bc1
2023-08-16 01:35:27,219:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:35:27,219:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:35:27,277:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:35:27,278:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:35:27,278:INFO:setup() successfully completed in 0.74s...............
2023-08-16 01:35:56,617:INFO:PyCaret ClassificationExperiment
2023-08-16 01:35:56,617:INFO:Logging name: clf-default-name
2023-08-16 01:35:56,617:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-16 01:35:56,617:INFO:version 3.0.4
2023-08-16 01:35:56,617:INFO:Initializing setup()
2023-08-16 01:35:56,617:INFO:self.USI: a622
2023-08-16 01:35:56,617:INFO:self._variable_keys: {'logging_param', '_ml_usecase', 'n_jobs_param', 'exp_id', 'y_train', 'idx', 'fold_generator', 'memory', 'data', 'pipeline', 'fold_groups_param', 'fix_imbalance', 'USI', 'gpu_param', 'exp_name_log', 'gpu_n_jobs_param', 'X_train', 'X_test', 'X', 'y_test', '_available_plots', 'target_param', 'html_param', 'is_multiclass', 'fold_shuffle_param', 'log_plots_param', 'seed', 'y'}
2023-08-16 01:35:56,617:INFO:Checking environment
2023-08-16 01:35:56,617:INFO:python_version: 3.9.13
2023-08-16 01:35:56,617:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-08-16 01:35:56,617:INFO:machine: AMD64
2023-08-16 01:35:56,617:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-16 01:35:56,617:INFO:Memory: svmem(total=16905969664, available=3543678976, percent=79.0, used=13362290688, free=3543678976)
2023-08-16 01:35:56,617:INFO:Physical Core: 8
2023-08-16 01:35:56,617:INFO:Logical Core: 16
2023-08-16 01:35:56,617:INFO:Checking libraries
2023-08-16 01:35:56,617:INFO:System:
2023-08-16 01:35:56,617:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-08-16 01:35:56,617:INFO:executable: c:\Users\lmacciomaretto\anaconda3\python.exe
2023-08-16 01:35:56,617:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-16 01:35:56,618:INFO:PyCaret required dependencies:
2023-08-16 01:35:56,618:INFO:                 pip: 22.2.2
2023-08-16 01:35:56,618:INFO:          setuptools: 63.4.1
2023-08-16 01:35:56,618:INFO:             pycaret: 3.0.4
2023-08-16 01:35:56,618:INFO:             IPython: 7.31.1
2023-08-16 01:35:56,618:INFO:          ipywidgets: 7.6.5
2023-08-16 01:35:56,618:INFO:                tqdm: 4.64.1
2023-08-16 01:35:56,618:INFO:               numpy: 1.21.5
2023-08-16 01:35:56,618:INFO:              pandas: 1.4.4
2023-08-16 01:35:56,618:INFO:              jinja2: 2.11.3
2023-08-16 01:35:56,618:INFO:               scipy: 1.9.1
2023-08-16 01:35:56,618:INFO:              joblib: 1.3.2
2023-08-16 01:35:56,618:INFO:             sklearn: 1.0.2
2023-08-16 01:35:56,618:INFO:                pyod: 1.1.0
2023-08-16 01:35:56,618:INFO:            imblearn: 0.11.0
2023-08-16 01:35:56,618:INFO:   category_encoders: 2.6.2
2023-08-16 01:35:56,618:INFO:            lightgbm: 4.0.0
2023-08-16 01:35:56,618:INFO:               numba: 0.55.1
2023-08-16 01:35:56,618:INFO:            requests: 2.28.1
2023-08-16 01:35:56,618:INFO:          matplotlib: 3.5.2
2023-08-16 01:35:56,618:INFO:          scikitplot: 0.3.7
2023-08-16 01:35:56,618:INFO:         yellowbrick: 1.5
2023-08-16 01:35:56,618:INFO:              plotly: 5.9.0
2023-08-16 01:35:56,618:INFO:    plotly-resampler: Not installed
2023-08-16 01:35:56,618:INFO:             kaleido: 0.2.1
2023-08-16 01:35:56,618:INFO:           schemdraw: 0.15
2023-08-16 01:35:56,618:INFO:         statsmodels: 0.13.2
2023-08-16 01:35:56,618:INFO:              sktime: 0.21.0
2023-08-16 01:35:56,618:INFO:               tbats: 1.1.3
2023-08-16 01:35:56,618:INFO:            pmdarima: 2.0.3
2023-08-16 01:35:56,618:INFO:              psutil: 5.9.0
2023-08-16 01:35:56,618:INFO:          markupsafe: 2.0.1
2023-08-16 01:35:56,618:INFO:             pickle5: Not installed
2023-08-16 01:35:56,618:INFO:         cloudpickle: 2.0.0
2023-08-16 01:35:56,618:INFO:         deprecation: 2.1.0
2023-08-16 01:35:56,618:INFO:              xxhash: 3.3.0
2023-08-16 01:35:56,618:INFO:           wurlitzer: Not installed
2023-08-16 01:35:56,618:INFO:PyCaret optional dependencies:
2023-08-16 01:35:56,618:INFO:                shap: Not installed
2023-08-16 01:35:56,618:INFO:           interpret: Not installed
2023-08-16 01:35:56,618:INFO:                umap: Not installed
2023-08-16 01:35:56,618:INFO:    pandas_profiling: Not installed
2023-08-16 01:35:56,619:INFO:  explainerdashboard: Not installed
2023-08-16 01:35:56,619:INFO:             autoviz: Not installed
2023-08-16 01:35:56,619:INFO:           fairlearn: Not installed
2023-08-16 01:35:56,619:INFO:          deepchecks: Not installed
2023-08-16 01:35:56,619:INFO:             xgboost: Not installed
2023-08-16 01:35:56,619:INFO:            catboost: Not installed
2023-08-16 01:35:56,619:INFO:              kmodes: Not installed
2023-08-16 01:35:56,619:INFO:             mlxtend: Not installed
2023-08-16 01:35:56,619:INFO:       statsforecast: Not installed
2023-08-16 01:35:56,619:INFO:        tune_sklearn: Not installed
2023-08-16 01:35:56,619:INFO:                 ray: Not installed
2023-08-16 01:35:56,619:INFO:            hyperopt: Not installed
2023-08-16 01:35:56,619:INFO:              optuna: Not installed
2023-08-16 01:35:56,619:INFO:               skopt: Not installed
2023-08-16 01:35:56,619:INFO:              mlflow: Not installed
2023-08-16 01:35:56,619:INFO:              gradio: Not installed
2023-08-16 01:35:56,619:INFO:             fastapi: Not installed
2023-08-16 01:35:56,619:INFO:             uvicorn: Not installed
2023-08-16 01:35:56,619:INFO:              m2cgen: Not installed
2023-08-16 01:35:56,619:INFO:           evidently: Not installed
2023-08-16 01:35:56,619:INFO:               fugue: Not installed
2023-08-16 01:35:56,619:INFO:           streamlit: Not installed
2023-08-16 01:35:56,619:INFO:             prophet: Not installed
2023-08-16 01:35:56,619:INFO:None
2023-08-16 01:35:56,619:INFO:Set up data.
2023-08-16 01:35:56,625:INFO:Set up train/test split.
2023-08-16 01:35:56,631:INFO:Set up index.
2023-08-16 01:35:56,631:INFO:Set up folding strategy.
2023-08-16 01:35:56,632:INFO:Assigning column types.
2023-08-16 01:35:56,635:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-16 01:35:56,667:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-16 01:35:56,668:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:35:56,688:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:35:56,688:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:35:56,721:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-16 01:35:56,722:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:35:56,742:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:35:56,742:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:35:56,742:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-16 01:35:56,775:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:35:56,795:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:35:56,796:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:35:56,831:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:35:56,851:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:35:56,851:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:35:56,851:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-16 01:35:56,906:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:35:56,906:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:35:56,960:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:35:56,960:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:35:56,961:INFO:Preparing preprocessing pipeline...
2023-08-16 01:35:56,963:INFO:Set up simple imputation.
2023-08-16 01:35:56,978:INFO:Finished creating preprocessing pipeline.
2023-08-16 01:35:56,980:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\LMACCI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['CATAG3', 'HEALTH2', 'ANYHLTI2',
                                             'INCOME', 'POVERTY3', 'TOBFLAG',
                                             'MRJFLAG', 'PYUD5MRJ', 'MJYRTOT',
                                             'ALCFLAG', 'COCFLAG', 'CRKFLAG',
                                             'HERFLAG', 'LSDFLAG',
                                             'METHAMFLAG'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose=0))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose=0)))],
         verbose=False)
2023-08-16 01:35:56,981:INFO:Creating final display dataframe.
2023-08-16 01:35:57,030:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          ADSMMDEA
2                   Target type            Binary
3           Original data shape       (12654, 16)
4        Transformed data shape       (12654, 16)
5   Transformed train set shape        (8857, 16)
6    Transformed test set shape        (3797, 16)
7              Numeric features                15
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              a622
2023-08-16 01:35:57,091:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:35:57,092:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:35:57,148:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:35:57,148:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:35:57,148:INFO:setup() successfully completed in 0.57s...............
2023-08-16 01:36:01,543:INFO:Initializing compare_models()
2023-08-16 01:36:01,543:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586C67D7F0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002586C67D7F0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-16 01:36:01,543:INFO:Checking exceptions
2023-08-16 01:36:01,548:INFO:Preparing display monitor
2023-08-16 01:36:01,581:INFO:Initializing Logistic Regression
2023-08-16 01:36:01,582:INFO:Total runtime is 1.6899903615315757e-05 minutes
2023-08-16 01:36:01,584:INFO:SubProcess create_model() called ==================================
2023-08-16 01:36:01,585:INFO:Initializing create_model()
2023-08-16 01:36:01,585:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586C67D7F0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586CD204F0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:36:01,585:INFO:Checking exceptions
2023-08-16 01:36:01,585:INFO:Importing libraries
2023-08-16 01:36:01,585:INFO:Copying training dataset
2023-08-16 01:36:01,591:INFO:Defining folds
2023-08-16 01:36:01,591:INFO:Declaring metric variables
2023-08-16 01:36:01,594:INFO:Importing untrained model
2023-08-16 01:36:01,596:INFO:Logistic Regression Imported successfully
2023-08-16 01:36:01,602:INFO:Starting cross validation
2023-08-16 01:36:01,603:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:36:06,958:INFO:Calculating mean and std
2023-08-16 01:36:06,959:INFO:Creating metrics dataframe
2023-08-16 01:36:07,012:INFO:Uploading results into container
2023-08-16 01:36:07,013:INFO:Uploading model into container now
2023-08-16 01:36:07,013:INFO:_master_model_container: 1
2023-08-16 01:36:07,013:INFO:_display_container: 2
2023-08-16 01:36:07,013:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-16 01:36:07,013:INFO:create_model() successfully completed......................................
2023-08-16 01:36:07,084:INFO:SubProcess create_model() end ==================================
2023-08-16 01:36:07,084:INFO:Creating metrics dataframe
2023-08-16 01:36:07,089:INFO:Initializing K Neighbors Classifier
2023-08-16 01:36:07,089:INFO:Total runtime is 0.09181192715962729 minutes
2023-08-16 01:36:07,092:INFO:SubProcess create_model() called ==================================
2023-08-16 01:36:07,092:INFO:Initializing create_model()
2023-08-16 01:36:07,092:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586C67D7F0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586CD204F0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:36:07,092:INFO:Checking exceptions
2023-08-16 01:36:07,093:INFO:Importing libraries
2023-08-16 01:36:07,093:INFO:Copying training dataset
2023-08-16 01:36:07,098:INFO:Defining folds
2023-08-16 01:36:07,099:INFO:Declaring metric variables
2023-08-16 01:36:07,101:INFO:Importing untrained model
2023-08-16 01:36:07,104:INFO:K Neighbors Classifier Imported successfully
2023-08-16 01:36:07,109:INFO:Starting cross validation
2023-08-16 01:36:07,110:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:36:07,246:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:36:07,246:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:36:07,262:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:36:10,389:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:36:10,420:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:36:10,421:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:36:10,434:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:36:10,436:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:36:10,436:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:36:10,734:INFO:Calculating mean and std
2023-08-16 01:36:10,736:INFO:Creating metrics dataframe
2023-08-16 01:36:10,791:INFO:Uploading results into container
2023-08-16 01:36:10,792:INFO:Uploading model into container now
2023-08-16 01:36:10,792:INFO:_master_model_container: 2
2023-08-16 01:36:10,792:INFO:_display_container: 2
2023-08-16 01:36:10,792:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-16 01:36:10,792:INFO:create_model() successfully completed......................................
2023-08-16 01:36:10,855:INFO:SubProcess create_model() end ==================================
2023-08-16 01:36:10,855:INFO:Creating metrics dataframe
2023-08-16 01:36:10,861:INFO:Initializing Naive Bayes
2023-08-16 01:36:10,862:INFO:Total runtime is 0.15468461910883585 minutes
2023-08-16 01:36:10,864:INFO:SubProcess create_model() called ==================================
2023-08-16 01:36:10,864:INFO:Initializing create_model()
2023-08-16 01:36:10,865:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586C67D7F0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586CD204F0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:36:10,865:INFO:Checking exceptions
2023-08-16 01:36:10,865:INFO:Importing libraries
2023-08-16 01:36:10,865:INFO:Copying training dataset
2023-08-16 01:36:10,870:INFO:Defining folds
2023-08-16 01:36:10,871:INFO:Declaring metric variables
2023-08-16 01:36:10,873:INFO:Importing untrained model
2023-08-16 01:36:10,876:INFO:Naive Bayes Imported successfully
2023-08-16 01:36:10,880:INFO:Starting cross validation
2023-08-16 01:36:10,881:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:36:11,413:INFO:Calculating mean and std
2023-08-16 01:36:11,415:INFO:Creating metrics dataframe
2023-08-16 01:36:11,489:INFO:Uploading results into container
2023-08-16 01:36:11,489:INFO:Uploading model into container now
2023-08-16 01:36:11,490:INFO:_master_model_container: 3
2023-08-16 01:36:11,490:INFO:_display_container: 2
2023-08-16 01:36:11,490:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-16 01:36:11,490:INFO:create_model() successfully completed......................................
2023-08-16 01:36:11,553:INFO:SubProcess create_model() end ==================================
2023-08-16 01:36:11,554:INFO:Creating metrics dataframe
2023-08-16 01:36:11,560:INFO:Initializing Decision Tree Classifier
2023-08-16 01:36:11,560:INFO:Total runtime is 0.1663249611854553 minutes
2023-08-16 01:36:11,562:INFO:SubProcess create_model() called ==================================
2023-08-16 01:36:11,562:INFO:Initializing create_model()
2023-08-16 01:36:11,562:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586C67D7F0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586CD204F0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:36:11,563:INFO:Checking exceptions
2023-08-16 01:36:11,563:INFO:Importing libraries
2023-08-16 01:36:11,563:INFO:Copying training dataset
2023-08-16 01:36:11,569:INFO:Defining folds
2023-08-16 01:36:11,569:INFO:Declaring metric variables
2023-08-16 01:36:11,572:INFO:Importing untrained model
2023-08-16 01:36:11,575:INFO:Decision Tree Classifier Imported successfully
2023-08-16 01:36:11,579:INFO:Starting cross validation
2023-08-16 01:36:11,580:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:36:12,144:INFO:Calculating mean and std
2023-08-16 01:36:12,145:INFO:Creating metrics dataframe
2023-08-16 01:36:12,197:INFO:Uploading results into container
2023-08-16 01:36:12,197:INFO:Uploading model into container now
2023-08-16 01:36:12,198:INFO:_master_model_container: 4
2023-08-16 01:36:12,198:INFO:_display_container: 2
2023-08-16 01:36:12,198:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-08-16 01:36:12,198:INFO:create_model() successfully completed......................................
2023-08-16 01:36:12,259:INFO:SubProcess create_model() end ==================================
2023-08-16 01:36:12,259:INFO:Creating metrics dataframe
2023-08-16 01:36:12,266:INFO:Initializing SVM - Linear Kernel
2023-08-16 01:36:12,266:INFO:Total runtime is 0.17809481223424276 minutes
2023-08-16 01:36:12,268:INFO:SubProcess create_model() called ==================================
2023-08-16 01:36:12,268:INFO:Initializing create_model()
2023-08-16 01:36:12,268:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586C67D7F0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586CD204F0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:36:12,268:INFO:Checking exceptions
2023-08-16 01:36:12,269:INFO:Importing libraries
2023-08-16 01:36:12,269:INFO:Copying training dataset
2023-08-16 01:36:12,274:INFO:Defining folds
2023-08-16 01:36:12,274:INFO:Declaring metric variables
2023-08-16 01:36:12,277:INFO:Importing untrained model
2023-08-16 01:36:12,280:INFO:SVM - Linear Kernel Imported successfully
2023-08-16 01:36:12,285:INFO:Starting cross validation
2023-08-16 01:36:12,285:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:36:12,372:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:36:12,379:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:36:12,384:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:36:12,395:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:36:12,399:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:36:12,411:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:36:12,413:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:36:12,426:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:36:12,428:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:36:12,438:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:36:12,841:INFO:Calculating mean and std
2023-08-16 01:36:12,842:INFO:Creating metrics dataframe
2023-08-16 01:36:12,907:INFO:Uploading results into container
2023-08-16 01:36:12,908:INFO:Uploading model into container now
2023-08-16 01:36:12,908:INFO:_master_model_container: 5
2023-08-16 01:36:12,908:INFO:_display_container: 2
2023-08-16 01:36:12,908:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-16 01:36:12,909:INFO:create_model() successfully completed......................................
2023-08-16 01:36:12,987:INFO:SubProcess create_model() end ==================================
2023-08-16 01:36:12,987:INFO:Creating metrics dataframe
2023-08-16 01:36:12,995:INFO:Initializing Ridge Classifier
2023-08-16 01:36:12,995:INFO:Total runtime is 0.19023817380269367 minutes
2023-08-16 01:36:12,997:INFO:SubProcess create_model() called ==================================
2023-08-16 01:36:12,997:INFO:Initializing create_model()
2023-08-16 01:36:12,997:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586C67D7F0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586CD204F0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:36:12,997:INFO:Checking exceptions
2023-08-16 01:36:12,997:INFO:Importing libraries
2023-08-16 01:36:12,997:INFO:Copying training dataset
2023-08-16 01:36:13,003:INFO:Defining folds
2023-08-16 01:36:13,003:INFO:Declaring metric variables
2023-08-16 01:36:13,005:INFO:Importing untrained model
2023-08-16 01:36:13,008:INFO:Ridge Classifier Imported successfully
2023-08-16 01:36:13,012:INFO:Starting cross validation
2023-08-16 01:36:13,013:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:36:13,080:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:36:13,081:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:36:13,082:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:36:13,084:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:36:13,092:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:36:13,096:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:36:13,104:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:36:13,107:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:36:13,109:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:36:13,110:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:36:13,555:INFO:Calculating mean and std
2023-08-16 01:36:13,556:INFO:Creating metrics dataframe
2023-08-16 01:36:13,610:INFO:Uploading results into container
2023-08-16 01:36:13,610:INFO:Uploading model into container now
2023-08-16 01:36:13,611:INFO:_master_model_container: 6
2023-08-16 01:36:13,611:INFO:_display_container: 2
2023-08-16 01:36:13,611:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=123, solver='auto', tol=0.001)
2023-08-16 01:36:13,611:INFO:create_model() successfully completed......................................
2023-08-16 01:36:13,674:INFO:SubProcess create_model() end ==================================
2023-08-16 01:36:13,674:INFO:Creating metrics dataframe
2023-08-16 01:36:13,682:INFO:Initializing Random Forest Classifier
2023-08-16 01:36:13,682:INFO:Total runtime is 0.20169611771901447 minutes
2023-08-16 01:36:13,684:INFO:SubProcess create_model() called ==================================
2023-08-16 01:36:13,684:INFO:Initializing create_model()
2023-08-16 01:36:13,684:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586C67D7F0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586CD204F0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:36:13,684:INFO:Checking exceptions
2023-08-16 01:36:13,684:INFO:Importing libraries
2023-08-16 01:36:13,684:INFO:Copying training dataset
2023-08-16 01:36:13,690:INFO:Defining folds
2023-08-16 01:36:13,690:INFO:Declaring metric variables
2023-08-16 01:36:13,693:INFO:Importing untrained model
2023-08-16 01:36:13,696:INFO:Random Forest Classifier Imported successfully
2023-08-16 01:36:13,700:INFO:Starting cross validation
2023-08-16 01:36:13,701:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:36:15,027:INFO:Calculating mean and std
2023-08-16 01:36:15,028:INFO:Creating metrics dataframe
2023-08-16 01:36:15,090:INFO:Uploading results into container
2023-08-16 01:36:15,091:INFO:Uploading model into container now
2023-08-16 01:36:15,091:INFO:_master_model_container: 7
2023-08-16 01:36:15,091:INFO:_display_container: 2
2023-08-16 01:36:15,091:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-08-16 01:36:15,091:INFO:create_model() successfully completed......................................
2023-08-16 01:36:15,154:INFO:SubProcess create_model() end ==================================
2023-08-16 01:36:15,155:INFO:Creating metrics dataframe
2023-08-16 01:36:15,163:INFO:Initializing Quadratic Discriminant Analysis
2023-08-16 01:36:15,163:INFO:Total runtime is 0.2263665477434794 minutes
2023-08-16 01:36:15,164:INFO:SubProcess create_model() called ==================================
2023-08-16 01:36:15,164:INFO:Initializing create_model()
2023-08-16 01:36:15,164:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586C67D7F0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586CD204F0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:36:15,164:INFO:Checking exceptions
2023-08-16 01:36:15,164:INFO:Importing libraries
2023-08-16 01:36:15,165:INFO:Copying training dataset
2023-08-16 01:36:15,170:INFO:Defining folds
2023-08-16 01:36:15,170:INFO:Declaring metric variables
2023-08-16 01:36:15,173:INFO:Importing untrained model
2023-08-16 01:36:15,176:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-16 01:36:15,180:INFO:Starting cross validation
2023-08-16 01:36:15,181:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:36:15,218:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:36:15,222:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:36:15,229:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:36:15,235:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:15,235:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:15,235:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:36:15,240:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:15,240:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:15,240:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:36:15,241:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:36:15,245:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:36:15,246:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:36:15,246:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:36:15,247:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:15,247:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:15,247:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:36:15,250:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:36:15,251:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:15,251:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:15,252:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:36:15,255:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:36:15,255:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:36:15,257:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:15,257:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:36:15,258:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:15,258:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:36:15,260:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:36:15,261:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:36:15,262:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:15,262:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:15,262:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:15,262:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:36:15,263:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:15,263:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:36:15,263:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:15,263:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:36:15,264:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:36:15,266:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:15,266:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:15,267:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:36:15,270:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:15,271:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:15,271:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:36:15,272:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:15,272:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:15,274:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:36:15,274:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:15,274:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:15,274:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:36:15,275:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:36:15,278:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:36:15,280:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:15,280:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:15,280:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:36:15,280:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:15,280:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:15,281:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:36:15,281:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:15,281:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:15,281:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:36:15,282:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:15,283:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:15,283:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:36:15,283:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:36:15,284:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:36:15,285:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:36:15,285:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:15,285:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:15,286:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:36:15,287:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:36:15,287:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:36:15,288:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:36:15,289:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:36:15,289:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:15,289:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:15,289:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:15,289:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:15,289:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:36:15,289:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:36:15,291:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:15,292:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:15,292:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:36:15,293:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:36:15,293:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:36:15,293:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:36:15,294:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:36:15,295:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:36:15,296:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:36:15,297:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:36:15,759:INFO:Calculating mean and std
2023-08-16 01:36:15,760:INFO:Creating metrics dataframe
2023-08-16 01:36:15,822:INFO:Uploading results into container
2023-08-16 01:36:15,822:INFO:Uploading model into container now
2023-08-16 01:36:15,823:INFO:_master_model_container: 8
2023-08-16 01:36:15,823:INFO:_display_container: 2
2023-08-16 01:36:15,823:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-16 01:36:15,823:INFO:create_model() successfully completed......................................
2023-08-16 01:36:15,886:INFO:SubProcess create_model() end ==================================
2023-08-16 01:36:15,886:INFO:Creating metrics dataframe
2023-08-16 01:36:15,894:INFO:Initializing Ada Boost Classifier
2023-08-16 01:36:15,894:INFO:Total runtime is 0.238552721341451 minutes
2023-08-16 01:36:15,896:INFO:SubProcess create_model() called ==================================
2023-08-16 01:36:15,897:INFO:Initializing create_model()
2023-08-16 01:36:15,897:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586C67D7F0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586CD204F0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:36:15,897:INFO:Checking exceptions
2023-08-16 01:36:15,897:INFO:Importing libraries
2023-08-16 01:36:15,897:INFO:Copying training dataset
2023-08-16 01:36:15,902:INFO:Defining folds
2023-08-16 01:36:15,902:INFO:Declaring metric variables
2023-08-16 01:36:15,904:INFO:Importing untrained model
2023-08-16 01:36:15,907:INFO:Ada Boost Classifier Imported successfully
2023-08-16 01:36:15,912:INFO:Starting cross validation
2023-08-16 01:36:15,912:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:36:16,852:INFO:Calculating mean and std
2023-08-16 01:36:16,853:INFO:Creating metrics dataframe
2023-08-16 01:36:16,912:INFO:Uploading results into container
2023-08-16 01:36:16,913:INFO:Uploading model into container now
2023-08-16 01:36:16,913:INFO:_master_model_container: 9
2023-08-16 01:36:16,913:INFO:_display_container: 2
2023-08-16 01:36:16,914:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2023-08-16 01:36:16,914:INFO:create_model() successfully completed......................................
2023-08-16 01:36:16,980:INFO:SubProcess create_model() end ==================================
2023-08-16 01:36:16,980:INFO:Creating metrics dataframe
2023-08-16 01:36:16,988:INFO:Initializing Gradient Boosting Classifier
2023-08-16 01:36:16,988:INFO:Total runtime is 0.2567890445391337 minutes
2023-08-16 01:36:16,990:INFO:SubProcess create_model() called ==================================
2023-08-16 01:36:16,990:INFO:Initializing create_model()
2023-08-16 01:36:16,990:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586C67D7F0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586CD204F0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:36:16,990:INFO:Checking exceptions
2023-08-16 01:36:16,990:INFO:Importing libraries
2023-08-16 01:36:16,990:INFO:Copying training dataset
2023-08-16 01:36:16,996:INFO:Defining folds
2023-08-16 01:36:16,996:INFO:Declaring metric variables
2023-08-16 01:36:16,999:INFO:Importing untrained model
2023-08-16 01:36:17,002:INFO:Gradient Boosting Classifier Imported successfully
2023-08-16 01:36:17,007:INFO:Starting cross validation
2023-08-16 01:36:17,008:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:36:18,201:INFO:Calculating mean and std
2023-08-16 01:36:18,202:INFO:Creating metrics dataframe
2023-08-16 01:36:18,273:INFO:Uploading results into container
2023-08-16 01:36:18,274:INFO:Uploading model into container now
2023-08-16 01:36:18,274:INFO:_master_model_container: 10
2023-08-16 01:36:18,274:INFO:_display_container: 2
2023-08-16 01:36:18,275:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-16 01:36:18,275:INFO:create_model() successfully completed......................................
2023-08-16 01:36:18,336:INFO:SubProcess create_model() end ==================================
2023-08-16 01:36:18,337:INFO:Creating metrics dataframe
2023-08-16 01:36:18,344:INFO:Initializing Linear Discriminant Analysis
2023-08-16 01:36:18,344:INFO:Total runtime is 0.27939485708872475 minutes
2023-08-16 01:36:18,347:INFO:SubProcess create_model() called ==================================
2023-08-16 01:36:18,347:INFO:Initializing create_model()
2023-08-16 01:36:18,347:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586C67D7F0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586CD204F0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:36:18,347:INFO:Checking exceptions
2023-08-16 01:36:18,347:INFO:Importing libraries
2023-08-16 01:36:18,348:INFO:Copying training dataset
2023-08-16 01:36:18,353:INFO:Defining folds
2023-08-16 01:36:18,353:INFO:Declaring metric variables
2023-08-16 01:36:18,356:INFO:Importing untrained model
2023-08-16 01:36:18,359:INFO:Linear Discriminant Analysis Imported successfully
2023-08-16 01:36:18,363:INFO:Starting cross validation
2023-08-16 01:36:18,364:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:36:19,011:INFO:Calculating mean and std
2023-08-16 01:36:19,012:INFO:Creating metrics dataframe
2023-08-16 01:36:19,084:INFO:Uploading results into container
2023-08-16 01:36:19,085:INFO:Uploading model into container now
2023-08-16 01:36:19,085:INFO:_master_model_container: 11
2023-08-16 01:36:19,085:INFO:_display_container: 2
2023-08-16 01:36:19,085:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-16 01:36:19,085:INFO:create_model() successfully completed......................................
2023-08-16 01:36:19,148:INFO:SubProcess create_model() end ==================================
2023-08-16 01:36:19,149:INFO:Creating metrics dataframe
2023-08-16 01:36:19,156:INFO:Initializing Extra Trees Classifier
2023-08-16 01:36:19,156:INFO:Total runtime is 0.29293207724889114 minutes
2023-08-16 01:36:19,158:INFO:SubProcess create_model() called ==================================
2023-08-16 01:36:19,159:INFO:Initializing create_model()
2023-08-16 01:36:19,159:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586C67D7F0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586CD204F0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:36:19,159:INFO:Checking exceptions
2023-08-16 01:36:19,159:INFO:Importing libraries
2023-08-16 01:36:19,159:INFO:Copying training dataset
2023-08-16 01:36:19,164:INFO:Defining folds
2023-08-16 01:36:19,164:INFO:Declaring metric variables
2023-08-16 01:36:19,167:INFO:Importing untrained model
2023-08-16 01:36:19,170:INFO:Extra Trees Classifier Imported successfully
2023-08-16 01:36:19,174:INFO:Starting cross validation
2023-08-16 01:36:19,174:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:36:20,640:INFO:Calculating mean and std
2023-08-16 01:36:20,641:INFO:Creating metrics dataframe
2023-08-16 01:36:20,713:INFO:Uploading results into container
2023-08-16 01:36:20,714:INFO:Uploading model into container now
2023-08-16 01:36:20,714:INFO:_master_model_container: 12
2023-08-16 01:36:20,714:INFO:_display_container: 2
2023-08-16 01:36:20,715:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-08-16 01:36:20,715:INFO:create_model() successfully completed......................................
2023-08-16 01:36:20,777:INFO:SubProcess create_model() end ==================================
2023-08-16 01:36:20,777:INFO:Creating metrics dataframe
2023-08-16 01:36:20,786:INFO:Initializing Light Gradient Boosting Machine
2023-08-16 01:36:20,786:INFO:Total runtime is 0.32009327411651606 minutes
2023-08-16 01:36:20,788:INFO:SubProcess create_model() called ==================================
2023-08-16 01:36:20,788:INFO:Initializing create_model()
2023-08-16 01:36:20,788:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586C67D7F0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586CD204F0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:36:20,788:INFO:Checking exceptions
2023-08-16 01:36:20,788:INFO:Importing libraries
2023-08-16 01:36:20,789:INFO:Copying training dataset
2023-08-16 01:36:20,794:INFO:Defining folds
2023-08-16 01:36:20,794:INFO:Declaring metric variables
2023-08-16 01:36:20,797:INFO:Importing untrained model
2023-08-16 01:36:20,800:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-16 01:36:20,804:INFO:Starting cross validation
2023-08-16 01:36:20,805:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:36:22,615:INFO:Calculating mean and std
2023-08-16 01:36:22,616:INFO:Creating metrics dataframe
2023-08-16 01:36:22,692:INFO:Uploading results into container
2023-08-16 01:36:22,693:INFO:Uploading model into container now
2023-08-16 01:36:22,693:INFO:_master_model_container: 13
2023-08-16 01:36:22,693:INFO:_display_container: 2
2023-08-16 01:36:22,694:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-16 01:36:22,694:INFO:create_model() successfully completed......................................
2023-08-16 01:36:22,757:INFO:SubProcess create_model() end ==================================
2023-08-16 01:36:22,757:INFO:Creating metrics dataframe
2023-08-16 01:36:22,765:INFO:Initializing Dummy Classifier
2023-08-16 01:36:22,765:INFO:Total runtime is 0.3530738234519958 minutes
2023-08-16 01:36:22,767:INFO:SubProcess create_model() called ==================================
2023-08-16 01:36:22,768:INFO:Initializing create_model()
2023-08-16 01:36:22,768:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586C67D7F0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586CD204F0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:36:22,768:INFO:Checking exceptions
2023-08-16 01:36:22,768:INFO:Importing libraries
2023-08-16 01:36:22,768:INFO:Copying training dataset
2023-08-16 01:36:22,773:INFO:Defining folds
2023-08-16 01:36:22,773:INFO:Declaring metric variables
2023-08-16 01:36:22,776:INFO:Importing untrained model
2023-08-16 01:36:22,778:INFO:Dummy Classifier Imported successfully
2023-08-16 01:36:22,783:INFO:Starting cross validation
2023-08-16 01:36:22,783:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:36:22,844:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:36:22,846:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:36:22,855:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:36:22,857:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:36:22,857:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:36:22,860:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:36:22,872:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:36:22,874:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:36:22,882:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:36:22,884:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:36:23,489:INFO:Calculating mean and std
2023-08-16 01:36:23,490:INFO:Creating metrics dataframe
2023-08-16 01:36:23,567:INFO:Uploading results into container
2023-08-16 01:36:23,568:INFO:Uploading model into container now
2023-08-16 01:36:23,569:INFO:_master_model_container: 14
2023-08-16 01:36:23,569:INFO:_display_container: 2
2023-08-16 01:36:23,569:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-08-16 01:36:23,569:INFO:create_model() successfully completed......................................
2023-08-16 01:36:23,632:INFO:SubProcess create_model() end ==================================
2023-08-16 01:36:23,632:INFO:Creating metrics dataframe
2023-08-16 01:36:23,648:INFO:Initializing create_model()
2023-08-16 01:36:23,648:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586C67D7F0>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:36:23,648:INFO:Checking exceptions
2023-08-16 01:36:23,650:INFO:Importing libraries
2023-08-16 01:36:23,650:INFO:Copying training dataset
2023-08-16 01:36:23,654:INFO:Defining folds
2023-08-16 01:36:23,654:INFO:Declaring metric variables
2023-08-16 01:36:23,654:INFO:Importing untrained model
2023-08-16 01:36:23,654:INFO:Declaring custom model
2023-08-16 01:36:23,655:INFO:Ada Boost Classifier Imported successfully
2023-08-16 01:36:23,655:INFO:Cross validation set to False
2023-08-16 01:36:23,655:INFO:Fitting Model
2023-08-16 01:36:23,909:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2023-08-16 01:36:23,909:INFO:create_model() successfully completed......................................
2023-08-16 01:36:23,992:INFO:_master_model_container: 14
2023-08-16 01:36:23,992:INFO:_display_container: 2
2023-08-16 01:36:23,992:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2023-08-16 01:36:23,992:INFO:compare_models() successfully completed......................................
2023-08-16 01:36:28,129:INFO:Initializing compare_models()
2023-08-16 01:36:28,129:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586C67DA00>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002586C67DA00>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-16 01:36:28,129:INFO:Checking exceptions
2023-08-16 01:36:28,134:INFO:Preparing display monitor
2023-08-16 01:36:28,162:INFO:Initializing Logistic Regression
2023-08-16 01:36:28,162:INFO:Total runtime is 0.0 minutes
2023-08-16 01:36:28,164:INFO:SubProcess create_model() called ==================================
2023-08-16 01:36:28,165:INFO:Initializing create_model()
2023-08-16 01:36:28,165:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586C67DA00>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586CD68160>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:36:28,165:INFO:Checking exceptions
2023-08-16 01:36:28,165:INFO:Importing libraries
2023-08-16 01:36:28,165:INFO:Copying training dataset
2023-08-16 01:36:28,170:INFO:Defining folds
2023-08-16 01:36:28,170:INFO:Declaring metric variables
2023-08-16 01:36:28,173:INFO:Importing untrained model
2023-08-16 01:36:28,177:INFO:Logistic Regression Imported successfully
2023-08-16 01:36:28,183:INFO:Starting cross validation
2023-08-16 01:36:28,184:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:36:28,918:INFO:Calculating mean and std
2023-08-16 01:36:28,919:INFO:Creating metrics dataframe
2023-08-16 01:36:28,996:INFO:Uploading results into container
2023-08-16 01:36:28,997:INFO:Uploading model into container now
2023-08-16 01:36:28,998:INFO:_master_model_container: 1
2023-08-16 01:36:28,998:INFO:_display_container: 2
2023-08-16 01:36:28,998:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-16 01:36:28,998:INFO:create_model() successfully completed......................................
2023-08-16 01:36:29,077:INFO:SubProcess create_model() end ==================================
2023-08-16 01:36:29,077:INFO:Creating metrics dataframe
2023-08-16 01:36:29,084:INFO:Initializing K Neighbors Classifier
2023-08-16 01:36:29,084:INFO:Total runtime is 0.01536713441212972 minutes
2023-08-16 01:36:29,087:INFO:SubProcess create_model() called ==================================
2023-08-16 01:36:29,088:INFO:Initializing create_model()
2023-08-16 01:36:29,088:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586C67DA00>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586CD68160>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:36:29,088:INFO:Checking exceptions
2023-08-16 01:36:29,088:INFO:Importing libraries
2023-08-16 01:36:29,088:INFO:Copying training dataset
2023-08-16 01:36:29,093:INFO:Defining folds
2023-08-16 01:36:29,093:INFO:Declaring metric variables
2023-08-16 01:36:29,095:INFO:Importing untrained model
2023-08-16 01:36:29,099:INFO:K Neighbors Classifier Imported successfully
2023-08-16 01:36:29,104:INFO:Starting cross validation
2023-08-16 01:36:29,105:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:36:29,209:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:36:29,223:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:36:29,247:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:36:29,247:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:36:29,258:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:36:29,259:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:36:29,259:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:36:29,278:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:36:29,287:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:36:29,287:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:36:29,979:INFO:Calculating mean and std
2023-08-16 01:36:29,980:INFO:Creating metrics dataframe
2023-08-16 01:36:30,060:INFO:Uploading results into container
2023-08-16 01:36:30,061:INFO:Uploading model into container now
2023-08-16 01:36:30,061:INFO:_master_model_container: 2
2023-08-16 01:36:30,061:INFO:_display_container: 2
2023-08-16 01:36:30,061:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-16 01:36:30,061:INFO:create_model() successfully completed......................................
2023-08-16 01:36:30,125:INFO:SubProcess create_model() end ==================================
2023-08-16 01:36:30,125:INFO:Creating metrics dataframe
2023-08-16 01:36:30,133:INFO:Initializing Naive Bayes
2023-08-16 01:36:30,133:INFO:Total runtime is 0.032854910691579184 minutes
2023-08-16 01:36:30,136:INFO:SubProcess create_model() called ==================================
2023-08-16 01:36:30,136:INFO:Initializing create_model()
2023-08-16 01:36:30,136:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586C67DA00>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586CD68160>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:36:30,136:INFO:Checking exceptions
2023-08-16 01:36:30,136:INFO:Importing libraries
2023-08-16 01:36:30,136:INFO:Copying training dataset
2023-08-16 01:36:30,142:INFO:Defining folds
2023-08-16 01:36:30,142:INFO:Declaring metric variables
2023-08-16 01:36:30,145:INFO:Importing untrained model
2023-08-16 01:36:30,148:INFO:Naive Bayes Imported successfully
2023-08-16 01:36:30,152:INFO:Starting cross validation
2023-08-16 01:36:30,153:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:36:30,849:INFO:Calculating mean and std
2023-08-16 01:36:30,850:INFO:Creating metrics dataframe
2023-08-16 01:36:30,926:INFO:Uploading results into container
2023-08-16 01:36:30,926:INFO:Uploading model into container now
2023-08-16 01:36:30,927:INFO:_master_model_container: 3
2023-08-16 01:36:30,927:INFO:_display_container: 2
2023-08-16 01:36:30,927:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-16 01:36:30,927:INFO:create_model() successfully completed......................................
2023-08-16 01:36:30,991:INFO:SubProcess create_model() end ==================================
2023-08-16 01:36:30,991:INFO:Creating metrics dataframe
2023-08-16 01:36:30,998:INFO:Initializing Decision Tree Classifier
2023-08-16 01:36:30,998:INFO:Total runtime is 0.047260908285776775 minutes
2023-08-16 01:36:31,000:INFO:SubProcess create_model() called ==================================
2023-08-16 01:36:31,000:INFO:Initializing create_model()
2023-08-16 01:36:31,001:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586C67DA00>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586CD68160>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:36:31,001:INFO:Checking exceptions
2023-08-16 01:36:31,001:INFO:Importing libraries
2023-08-16 01:36:31,001:INFO:Copying training dataset
2023-08-16 01:36:31,006:INFO:Defining folds
2023-08-16 01:36:31,006:INFO:Declaring metric variables
2023-08-16 01:36:31,010:INFO:Importing untrained model
2023-08-16 01:36:31,012:INFO:Decision Tree Classifier Imported successfully
2023-08-16 01:36:31,017:INFO:Starting cross validation
2023-08-16 01:36:31,018:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:36:31,706:INFO:Calculating mean and std
2023-08-16 01:36:31,708:INFO:Creating metrics dataframe
2023-08-16 01:36:31,782:INFO:Uploading results into container
2023-08-16 01:36:31,782:INFO:Uploading model into container now
2023-08-16 01:36:31,783:INFO:_master_model_container: 4
2023-08-16 01:36:31,783:INFO:_display_container: 2
2023-08-16 01:36:31,783:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-08-16 01:36:31,783:INFO:create_model() successfully completed......................................
2023-08-16 01:36:31,848:INFO:SubProcess create_model() end ==================================
2023-08-16 01:36:31,848:INFO:Creating metrics dataframe
2023-08-16 01:36:31,854:INFO:Initializing SVM - Linear Kernel
2023-08-16 01:36:31,854:INFO:Total runtime is 0.06153234640757243 minutes
2023-08-16 01:36:31,857:INFO:SubProcess create_model() called ==================================
2023-08-16 01:36:31,857:INFO:Initializing create_model()
2023-08-16 01:36:31,858:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586C67DA00>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586CD68160>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:36:31,858:INFO:Checking exceptions
2023-08-16 01:36:31,858:INFO:Importing libraries
2023-08-16 01:36:31,858:INFO:Copying training dataset
2023-08-16 01:36:31,863:INFO:Defining folds
2023-08-16 01:36:31,863:INFO:Declaring metric variables
2023-08-16 01:36:31,866:INFO:Importing untrained model
2023-08-16 01:36:31,868:INFO:SVM - Linear Kernel Imported successfully
2023-08-16 01:36:31,872:INFO:Starting cross validation
2023-08-16 01:36:31,873:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:36:31,963:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:36:31,972:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:36:31,981:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:36:31,988:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:36:32,000:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:36:32,003:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:36:32,003:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:36:32,004:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:36:32,010:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:36:32,010:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:36:32,596:INFO:Calculating mean and std
2023-08-16 01:36:32,597:INFO:Creating metrics dataframe
2023-08-16 01:36:32,669:INFO:Uploading results into container
2023-08-16 01:36:32,670:INFO:Uploading model into container now
2023-08-16 01:36:32,670:INFO:_master_model_container: 5
2023-08-16 01:36:32,670:INFO:_display_container: 2
2023-08-16 01:36:32,670:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-16 01:36:32,671:INFO:create_model() successfully completed......................................
2023-08-16 01:36:32,735:INFO:SubProcess create_model() end ==================================
2023-08-16 01:36:32,735:INFO:Creating metrics dataframe
2023-08-16 01:36:32,743:INFO:Initializing Ridge Classifier
2023-08-16 01:36:32,743:INFO:Total runtime is 0.07634811798731486 minutes
2023-08-16 01:36:32,745:INFO:SubProcess create_model() called ==================================
2023-08-16 01:36:32,745:INFO:Initializing create_model()
2023-08-16 01:36:32,745:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586C67DA00>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586CD68160>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:36:32,745:INFO:Checking exceptions
2023-08-16 01:36:32,745:INFO:Importing libraries
2023-08-16 01:36:32,745:INFO:Copying training dataset
2023-08-16 01:36:32,750:INFO:Defining folds
2023-08-16 01:36:32,750:INFO:Declaring metric variables
2023-08-16 01:36:32,753:INFO:Importing untrained model
2023-08-16 01:36:32,757:INFO:Ridge Classifier Imported successfully
2023-08-16 01:36:32,762:INFO:Starting cross validation
2023-08-16 01:36:32,762:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:36:32,818:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:36:32,820:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:36:32,827:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:36:32,830:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:36:32,834:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:36:32,838:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:36:32,848:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:36:32,850:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:36:32,851:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:36:32,854:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:36:33,460:INFO:Calculating mean and std
2023-08-16 01:36:33,461:INFO:Creating metrics dataframe
2023-08-16 01:36:33,534:INFO:Uploading results into container
2023-08-16 01:36:33,535:INFO:Uploading model into container now
2023-08-16 01:36:33,535:INFO:_master_model_container: 6
2023-08-16 01:36:33,535:INFO:_display_container: 2
2023-08-16 01:36:33,536:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=123, solver='auto', tol=0.001)
2023-08-16 01:36:33,536:INFO:create_model() successfully completed......................................
2023-08-16 01:36:33,599:INFO:SubProcess create_model() end ==================================
2023-08-16 01:36:33,599:INFO:Creating metrics dataframe
2023-08-16 01:36:33,606:INFO:Initializing Random Forest Classifier
2023-08-16 01:36:33,606:INFO:Total runtime is 0.09073375463485718 minutes
2023-08-16 01:36:33,608:INFO:SubProcess create_model() called ==================================
2023-08-16 01:36:33,608:INFO:Initializing create_model()
2023-08-16 01:36:33,608:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586C67DA00>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586CD68160>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:36:33,608:INFO:Checking exceptions
2023-08-16 01:36:33,608:INFO:Importing libraries
2023-08-16 01:36:33,608:INFO:Copying training dataset
2023-08-16 01:36:33,614:INFO:Defining folds
2023-08-16 01:36:33,614:INFO:Declaring metric variables
2023-08-16 01:36:33,617:INFO:Importing untrained model
2023-08-16 01:36:33,620:INFO:Random Forest Classifier Imported successfully
2023-08-16 01:36:33,625:INFO:Starting cross validation
2023-08-16 01:36:33,626:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:36:34,581:INFO:Calculating mean and std
2023-08-16 01:36:34,583:INFO:Creating metrics dataframe
2023-08-16 01:36:34,658:INFO:Uploading results into container
2023-08-16 01:36:34,658:INFO:Uploading model into container now
2023-08-16 01:36:34,659:INFO:_master_model_container: 7
2023-08-16 01:36:34,659:INFO:_display_container: 2
2023-08-16 01:36:34,659:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-08-16 01:36:34,659:INFO:create_model() successfully completed......................................
2023-08-16 01:36:34,763:INFO:SubProcess create_model() end ==================================
2023-08-16 01:36:34,763:INFO:Creating metrics dataframe
2023-08-16 01:36:34,771:INFO:Initializing Quadratic Discriminant Analysis
2023-08-16 01:36:34,771:INFO:Total runtime is 0.11015830437342326 minutes
2023-08-16 01:36:34,774:INFO:SubProcess create_model() called ==================================
2023-08-16 01:36:34,775:INFO:Initializing create_model()
2023-08-16 01:36:34,775:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586C67DA00>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586CD68160>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:36:34,775:INFO:Checking exceptions
2023-08-16 01:36:34,775:INFO:Importing libraries
2023-08-16 01:36:34,775:INFO:Copying training dataset
2023-08-16 01:36:34,780:INFO:Defining folds
2023-08-16 01:36:34,780:INFO:Declaring metric variables
2023-08-16 01:36:34,783:INFO:Importing untrained model
2023-08-16 01:36:34,787:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-16 01:36:34,792:INFO:Starting cross validation
2023-08-16 01:36:34,793:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:36:34,831:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:36:34,839:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:36:34,840:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:36:34,845:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:36:34,849:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:34,849:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:34,850:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:36:34,851:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:36:34,853:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:34,853:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:34,854:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:36:34,859:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:34,859:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:34,859:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:36:34,860:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:36:34,861:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:34,861:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:34,861:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:36:34,866:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:34,866:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:34,867:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:36:34,868:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:34,869:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:34,869:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:36:34,869:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:34,869:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:34,870:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:36:34,870:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:36:34,872:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:36:34,873:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:36:34,873:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:36:34,874:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:34,874:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:34,874:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:36:34,875:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:36:34,875:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:36:34,875:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:36:34,876:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:36:34,877:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:36:34,877:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:34,877:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:34,878:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:36:34,878:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:36:34,879:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:34,879:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:34,880:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:36:34,880:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:36:34,880:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:34,880:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:34,881:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:36:34,881:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:36:34,883:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:36:34,886:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:36:34,889:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:34,889:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:34,889:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:36:34,891:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:34,891:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:34,891:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:36:34,894:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:34,894:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:34,894:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:36:34,895:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:34,896:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:34,896:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:36:34,897:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:34,897:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:34,898:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:36:34,899:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:36:34,902:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:34,903:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:34,903:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:36:34,903:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:36:34,904:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:36:34,905:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:34,906:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:34,906:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:36:34,906:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:36:34,907:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:36:34,909:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:36:34,910:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:34,910:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:34,910:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:34,910:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:36:34,910:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:36:34,910:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:36:34,911:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:36:34,913:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:36:34,914:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:36:34,915:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:36:35,487:INFO:Calculating mean and std
2023-08-16 01:36:35,488:INFO:Creating metrics dataframe
2023-08-16 01:36:35,567:INFO:Uploading results into container
2023-08-16 01:36:35,567:INFO:Uploading model into container now
2023-08-16 01:36:35,568:INFO:_master_model_container: 8
2023-08-16 01:36:35,568:INFO:_display_container: 2
2023-08-16 01:36:35,568:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-16 01:36:35,568:INFO:create_model() successfully completed......................................
2023-08-16 01:36:35,632:INFO:SubProcess create_model() end ==================================
2023-08-16 01:36:35,632:INFO:Creating metrics dataframe
2023-08-16 01:36:35,640:INFO:Initializing Ada Boost Classifier
2023-08-16 01:36:35,640:INFO:Total runtime is 0.12462624708811443 minutes
2023-08-16 01:36:35,642:INFO:SubProcess create_model() called ==================================
2023-08-16 01:36:35,643:INFO:Initializing create_model()
2023-08-16 01:36:35,643:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586C67DA00>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586CD68160>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:36:35,643:INFO:Checking exceptions
2023-08-16 01:36:35,643:INFO:Importing libraries
2023-08-16 01:36:35,643:INFO:Copying training dataset
2023-08-16 01:36:35,649:INFO:Defining folds
2023-08-16 01:36:35,649:INFO:Declaring metric variables
2023-08-16 01:36:35,652:INFO:Importing untrained model
2023-08-16 01:36:35,654:INFO:Ada Boost Classifier Imported successfully
2023-08-16 01:36:35,658:INFO:Starting cross validation
2023-08-16 01:36:35,659:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:36:36,437:INFO:Calculating mean and std
2023-08-16 01:36:36,438:INFO:Creating metrics dataframe
2023-08-16 01:36:36,513:INFO:Uploading results into container
2023-08-16 01:36:36,513:INFO:Uploading model into container now
2023-08-16 01:36:36,514:INFO:_master_model_container: 9
2023-08-16 01:36:36,514:INFO:_display_container: 2
2023-08-16 01:36:36,514:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2023-08-16 01:36:36,514:INFO:create_model() successfully completed......................................
2023-08-16 01:36:36,580:INFO:SubProcess create_model() end ==================================
2023-08-16 01:36:36,580:INFO:Creating metrics dataframe
2023-08-16 01:36:36,587:INFO:Initializing Gradient Boosting Classifier
2023-08-16 01:36:36,587:INFO:Total runtime is 0.14041716655095418 minutes
2023-08-16 01:36:36,589:INFO:SubProcess create_model() called ==================================
2023-08-16 01:36:36,589:INFO:Initializing create_model()
2023-08-16 01:36:36,590:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586C67DA00>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586CD68160>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:36:36,590:INFO:Checking exceptions
2023-08-16 01:36:36,590:INFO:Importing libraries
2023-08-16 01:36:36,590:INFO:Copying training dataset
2023-08-16 01:36:36,595:INFO:Defining folds
2023-08-16 01:36:36,595:INFO:Declaring metric variables
2023-08-16 01:36:36,597:INFO:Importing untrained model
2023-08-16 01:36:36,600:INFO:Gradient Boosting Classifier Imported successfully
2023-08-16 01:36:36,604:INFO:Starting cross validation
2023-08-16 01:36:36,605:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:36:37,356:INFO:Calculating mean and std
2023-08-16 01:36:37,357:INFO:Creating metrics dataframe
2023-08-16 01:36:37,431:INFO:Uploading results into container
2023-08-16 01:36:37,432:INFO:Uploading model into container now
2023-08-16 01:36:37,432:INFO:_master_model_container: 10
2023-08-16 01:36:37,432:INFO:_display_container: 2
2023-08-16 01:36:37,432:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-16 01:36:37,432:INFO:create_model() successfully completed......................................
2023-08-16 01:36:37,495:INFO:SubProcess create_model() end ==================================
2023-08-16 01:36:37,495:INFO:Creating metrics dataframe
2023-08-16 01:36:37,503:INFO:Initializing Linear Discriminant Analysis
2023-08-16 01:36:37,503:INFO:Total runtime is 0.15568193991978962 minutes
2023-08-16 01:36:37,505:INFO:SubProcess create_model() called ==================================
2023-08-16 01:36:37,505:INFO:Initializing create_model()
2023-08-16 01:36:37,505:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586C67DA00>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586CD68160>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:36:37,505:INFO:Checking exceptions
2023-08-16 01:36:37,505:INFO:Importing libraries
2023-08-16 01:36:37,505:INFO:Copying training dataset
2023-08-16 01:36:37,511:INFO:Defining folds
2023-08-16 01:36:37,511:INFO:Declaring metric variables
2023-08-16 01:36:37,514:INFO:Importing untrained model
2023-08-16 01:36:37,516:INFO:Linear Discriminant Analysis Imported successfully
2023-08-16 01:36:37,521:INFO:Starting cross validation
2023-08-16 01:36:37,521:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:36:38,213:INFO:Calculating mean and std
2023-08-16 01:36:38,214:INFO:Creating metrics dataframe
2023-08-16 01:36:38,287:INFO:Uploading results into container
2023-08-16 01:36:38,287:INFO:Uploading model into container now
2023-08-16 01:36:38,288:INFO:_master_model_container: 11
2023-08-16 01:36:38,288:INFO:_display_container: 2
2023-08-16 01:36:38,288:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-16 01:36:38,288:INFO:create_model() successfully completed......................................
2023-08-16 01:36:38,353:INFO:SubProcess create_model() end ==================================
2023-08-16 01:36:38,354:INFO:Creating metrics dataframe
2023-08-16 01:36:38,362:INFO:Initializing Extra Trees Classifier
2023-08-16 01:36:38,362:INFO:Total runtime is 0.17000874280929565 minutes
2023-08-16 01:36:38,364:INFO:SubProcess create_model() called ==================================
2023-08-16 01:36:38,364:INFO:Initializing create_model()
2023-08-16 01:36:38,364:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586C67DA00>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586CD68160>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:36:38,364:INFO:Checking exceptions
2023-08-16 01:36:38,364:INFO:Importing libraries
2023-08-16 01:36:38,364:INFO:Copying training dataset
2023-08-16 01:36:38,369:INFO:Defining folds
2023-08-16 01:36:38,370:INFO:Declaring metric variables
2023-08-16 01:36:38,372:INFO:Importing untrained model
2023-08-16 01:36:38,375:INFO:Extra Trees Classifier Imported successfully
2023-08-16 01:36:38,380:INFO:Starting cross validation
2023-08-16 01:36:38,381:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:36:39,355:INFO:Calculating mean and std
2023-08-16 01:36:39,356:INFO:Creating metrics dataframe
2023-08-16 01:36:39,430:INFO:Uploading results into container
2023-08-16 01:36:39,431:INFO:Uploading model into container now
2023-08-16 01:36:39,431:INFO:_master_model_container: 12
2023-08-16 01:36:39,431:INFO:_display_container: 2
2023-08-16 01:36:39,432:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-08-16 01:36:39,432:INFO:create_model() successfully completed......................................
2023-08-16 01:36:39,496:INFO:SubProcess create_model() end ==================================
2023-08-16 01:36:39,496:INFO:Creating metrics dataframe
2023-08-16 01:36:39,504:INFO:Initializing Light Gradient Boosting Machine
2023-08-16 01:36:39,504:INFO:Total runtime is 0.1890385866165161 minutes
2023-08-16 01:36:39,507:INFO:SubProcess create_model() called ==================================
2023-08-16 01:36:39,507:INFO:Initializing create_model()
2023-08-16 01:36:39,507:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586C67DA00>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586CD68160>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:36:39,507:INFO:Checking exceptions
2023-08-16 01:36:39,507:INFO:Importing libraries
2023-08-16 01:36:39,507:INFO:Copying training dataset
2023-08-16 01:36:39,515:INFO:Defining folds
2023-08-16 01:36:39,516:INFO:Declaring metric variables
2023-08-16 01:36:39,520:INFO:Importing untrained model
2023-08-16 01:36:39,524:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-16 01:36:39,530:INFO:Starting cross validation
2023-08-16 01:36:39,531:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:36:40,335:INFO:Calculating mean and std
2023-08-16 01:36:40,336:INFO:Creating metrics dataframe
2023-08-16 01:36:40,410:INFO:Uploading results into container
2023-08-16 01:36:40,411:INFO:Uploading model into container now
2023-08-16 01:36:40,411:INFO:_master_model_container: 13
2023-08-16 01:36:40,411:INFO:_display_container: 2
2023-08-16 01:36:40,411:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-16 01:36:40,411:INFO:create_model() successfully completed......................................
2023-08-16 01:36:40,476:INFO:SubProcess create_model() end ==================================
2023-08-16 01:36:40,476:INFO:Creating metrics dataframe
2023-08-16 01:36:40,484:INFO:Initializing Dummy Classifier
2023-08-16 01:36:40,484:INFO:Total runtime is 0.2053675333658854 minutes
2023-08-16 01:36:40,487:INFO:SubProcess create_model() called ==================================
2023-08-16 01:36:40,487:INFO:Initializing create_model()
2023-08-16 01:36:40,487:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586C67DA00>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586CD68160>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:36:40,487:INFO:Checking exceptions
2023-08-16 01:36:40,488:INFO:Importing libraries
2023-08-16 01:36:40,488:INFO:Copying training dataset
2023-08-16 01:36:40,493:INFO:Defining folds
2023-08-16 01:36:40,493:INFO:Declaring metric variables
2023-08-16 01:36:40,496:INFO:Importing untrained model
2023-08-16 01:36:40,498:INFO:Dummy Classifier Imported successfully
2023-08-16 01:36:40,502:INFO:Starting cross validation
2023-08-16 01:36:40,503:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:36:40,565:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:36:40,565:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:36:40,570:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:36:40,576:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:36:40,576:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:36:40,583:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:36:40,583:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:36:40,593:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:36:40,597:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:36:40,600:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:36:41,177:INFO:Calculating mean and std
2023-08-16 01:36:41,178:INFO:Creating metrics dataframe
2023-08-16 01:36:41,253:INFO:Uploading results into container
2023-08-16 01:36:41,254:INFO:Uploading model into container now
2023-08-16 01:36:41,254:INFO:_master_model_container: 14
2023-08-16 01:36:41,254:INFO:_display_container: 2
2023-08-16 01:36:41,254:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-08-16 01:36:41,254:INFO:create_model() successfully completed......................................
2023-08-16 01:36:41,316:INFO:SubProcess create_model() end ==================================
2023-08-16 01:36:41,316:INFO:Creating metrics dataframe
2023-08-16 01:36:41,331:INFO:Initializing create_model()
2023-08-16 01:36:41,331:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586C67DA00>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:36:41,331:INFO:Checking exceptions
2023-08-16 01:36:41,333:INFO:Importing libraries
2023-08-16 01:36:41,333:INFO:Copying training dataset
2023-08-16 01:36:41,338:INFO:Defining folds
2023-08-16 01:36:41,338:INFO:Declaring metric variables
2023-08-16 01:36:41,338:INFO:Importing untrained model
2023-08-16 01:36:41,338:INFO:Declaring custom model
2023-08-16 01:36:41,339:INFO:Ada Boost Classifier Imported successfully
2023-08-16 01:36:41,339:INFO:Cross validation set to False
2023-08-16 01:36:41,339:INFO:Fitting Model
2023-08-16 01:36:41,420:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2023-08-16 01:36:41,420:INFO:create_model() successfully completed......................................
2023-08-16 01:36:41,503:INFO:_master_model_container: 14
2023-08-16 01:36:41,503:INFO:_display_container: 2
2023-08-16 01:36:41,504:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2023-08-16 01:36:41,504:INFO:compare_models() successfully completed......................................
2023-08-16 01:37:17,039:INFO:Initializing plot_model()
2023-08-16 01:37:17,039:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586C67D7F0>, system=True)
2023-08-16 01:37:17,040:INFO:Checking exceptions
2023-08-16 01:37:17,046:INFO:Preloading libraries
2023-08-16 01:37:17,049:INFO:Copying training dataset
2023-08-16 01:37:17,049:INFO:Plot type: confusion_matrix
2023-08-16 01:37:17,105:INFO:Fitting Model
2023-08-16 01:37:17,107:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names
  warnings.warn(

2023-08-16 01:37:17,107:INFO:Scoring test/hold-out set
2023-08-16 01:37:17,239:INFO:Visual Rendered Successfully
2023-08-16 01:37:17,336:INFO:plot_model() successfully completed......................................
2023-08-16 01:37:40,875:INFO:Initializing plot_model()
2023-08-16 01:37:40,875:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586C67D7F0>, system=True)
2023-08-16 01:37:40,875:INFO:Checking exceptions
2023-08-16 01:37:40,881:INFO:Preloading libraries
2023-08-16 01:37:40,884:INFO:Copying training dataset
2023-08-16 01:37:40,884:INFO:Plot type: auc
2023-08-16 01:37:40,942:INFO:Fitting Model
2023-08-16 01:37:40,942:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names
  warnings.warn(

2023-08-16 01:37:40,942:INFO:Scoring test/hold-out set
2023-08-16 01:37:41,084:INFO:Visual Rendered Successfully
2023-08-16 01:37:41,150:INFO:plot_model() successfully completed......................................
2023-08-16 01:37:54,954:INFO:Initializing plot_model()
2023-08-16 01:37:54,954:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586C67D7F0>, system=True)
2023-08-16 01:37:54,954:INFO:Checking exceptions
2023-08-16 01:37:54,959:INFO:Preloading libraries
2023-08-16 01:37:54,962:INFO:Copying training dataset
2023-08-16 01:37:54,962:INFO:Plot type: feature
2023-08-16 01:37:54,962:WARNING:No coef_ found. Trying feature_importances_
2023-08-16 01:37:55,051:INFO:Visual Rendered Successfully
2023-08-16 01:37:55,120:INFO:plot_model() successfully completed......................................
2023-08-16 01:40:49,948:INFO:PyCaret ClassificationExperiment
2023-08-16 01:40:49,948:INFO:Logging name: clf-default-name
2023-08-16 01:40:49,948:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-16 01:40:49,948:INFO:version 3.0.4
2023-08-16 01:40:49,948:INFO:Initializing setup()
2023-08-16 01:40:49,948:INFO:self.USI: e310
2023-08-16 01:40:49,948:INFO:self._variable_keys: {'logging_param', '_ml_usecase', 'n_jobs_param', 'exp_id', 'y_train', 'idx', 'fold_generator', 'memory', 'data', 'pipeline', 'fold_groups_param', 'fix_imbalance', 'USI', 'gpu_param', 'exp_name_log', 'gpu_n_jobs_param', 'X_train', 'X_test', 'X', 'y_test', '_available_plots', 'target_param', 'html_param', 'is_multiclass', 'fold_shuffle_param', 'log_plots_param', 'seed', 'y'}
2023-08-16 01:40:49,948:INFO:Checking environment
2023-08-16 01:40:49,948:INFO:python_version: 3.9.13
2023-08-16 01:40:49,948:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-08-16 01:40:49,948:INFO:machine: AMD64
2023-08-16 01:40:49,948:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-16 01:40:49,948:INFO:Memory: svmem(total=16905969664, available=1378275328, percent=91.8, used=15527694336, free=1378275328)
2023-08-16 01:40:49,948:INFO:Physical Core: 8
2023-08-16 01:40:49,948:INFO:Logical Core: 16
2023-08-16 01:40:49,948:INFO:Checking libraries
2023-08-16 01:40:49,948:INFO:System:
2023-08-16 01:40:49,948:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-08-16 01:40:49,948:INFO:executable: c:\Users\lmacciomaretto\anaconda3\python.exe
2023-08-16 01:40:49,948:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-16 01:40:49,948:INFO:PyCaret required dependencies:
2023-08-16 01:40:49,948:INFO:                 pip: 22.2.2
2023-08-16 01:40:49,948:INFO:          setuptools: 63.4.1
2023-08-16 01:40:49,949:INFO:             pycaret: 3.0.4
2023-08-16 01:40:49,949:INFO:             IPython: 7.31.1
2023-08-16 01:40:49,949:INFO:          ipywidgets: 7.6.5
2023-08-16 01:40:49,949:INFO:                tqdm: 4.64.1
2023-08-16 01:40:49,949:INFO:               numpy: 1.21.5
2023-08-16 01:40:49,949:INFO:              pandas: 1.4.4
2023-08-16 01:40:49,949:INFO:              jinja2: 2.11.3
2023-08-16 01:40:49,949:INFO:               scipy: 1.9.1
2023-08-16 01:40:49,949:INFO:              joblib: 1.3.2
2023-08-16 01:40:49,949:INFO:             sklearn: 1.0.2
2023-08-16 01:40:49,949:INFO:                pyod: 1.1.0
2023-08-16 01:40:49,949:INFO:            imblearn: 0.11.0
2023-08-16 01:40:49,949:INFO:   category_encoders: 2.6.2
2023-08-16 01:40:49,949:INFO:            lightgbm: 4.0.0
2023-08-16 01:40:49,949:INFO:               numba: 0.55.1
2023-08-16 01:40:49,949:INFO:            requests: 2.28.1
2023-08-16 01:40:49,949:INFO:          matplotlib: 3.5.2
2023-08-16 01:40:49,949:INFO:          scikitplot: 0.3.7
2023-08-16 01:40:49,949:INFO:         yellowbrick: 1.5
2023-08-16 01:40:49,949:INFO:              plotly: 5.9.0
2023-08-16 01:40:49,949:INFO:    plotly-resampler: Not installed
2023-08-16 01:40:49,949:INFO:             kaleido: 0.2.1
2023-08-16 01:40:49,949:INFO:           schemdraw: 0.15
2023-08-16 01:40:49,949:INFO:         statsmodels: 0.13.2
2023-08-16 01:40:49,949:INFO:              sktime: 0.21.0
2023-08-16 01:40:49,949:INFO:               tbats: 1.1.3
2023-08-16 01:40:49,949:INFO:            pmdarima: 2.0.3
2023-08-16 01:40:49,949:INFO:              psutil: 5.9.0
2023-08-16 01:40:49,949:INFO:          markupsafe: 2.0.1
2023-08-16 01:40:49,949:INFO:             pickle5: Not installed
2023-08-16 01:40:49,949:INFO:         cloudpickle: 2.0.0
2023-08-16 01:40:49,949:INFO:         deprecation: 2.1.0
2023-08-16 01:40:49,949:INFO:              xxhash: 3.3.0
2023-08-16 01:40:49,949:INFO:           wurlitzer: Not installed
2023-08-16 01:40:49,949:INFO:PyCaret optional dependencies:
2023-08-16 01:40:49,949:INFO:                shap: Not installed
2023-08-16 01:40:49,949:INFO:           interpret: Not installed
2023-08-16 01:40:49,949:INFO:                umap: Not installed
2023-08-16 01:40:49,949:INFO:    pandas_profiling: Not installed
2023-08-16 01:40:49,950:INFO:  explainerdashboard: Not installed
2023-08-16 01:40:49,950:INFO:             autoviz: Not installed
2023-08-16 01:40:49,950:INFO:           fairlearn: Not installed
2023-08-16 01:40:49,950:INFO:          deepchecks: Not installed
2023-08-16 01:40:49,950:INFO:             xgboost: Not installed
2023-08-16 01:40:49,950:INFO:            catboost: Not installed
2023-08-16 01:40:49,950:INFO:              kmodes: Not installed
2023-08-16 01:40:49,950:INFO:             mlxtend: Not installed
2023-08-16 01:40:49,950:INFO:       statsforecast: Not installed
2023-08-16 01:40:49,950:INFO:        tune_sklearn: Not installed
2023-08-16 01:40:49,950:INFO:                 ray: Not installed
2023-08-16 01:40:49,950:INFO:            hyperopt: Not installed
2023-08-16 01:40:49,950:INFO:              optuna: Not installed
2023-08-16 01:40:49,950:INFO:               skopt: Not installed
2023-08-16 01:40:49,950:INFO:              mlflow: Not installed
2023-08-16 01:40:49,950:INFO:              gradio: Not installed
2023-08-16 01:40:49,950:INFO:             fastapi: Not installed
2023-08-16 01:40:49,950:INFO:             uvicorn: Not installed
2023-08-16 01:40:49,950:INFO:              m2cgen: Not installed
2023-08-16 01:40:49,950:INFO:           evidently: Not installed
2023-08-16 01:40:49,950:INFO:               fugue: Not installed
2023-08-16 01:40:49,950:INFO:           streamlit: Not installed
2023-08-16 01:40:49,950:INFO:             prophet: Not installed
2023-08-16 01:40:49,950:INFO:None
2023-08-16 01:40:49,950:INFO:Set up data.
2023-08-16 01:40:49,956:INFO:Set up train/test split.
2023-08-16 01:40:49,962:INFO:Set up index.
2023-08-16 01:40:49,962:INFO:Set up folding strategy.
2023-08-16 01:40:49,962:INFO:Assigning column types.
2023-08-16 01:40:49,965:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-16 01:40:49,999:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-16 01:40:50,000:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:40:50,021:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:40:50,021:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:40:50,055:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-16 01:40:50,055:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:40:50,076:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:40:50,076:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:40:50,077:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-16 01:40:50,110:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:40:50,132:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:40:50,132:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:40:50,166:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:40:50,187:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:40:50,187:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:40:50,188:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-16 01:40:50,242:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:40:50,242:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:40:50,296:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:40:50,296:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:40:50,297:INFO:Preparing preprocessing pipeline...
2023-08-16 01:40:50,298:INFO:Set up simple imputation.
2023-08-16 01:40:50,312:INFO:Finished creating preprocessing pipeline.
2023-08-16 01:40:50,314:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\LMACCI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['CATAG3', 'HEALTH2', 'ANYHLTI2',
                                             'INCOME', 'POVERTY3', 'TOBFLAG',
                                             'MRJFLAG', 'PYUD5MRJ', 'MJYRTOT',
                                             'ALCFLAG', 'COCFLAG', 'CRKFLAG',
                                             'HERFLAG', 'LSDFLAG',
                                             'METHAMFLAG'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose=0))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose=0)))],
         verbose=False)
2023-08-16 01:40:50,314:INFO:Creating final display dataframe.
2023-08-16 01:40:50,359:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          ADSMMDEA
2                   Target type            Binary
3           Original data shape        (8845, 16)
4        Transformed data shape        (8845, 16)
5   Transformed train set shape        (6191, 16)
6    Transformed test set shape        (2654, 16)
7              Numeric features                15
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              e310
2023-08-16 01:40:50,420:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:40:50,421:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:40:50,477:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:40:50,477:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:40:50,478:INFO:setup() successfully completed in 0.59s...............
2023-08-16 01:41:07,323:INFO:PyCaret ClassificationExperiment
2023-08-16 01:41:07,323:INFO:Logging name: clf-default-name
2023-08-16 01:41:07,323:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-16 01:41:07,324:INFO:version 3.0.4
2023-08-16 01:41:07,324:INFO:Initializing setup()
2023-08-16 01:41:07,324:INFO:self.USI: cd2c
2023-08-16 01:41:07,324:INFO:self._variable_keys: {'logging_param', '_ml_usecase', 'n_jobs_param', 'exp_id', 'y_train', 'idx', 'fold_generator', 'memory', 'data', 'pipeline', 'fold_groups_param', 'fix_imbalance', 'USI', 'gpu_param', 'exp_name_log', 'gpu_n_jobs_param', 'X_train', 'X_test', 'X', 'y_test', '_available_plots', 'target_param', 'html_param', 'is_multiclass', 'fold_shuffle_param', 'log_plots_param', 'seed', 'y'}
2023-08-16 01:41:07,324:INFO:Checking environment
2023-08-16 01:41:07,324:INFO:python_version: 3.9.13
2023-08-16 01:41:07,324:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-08-16 01:41:07,324:INFO:machine: AMD64
2023-08-16 01:41:07,324:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-16 01:41:07,324:INFO:Memory: svmem(total=16905969664, available=1426755584, percent=91.6, used=15479214080, free=1426755584)
2023-08-16 01:41:07,324:INFO:Physical Core: 8
2023-08-16 01:41:07,324:INFO:Logical Core: 16
2023-08-16 01:41:07,324:INFO:Checking libraries
2023-08-16 01:41:07,324:INFO:System:
2023-08-16 01:41:07,325:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-08-16 01:41:07,325:INFO:executable: c:\Users\lmacciomaretto\anaconda3\python.exe
2023-08-16 01:41:07,325:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-16 01:41:07,325:INFO:PyCaret required dependencies:
2023-08-16 01:41:07,325:INFO:                 pip: 22.2.2
2023-08-16 01:41:07,325:INFO:          setuptools: 63.4.1
2023-08-16 01:41:07,325:INFO:             pycaret: 3.0.4
2023-08-16 01:41:07,325:INFO:             IPython: 7.31.1
2023-08-16 01:41:07,325:INFO:          ipywidgets: 7.6.5
2023-08-16 01:41:07,325:INFO:                tqdm: 4.64.1
2023-08-16 01:41:07,325:INFO:               numpy: 1.21.5
2023-08-16 01:41:07,325:INFO:              pandas: 1.4.4
2023-08-16 01:41:07,325:INFO:              jinja2: 2.11.3
2023-08-16 01:41:07,325:INFO:               scipy: 1.9.1
2023-08-16 01:41:07,325:INFO:              joblib: 1.3.2
2023-08-16 01:41:07,325:INFO:             sklearn: 1.0.2
2023-08-16 01:41:07,325:INFO:                pyod: 1.1.0
2023-08-16 01:41:07,325:INFO:            imblearn: 0.11.0
2023-08-16 01:41:07,325:INFO:   category_encoders: 2.6.2
2023-08-16 01:41:07,325:INFO:            lightgbm: 4.0.0
2023-08-16 01:41:07,326:INFO:               numba: 0.55.1
2023-08-16 01:41:07,326:INFO:            requests: 2.28.1
2023-08-16 01:41:07,326:INFO:          matplotlib: 3.5.2
2023-08-16 01:41:07,326:INFO:          scikitplot: 0.3.7
2023-08-16 01:41:07,326:INFO:         yellowbrick: 1.5
2023-08-16 01:41:07,326:INFO:              plotly: 5.9.0
2023-08-16 01:41:07,326:INFO:    plotly-resampler: Not installed
2023-08-16 01:41:07,327:INFO:             kaleido: 0.2.1
2023-08-16 01:41:07,327:INFO:           schemdraw: 0.15
2023-08-16 01:41:07,327:INFO:         statsmodels: 0.13.2
2023-08-16 01:41:07,327:INFO:              sktime: 0.21.0
2023-08-16 01:41:07,327:INFO:               tbats: 1.1.3
2023-08-16 01:41:07,327:INFO:            pmdarima: 2.0.3
2023-08-16 01:41:07,327:INFO:              psutil: 5.9.0
2023-08-16 01:41:07,327:INFO:          markupsafe: 2.0.1
2023-08-16 01:41:07,327:INFO:             pickle5: Not installed
2023-08-16 01:41:07,327:INFO:         cloudpickle: 2.0.0
2023-08-16 01:41:07,327:INFO:         deprecation: 2.1.0
2023-08-16 01:41:07,327:INFO:              xxhash: 3.3.0
2023-08-16 01:41:07,327:INFO:           wurlitzer: Not installed
2023-08-16 01:41:07,327:INFO:PyCaret optional dependencies:
2023-08-16 01:41:07,327:INFO:                shap: Not installed
2023-08-16 01:41:07,327:INFO:           interpret: Not installed
2023-08-16 01:41:07,327:INFO:                umap: Not installed
2023-08-16 01:41:07,327:INFO:    pandas_profiling: Not installed
2023-08-16 01:41:07,327:INFO:  explainerdashboard: Not installed
2023-08-16 01:41:07,327:INFO:             autoviz: Not installed
2023-08-16 01:41:07,327:INFO:           fairlearn: Not installed
2023-08-16 01:41:07,327:INFO:          deepchecks: Not installed
2023-08-16 01:41:07,328:INFO:             xgboost: Not installed
2023-08-16 01:41:07,328:INFO:            catboost: Not installed
2023-08-16 01:41:07,328:INFO:              kmodes: Not installed
2023-08-16 01:41:07,328:INFO:             mlxtend: Not installed
2023-08-16 01:41:07,328:INFO:       statsforecast: Not installed
2023-08-16 01:41:07,328:INFO:        tune_sklearn: Not installed
2023-08-16 01:41:07,328:INFO:                 ray: Not installed
2023-08-16 01:41:07,328:INFO:            hyperopt: Not installed
2023-08-16 01:41:07,328:INFO:              optuna: Not installed
2023-08-16 01:41:07,328:INFO:               skopt: Not installed
2023-08-16 01:41:07,328:INFO:              mlflow: Not installed
2023-08-16 01:41:07,328:INFO:              gradio: Not installed
2023-08-16 01:41:07,328:INFO:             fastapi: Not installed
2023-08-16 01:41:07,328:INFO:             uvicorn: Not installed
2023-08-16 01:41:07,328:INFO:              m2cgen: Not installed
2023-08-16 01:41:07,328:INFO:           evidently: Not installed
2023-08-16 01:41:07,328:INFO:               fugue: Not installed
2023-08-16 01:41:07,328:INFO:           streamlit: Not installed
2023-08-16 01:41:07,328:INFO:             prophet: Not installed
2023-08-16 01:41:07,329:INFO:None
2023-08-16 01:41:07,329:INFO:Set up data.
2023-08-16 01:41:07,334:INFO:Set up train/test split.
2023-08-16 01:41:07,339:INFO:Set up index.
2023-08-16 01:41:07,339:INFO:Set up folding strategy.
2023-08-16 01:41:07,339:INFO:Assigning column types.
2023-08-16 01:41:07,342:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-16 01:41:07,375:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-16 01:41:07,376:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:41:07,398:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:41:07,398:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:41:07,431:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-16 01:41:07,432:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:41:07,452:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:41:07,452:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:41:07,453:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-16 01:41:07,485:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:41:07,506:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:41:07,506:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:41:07,540:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:41:07,560:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:41:07,561:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:41:07,561:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-16 01:41:07,615:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:41:07,615:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:41:07,668:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:41:07,669:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:41:07,670:INFO:Preparing preprocessing pipeline...
2023-08-16 01:41:07,670:INFO:Set up simple imputation.
2023-08-16 01:41:07,683:INFO:Finished creating preprocessing pipeline.
2023-08-16 01:41:07,685:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\LMACCI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['CATAG3', 'HEALTH2', 'ANYHLTI2',
                                             'INCOME', 'POVERTY3', 'TOBFLAG',
                                             'MRJFLAG', 'PYUD5MRJ', 'MJYRTOT',
                                             'ALCFLAG', 'COCFLAG', 'CRKFLAG',
                                             'HERFLAG', 'LSDFLAG',
                                             'METHAMFLAG'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose=0))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose=0)))],
         verbose=False)
2023-08-16 01:41:07,685:INFO:Creating final display dataframe.
2023-08-16 01:41:07,728:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          ADSMMDEA
2                   Target type            Binary
3           Original data shape        (8845, 16)
4        Transformed data shape        (8845, 16)
5   Transformed train set shape        (6191, 16)
6    Transformed test set shape        (2654, 16)
7              Numeric features                15
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              cd2c
2023-08-16 01:41:07,789:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:41:07,789:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:41:07,846:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:41:07,846:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:41:07,846:INFO:setup() successfully completed in 0.58s...............
2023-08-16 01:41:11,772:INFO:Initializing compare_models()
2023-08-16 01:41:11,772:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586CEECE20>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002586CEECE20>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-16 01:41:11,772:INFO:Checking exceptions
2023-08-16 01:41:11,776:INFO:Preparing display monitor
2023-08-16 01:41:11,801:INFO:Initializing Logistic Regression
2023-08-16 01:41:11,801:INFO:Total runtime is 0.0 minutes
2023-08-16 01:41:11,805:INFO:SubProcess create_model() called ==================================
2023-08-16 01:41:11,805:INFO:Initializing create_model()
2023-08-16 01:41:11,805:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586CEECE20>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586C67D7F0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:41:11,805:INFO:Checking exceptions
2023-08-16 01:41:11,805:INFO:Importing libraries
2023-08-16 01:41:11,805:INFO:Copying training dataset
2023-08-16 01:41:11,810:INFO:Defining folds
2023-08-16 01:41:11,810:INFO:Declaring metric variables
2023-08-16 01:41:11,812:INFO:Importing untrained model
2023-08-16 01:41:11,815:INFO:Logistic Regression Imported successfully
2023-08-16 01:41:11,820:INFO:Starting cross validation
2023-08-16 01:41:11,820:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:41:12,568:INFO:Calculating mean and std
2023-08-16 01:41:12,569:INFO:Creating metrics dataframe
2023-08-16 01:41:12,648:INFO:Uploading results into container
2023-08-16 01:41:12,649:INFO:Uploading model into container now
2023-08-16 01:41:12,649:INFO:_master_model_container: 1
2023-08-16 01:41:12,649:INFO:_display_container: 2
2023-08-16 01:41:12,649:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-16 01:41:12,649:INFO:create_model() successfully completed......................................
2023-08-16 01:41:12,729:INFO:SubProcess create_model() end ==================================
2023-08-16 01:41:12,729:INFO:Creating metrics dataframe
2023-08-16 01:41:12,736:INFO:Initializing K Neighbors Classifier
2023-08-16 01:41:12,736:INFO:Total runtime is 0.01557542085647583 minutes
2023-08-16 01:41:12,738:INFO:SubProcess create_model() called ==================================
2023-08-16 01:41:12,738:INFO:Initializing create_model()
2023-08-16 01:41:12,738:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586CEECE20>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586C67D7F0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:41:12,738:INFO:Checking exceptions
2023-08-16 01:41:12,739:INFO:Importing libraries
2023-08-16 01:41:12,739:INFO:Copying training dataset
2023-08-16 01:41:12,743:INFO:Defining folds
2023-08-16 01:41:12,743:INFO:Declaring metric variables
2023-08-16 01:41:12,745:INFO:Importing untrained model
2023-08-16 01:41:12,748:INFO:K Neighbors Classifier Imported successfully
2023-08-16 01:41:12,752:INFO:Starting cross validation
2023-08-16 01:41:12,753:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:41:12,846:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:41:12,846:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:41:12,857:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:41:12,858:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:41:12,872:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:41:12,876:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:41:12,876:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:41:12,891:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:41:12,891:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:41:12,892:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:41:13,521:INFO:Calculating mean and std
2023-08-16 01:41:13,522:INFO:Creating metrics dataframe
2023-08-16 01:41:13,600:INFO:Uploading results into container
2023-08-16 01:41:13,600:INFO:Uploading model into container now
2023-08-16 01:41:13,600:INFO:_master_model_container: 2
2023-08-16 01:41:13,601:INFO:_display_container: 2
2023-08-16 01:41:13,601:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-16 01:41:13,601:INFO:create_model() successfully completed......................................
2023-08-16 01:41:13,667:INFO:SubProcess create_model() end ==================================
2023-08-16 01:41:13,667:INFO:Creating metrics dataframe
2023-08-16 01:41:13,673:INFO:Initializing Naive Bayes
2023-08-16 01:41:13,673:INFO:Total runtime is 0.031197245915730795 minutes
2023-08-16 01:41:13,675:INFO:SubProcess create_model() called ==================================
2023-08-16 01:41:13,675:INFO:Initializing create_model()
2023-08-16 01:41:13,675:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586CEECE20>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586C67D7F0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:41:13,675:INFO:Checking exceptions
2023-08-16 01:41:13,675:INFO:Importing libraries
2023-08-16 01:41:13,675:INFO:Copying training dataset
2023-08-16 01:41:13,680:INFO:Defining folds
2023-08-16 01:41:13,680:INFO:Declaring metric variables
2023-08-16 01:41:13,683:INFO:Importing untrained model
2023-08-16 01:41:13,686:INFO:Naive Bayes Imported successfully
2023-08-16 01:41:13,690:INFO:Starting cross validation
2023-08-16 01:41:13,690:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:41:14,379:INFO:Calculating mean and std
2023-08-16 01:41:14,380:INFO:Creating metrics dataframe
2023-08-16 01:41:14,451:INFO:Uploading results into container
2023-08-16 01:41:14,451:INFO:Uploading model into container now
2023-08-16 01:41:14,452:INFO:_master_model_container: 3
2023-08-16 01:41:14,452:INFO:_display_container: 2
2023-08-16 01:41:14,452:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-16 01:41:14,452:INFO:create_model() successfully completed......................................
2023-08-16 01:41:14,519:INFO:SubProcess create_model() end ==================================
2023-08-16 01:41:14,519:INFO:Creating metrics dataframe
2023-08-16 01:41:14,525:INFO:Initializing Decision Tree Classifier
2023-08-16 01:41:14,525:INFO:Total runtime is 0.0454023281733195 minutes
2023-08-16 01:41:14,528:INFO:SubProcess create_model() called ==================================
2023-08-16 01:41:14,528:INFO:Initializing create_model()
2023-08-16 01:41:14,528:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586CEECE20>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586C67D7F0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:41:14,528:INFO:Checking exceptions
2023-08-16 01:41:14,528:INFO:Importing libraries
2023-08-16 01:41:14,528:INFO:Copying training dataset
2023-08-16 01:41:14,533:INFO:Defining folds
2023-08-16 01:41:14,533:INFO:Declaring metric variables
2023-08-16 01:41:14,535:INFO:Importing untrained model
2023-08-16 01:41:14,538:INFO:Decision Tree Classifier Imported successfully
2023-08-16 01:41:14,542:INFO:Starting cross validation
2023-08-16 01:41:14,543:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:41:15,219:INFO:Calculating mean and std
2023-08-16 01:41:15,220:INFO:Creating metrics dataframe
2023-08-16 01:41:15,300:INFO:Uploading results into container
2023-08-16 01:41:15,301:INFO:Uploading model into container now
2023-08-16 01:41:15,301:INFO:_master_model_container: 4
2023-08-16 01:41:15,301:INFO:_display_container: 2
2023-08-16 01:41:15,302:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-08-16 01:41:15,302:INFO:create_model() successfully completed......................................
2023-08-16 01:41:15,368:INFO:SubProcess create_model() end ==================================
2023-08-16 01:41:15,369:INFO:Creating metrics dataframe
2023-08-16 01:41:15,375:INFO:Initializing SVM - Linear Kernel
2023-08-16 01:41:15,375:INFO:Total runtime is 0.05956843296686809 minutes
2023-08-16 01:41:15,378:INFO:SubProcess create_model() called ==================================
2023-08-16 01:41:15,378:INFO:Initializing create_model()
2023-08-16 01:41:15,378:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586CEECE20>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586C67D7F0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:41:15,378:INFO:Checking exceptions
2023-08-16 01:41:15,378:INFO:Importing libraries
2023-08-16 01:41:15,378:INFO:Copying training dataset
2023-08-16 01:41:15,383:INFO:Defining folds
2023-08-16 01:41:15,384:INFO:Declaring metric variables
2023-08-16 01:41:15,386:INFO:Importing untrained model
2023-08-16 01:41:15,389:INFO:SVM - Linear Kernel Imported successfully
2023-08-16 01:41:15,395:INFO:Starting cross validation
2023-08-16 01:41:15,396:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:41:15,458:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:41:15,462:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:41:15,475:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:41:15,480:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:41:15,481:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:41:15,483:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:41:15,483:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:41:15,485:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:41:15,492:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:41:15,503:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:41:16,092:INFO:Calculating mean and std
2023-08-16 01:41:16,093:INFO:Creating metrics dataframe
2023-08-16 01:41:16,167:INFO:Uploading results into container
2023-08-16 01:41:16,168:INFO:Uploading model into container now
2023-08-16 01:41:16,168:INFO:_master_model_container: 5
2023-08-16 01:41:16,168:INFO:_display_container: 2
2023-08-16 01:41:16,169:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-16 01:41:16,169:INFO:create_model() successfully completed......................................
2023-08-16 01:41:16,238:INFO:SubProcess create_model() end ==================================
2023-08-16 01:41:16,239:INFO:Creating metrics dataframe
2023-08-16 01:41:16,246:INFO:Initializing Ridge Classifier
2023-08-16 01:41:16,246:INFO:Total runtime is 0.07407280604044597 minutes
2023-08-16 01:41:16,248:INFO:SubProcess create_model() called ==================================
2023-08-16 01:41:16,249:INFO:Initializing create_model()
2023-08-16 01:41:16,249:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586CEECE20>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586C67D7F0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:41:16,249:INFO:Checking exceptions
2023-08-16 01:41:16,249:INFO:Importing libraries
2023-08-16 01:41:16,249:INFO:Copying training dataset
2023-08-16 01:41:16,254:INFO:Defining folds
2023-08-16 01:41:16,254:INFO:Declaring metric variables
2023-08-16 01:41:16,256:INFO:Importing untrained model
2023-08-16 01:41:16,259:INFO:Ridge Classifier Imported successfully
2023-08-16 01:41:16,263:INFO:Starting cross validation
2023-08-16 01:41:16,264:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:41:16,315:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:41:16,315:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:41:16,319:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:41:16,319:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:41:16,327:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:41:16,331:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:41:16,333:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:41:16,341:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:41:16,344:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:41:16,348:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:41:16,932:INFO:Calculating mean and std
2023-08-16 01:41:16,933:INFO:Creating metrics dataframe
2023-08-16 01:41:17,010:INFO:Uploading results into container
2023-08-16 01:41:17,011:INFO:Uploading model into container now
2023-08-16 01:41:17,012:INFO:_master_model_container: 6
2023-08-16 01:41:17,012:INFO:_display_container: 2
2023-08-16 01:41:17,012:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=123, solver='auto', tol=0.001)
2023-08-16 01:41:17,012:INFO:create_model() successfully completed......................................
2023-08-16 01:41:17,077:INFO:SubProcess create_model() end ==================================
2023-08-16 01:41:17,077:INFO:Creating metrics dataframe
2023-08-16 01:41:17,084:INFO:Initializing Random Forest Classifier
2023-08-16 01:41:17,084:INFO:Total runtime is 0.08804256518681845 minutes
2023-08-16 01:41:17,087:INFO:SubProcess create_model() called ==================================
2023-08-16 01:41:17,087:INFO:Initializing create_model()
2023-08-16 01:41:17,087:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586CEECE20>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586C67D7F0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:41:17,087:INFO:Checking exceptions
2023-08-16 01:41:17,087:INFO:Importing libraries
2023-08-16 01:41:17,087:INFO:Copying training dataset
2023-08-16 01:41:17,092:INFO:Defining folds
2023-08-16 01:41:17,092:INFO:Declaring metric variables
2023-08-16 01:41:17,094:INFO:Importing untrained model
2023-08-16 01:41:17,097:INFO:Random Forest Classifier Imported successfully
2023-08-16 01:41:17,101:INFO:Starting cross validation
2023-08-16 01:41:17,101:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:41:18,421:INFO:Calculating mean and std
2023-08-16 01:41:18,422:INFO:Creating metrics dataframe
2023-08-16 01:41:18,502:INFO:Uploading results into container
2023-08-16 01:41:18,503:INFO:Uploading model into container now
2023-08-16 01:41:18,504:INFO:_master_model_container: 7
2023-08-16 01:41:18,504:INFO:_display_container: 2
2023-08-16 01:41:18,504:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-08-16 01:41:18,504:INFO:create_model() successfully completed......................................
2023-08-16 01:41:18,579:INFO:SubProcess create_model() end ==================================
2023-08-16 01:41:18,579:INFO:Creating metrics dataframe
2023-08-16 01:41:18,588:INFO:Initializing Quadratic Discriminant Analysis
2023-08-16 01:41:18,588:INFO:Total runtime is 0.11311598618825278 minutes
2023-08-16 01:41:18,590:INFO:SubProcess create_model() called ==================================
2023-08-16 01:41:18,590:INFO:Initializing create_model()
2023-08-16 01:41:18,590:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586CEECE20>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586C67D7F0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:41:18,590:INFO:Checking exceptions
2023-08-16 01:41:18,590:INFO:Importing libraries
2023-08-16 01:41:18,590:INFO:Copying training dataset
2023-08-16 01:41:18,595:INFO:Defining folds
2023-08-16 01:41:18,595:INFO:Declaring metric variables
2023-08-16 01:41:18,598:INFO:Importing untrained model
2023-08-16 01:41:18,601:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-16 01:41:18,606:INFO:Starting cross validation
2023-08-16 01:41:18,607:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:41:18,649:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:41:18,656:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:41:18,658:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:41:18,665:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:41:18,672:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:41:18,675:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:41:18,681:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:18,681:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:18,681:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:41:18,683:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:18,683:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:18,683:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:41:18,685:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:18,685:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:18,686:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:41:18,689:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:18,690:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:18,690:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:41:18,691:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:18,691:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:18,691:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:41:18,694:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:18,694:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:18,695:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:41:18,696:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:18,696:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:18,696:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:41:18,697:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:41:18,701:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:41:18,702:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:18,703:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:18,703:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:41:18,703:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:18,703:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:18,704:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:41:18,704:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:41:18,705:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:41:18,708:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:41:18,708:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:41:18,709:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:18,709:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:41:18,710:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:18,710:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:41:18,713:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:18,713:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:18,714:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:41:18,715:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:41:18,718:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:41:18,719:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:41:18,719:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:41:18,719:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:18,719:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:18,720:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:41:18,721:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:41:18,722:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:18,722:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:18,722:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:41:18,722:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:41:18,724:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:41:18,725:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:18,726:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:18,726:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:41:18,733:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:18,734:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:18,734:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:41:18,736:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:18,736:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:18,737:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:41:18,738:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:18,738:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:18,738:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:41:18,739:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:41:18,739:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:18,739:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:18,740:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:41:18,740:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:41:18,742:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:41:18,742:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:41:18,748:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:18,748:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:18,748:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:41:18,750:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:41:18,751:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:41:18,755:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:18,755:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:18,755:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:41:18,756:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:41:18,759:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:41:19,341:INFO:Calculating mean and std
2023-08-16 01:41:19,342:INFO:Creating metrics dataframe
2023-08-16 01:41:19,418:INFO:Uploading results into container
2023-08-16 01:41:19,419:INFO:Uploading model into container now
2023-08-16 01:41:19,419:INFO:_master_model_container: 8
2023-08-16 01:41:19,419:INFO:_display_container: 2
2023-08-16 01:41:19,420:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-16 01:41:19,420:INFO:create_model() successfully completed......................................
2023-08-16 01:41:19,489:INFO:SubProcess create_model() end ==================================
2023-08-16 01:41:19,489:INFO:Creating metrics dataframe
2023-08-16 01:41:19,496:INFO:Initializing Ada Boost Classifier
2023-08-16 01:41:19,497:INFO:Total runtime is 0.12825731833775839 minutes
2023-08-16 01:41:19,499:INFO:SubProcess create_model() called ==================================
2023-08-16 01:41:19,499:INFO:Initializing create_model()
2023-08-16 01:41:19,499:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586CEECE20>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586C67D7F0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:41:19,499:INFO:Checking exceptions
2023-08-16 01:41:19,499:INFO:Importing libraries
2023-08-16 01:41:19,499:INFO:Copying training dataset
2023-08-16 01:41:19,504:INFO:Defining folds
2023-08-16 01:41:19,504:INFO:Declaring metric variables
2023-08-16 01:41:19,506:INFO:Importing untrained model
2023-08-16 01:41:19,509:INFO:Ada Boost Classifier Imported successfully
2023-08-16 01:41:19,513:INFO:Starting cross validation
2023-08-16 01:41:19,513:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:41:20,529:INFO:Calculating mean and std
2023-08-16 01:41:20,531:INFO:Creating metrics dataframe
2023-08-16 01:41:20,611:INFO:Uploading results into container
2023-08-16 01:41:20,612:INFO:Uploading model into container now
2023-08-16 01:41:20,612:INFO:_master_model_container: 9
2023-08-16 01:41:20,612:INFO:_display_container: 2
2023-08-16 01:41:20,613:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2023-08-16 01:41:20,613:INFO:create_model() successfully completed......................................
2023-08-16 01:41:20,679:INFO:SubProcess create_model() end ==================================
2023-08-16 01:41:20,679:INFO:Creating metrics dataframe
2023-08-16 01:41:20,686:INFO:Initializing Gradient Boosting Classifier
2023-08-16 01:41:20,687:INFO:Total runtime is 0.1480936845143636 minutes
2023-08-16 01:41:20,689:INFO:SubProcess create_model() called ==================================
2023-08-16 01:41:20,690:INFO:Initializing create_model()
2023-08-16 01:41:20,690:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586CEECE20>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586C67D7F0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:41:20,690:INFO:Checking exceptions
2023-08-16 01:41:20,690:INFO:Importing libraries
2023-08-16 01:41:20,690:INFO:Copying training dataset
2023-08-16 01:41:20,694:INFO:Defining folds
2023-08-16 01:41:20,694:INFO:Declaring metric variables
2023-08-16 01:41:20,697:INFO:Importing untrained model
2023-08-16 01:41:20,699:INFO:Gradient Boosting Classifier Imported successfully
2023-08-16 01:41:20,703:INFO:Starting cross validation
2023-08-16 01:41:20,704:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:41:21,896:INFO:Calculating mean and std
2023-08-16 01:41:21,897:INFO:Creating metrics dataframe
2023-08-16 01:41:21,980:INFO:Uploading results into container
2023-08-16 01:41:21,981:INFO:Uploading model into container now
2023-08-16 01:41:21,981:INFO:_master_model_container: 10
2023-08-16 01:41:21,981:INFO:_display_container: 2
2023-08-16 01:41:21,982:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-16 01:41:21,982:INFO:create_model() successfully completed......................................
2023-08-16 01:41:22,050:INFO:SubProcess create_model() end ==================================
2023-08-16 01:41:22,050:INFO:Creating metrics dataframe
2023-08-16 01:41:22,058:INFO:Initializing Linear Discriminant Analysis
2023-08-16 01:41:22,058:INFO:Total runtime is 0.17094546953837078 minutes
2023-08-16 01:41:22,061:INFO:SubProcess create_model() called ==================================
2023-08-16 01:41:22,061:INFO:Initializing create_model()
2023-08-16 01:41:22,061:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586CEECE20>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586C67D7F0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:41:22,061:INFO:Checking exceptions
2023-08-16 01:41:22,061:INFO:Importing libraries
2023-08-16 01:41:22,061:INFO:Copying training dataset
2023-08-16 01:41:22,066:INFO:Defining folds
2023-08-16 01:41:22,066:INFO:Declaring metric variables
2023-08-16 01:41:22,068:INFO:Importing untrained model
2023-08-16 01:41:22,071:INFO:Linear Discriminant Analysis Imported successfully
2023-08-16 01:41:22,076:INFO:Starting cross validation
2023-08-16 01:41:22,077:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:41:22,832:INFO:Calculating mean and std
2023-08-16 01:41:22,833:INFO:Creating metrics dataframe
2023-08-16 01:41:22,923:INFO:Uploading results into container
2023-08-16 01:41:22,923:INFO:Uploading model into container now
2023-08-16 01:41:22,924:INFO:_master_model_container: 11
2023-08-16 01:41:22,924:INFO:_display_container: 2
2023-08-16 01:41:22,924:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-16 01:41:22,924:INFO:create_model() successfully completed......................................
2023-08-16 01:41:22,998:INFO:SubProcess create_model() end ==================================
2023-08-16 01:41:22,998:INFO:Creating metrics dataframe
2023-08-16 01:41:23,009:INFO:Initializing Extra Trees Classifier
2023-08-16 01:41:23,009:INFO:Total runtime is 0.1867953697840373 minutes
2023-08-16 01:41:23,011:INFO:SubProcess create_model() called ==================================
2023-08-16 01:41:23,012:INFO:Initializing create_model()
2023-08-16 01:41:23,012:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586CEECE20>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586C67D7F0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:41:23,012:INFO:Checking exceptions
2023-08-16 01:41:23,012:INFO:Importing libraries
2023-08-16 01:41:23,012:INFO:Copying training dataset
2023-08-16 01:41:23,017:INFO:Defining folds
2023-08-16 01:41:23,017:INFO:Declaring metric variables
2023-08-16 01:41:23,020:INFO:Importing untrained model
2023-08-16 01:41:23,023:INFO:Extra Trees Classifier Imported successfully
2023-08-16 01:41:23,028:INFO:Starting cross validation
2023-08-16 01:41:23,029:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:41:24,505:INFO:Calculating mean and std
2023-08-16 01:41:24,506:INFO:Creating metrics dataframe
2023-08-16 01:41:24,600:INFO:Uploading results into container
2023-08-16 01:41:24,601:INFO:Uploading model into container now
2023-08-16 01:41:24,601:INFO:_master_model_container: 12
2023-08-16 01:41:24,601:INFO:_display_container: 2
2023-08-16 01:41:24,601:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-08-16 01:41:24,601:INFO:create_model() successfully completed......................................
2023-08-16 01:41:24,666:INFO:SubProcess create_model() end ==================================
2023-08-16 01:41:24,666:INFO:Creating metrics dataframe
2023-08-16 01:41:24,675:INFO:Initializing Light Gradient Boosting Machine
2023-08-16 01:41:24,675:INFO:Total runtime is 0.2145593563715617 minutes
2023-08-16 01:41:24,678:INFO:SubProcess create_model() called ==================================
2023-08-16 01:41:24,678:INFO:Initializing create_model()
2023-08-16 01:41:24,678:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586CEECE20>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586C67D7F0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:41:24,678:INFO:Checking exceptions
2023-08-16 01:41:24,678:INFO:Importing libraries
2023-08-16 01:41:24,678:INFO:Copying training dataset
2023-08-16 01:41:24,683:INFO:Defining folds
2023-08-16 01:41:24,683:INFO:Declaring metric variables
2023-08-16 01:41:24,686:INFO:Importing untrained model
2023-08-16 01:41:24,689:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-16 01:41:24,693:INFO:Starting cross validation
2023-08-16 01:41:24,693:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:41:26,463:INFO:Calculating mean and std
2023-08-16 01:41:26,464:INFO:Creating metrics dataframe
2023-08-16 01:41:26,558:INFO:Uploading results into container
2023-08-16 01:41:26,559:INFO:Uploading model into container now
2023-08-16 01:41:26,559:INFO:_master_model_container: 13
2023-08-16 01:41:26,559:INFO:_display_container: 2
2023-08-16 01:41:26,560:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-16 01:41:26,560:INFO:create_model() successfully completed......................................
2023-08-16 01:41:26,625:INFO:SubProcess create_model() end ==================================
2023-08-16 01:41:26,625:INFO:Creating metrics dataframe
2023-08-16 01:41:26,633:INFO:Initializing Dummy Classifier
2023-08-16 01:41:26,633:INFO:Total runtime is 0.247204061349233 minutes
2023-08-16 01:41:26,636:INFO:SubProcess create_model() called ==================================
2023-08-16 01:41:26,636:INFO:Initializing create_model()
2023-08-16 01:41:26,637:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586CEECE20>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586C67D7F0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:41:26,637:INFO:Checking exceptions
2023-08-16 01:41:26,637:INFO:Importing libraries
2023-08-16 01:41:26,637:INFO:Copying training dataset
2023-08-16 01:41:26,641:INFO:Defining folds
2023-08-16 01:41:26,642:INFO:Declaring metric variables
2023-08-16 01:41:26,644:INFO:Importing untrained model
2023-08-16 01:41:26,646:INFO:Dummy Classifier Imported successfully
2023-08-16 01:41:26,651:INFO:Starting cross validation
2023-08-16 01:41:26,652:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:41:26,704:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:41:26,711:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:41:26,718:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:41:26,718:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:41:26,722:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:41:26,729:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:41:26,735:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:41:26,736:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:41:26,741:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:41:26,752:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:41:27,495:INFO:Calculating mean and std
2023-08-16 01:41:27,496:INFO:Creating metrics dataframe
2023-08-16 01:41:27,589:INFO:Uploading results into container
2023-08-16 01:41:27,590:INFO:Uploading model into container now
2023-08-16 01:41:27,590:INFO:_master_model_container: 14
2023-08-16 01:41:27,590:INFO:_display_container: 2
2023-08-16 01:41:27,590:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-08-16 01:41:27,590:INFO:create_model() successfully completed......................................
2023-08-16 01:41:27,656:INFO:SubProcess create_model() end ==================================
2023-08-16 01:41:27,656:INFO:Creating metrics dataframe
2023-08-16 01:41:27,671:INFO:Initializing create_model()
2023-08-16 01:41:27,672:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586CEECE20>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:41:27,672:INFO:Checking exceptions
2023-08-16 01:41:27,673:INFO:Importing libraries
2023-08-16 01:41:27,673:INFO:Copying training dataset
2023-08-16 01:41:27,677:INFO:Defining folds
2023-08-16 01:41:27,677:INFO:Declaring metric variables
2023-08-16 01:41:27,677:INFO:Importing untrained model
2023-08-16 01:41:27,677:INFO:Declaring custom model
2023-08-16 01:41:27,678:INFO:Logistic Regression Imported successfully
2023-08-16 01:41:27,678:INFO:Cross validation set to False
2023-08-16 01:41:27,678:INFO:Fitting Model
2023-08-16 01:41:27,826:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-16 01:41:27,826:INFO:create_model() successfully completed......................................
2023-08-16 01:41:27,925:INFO:_master_model_container: 14
2023-08-16 01:41:27,925:INFO:_display_container: 2
2023-08-16 01:41:27,925:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-16 01:41:27,925:INFO:compare_models() successfully completed......................................
2023-08-16 01:41:51,442:INFO:Initializing compare_models()
2023-08-16 01:41:51,443:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586CEECE20>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002586CEECE20>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-16 01:41:51,443:INFO:Checking exceptions
2023-08-16 01:41:51,445:INFO:Preparing display monitor
2023-08-16 01:41:51,471:INFO:Initializing Logistic Regression
2023-08-16 01:41:51,471:INFO:Total runtime is 0.0 minutes
2023-08-16 01:41:51,473:INFO:SubProcess create_model() called ==================================
2023-08-16 01:41:51,474:INFO:Initializing create_model()
2023-08-16 01:41:51,474:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586CEECE20>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586C66FF40>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:41:51,474:INFO:Checking exceptions
2023-08-16 01:41:51,474:INFO:Importing libraries
2023-08-16 01:41:51,474:INFO:Copying training dataset
2023-08-16 01:41:51,480:INFO:Defining folds
2023-08-16 01:41:51,480:INFO:Declaring metric variables
2023-08-16 01:41:51,485:INFO:Importing untrained model
2023-08-16 01:41:51,491:INFO:Logistic Regression Imported successfully
2023-08-16 01:41:51,499:INFO:Starting cross validation
2023-08-16 01:41:51,500:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:41:52,380:INFO:Calculating mean and std
2023-08-16 01:41:52,380:INFO:Creating metrics dataframe
2023-08-16 01:41:52,471:INFO:Uploading results into container
2023-08-16 01:41:52,472:INFO:Uploading model into container now
2023-08-16 01:41:52,472:INFO:_master_model_container: 15
2023-08-16 01:41:52,472:INFO:_display_container: 3
2023-08-16 01:41:52,473:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-16 01:41:52,473:INFO:create_model() successfully completed......................................
2023-08-16 01:41:52,541:INFO:SubProcess create_model() end ==================================
2023-08-16 01:41:52,541:INFO:Creating metrics dataframe
2023-08-16 01:41:52,547:INFO:Initializing K Neighbors Classifier
2023-08-16 01:41:52,548:INFO:Total runtime is 0.017957170804341633 minutes
2023-08-16 01:41:52,551:INFO:SubProcess create_model() called ==================================
2023-08-16 01:41:52,551:INFO:Initializing create_model()
2023-08-16 01:41:52,552:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586CEECE20>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586C66FF40>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:41:52,552:INFO:Checking exceptions
2023-08-16 01:41:52,552:INFO:Importing libraries
2023-08-16 01:41:52,552:INFO:Copying training dataset
2023-08-16 01:41:52,556:INFO:Defining folds
2023-08-16 01:41:52,556:INFO:Declaring metric variables
2023-08-16 01:41:52,558:INFO:Importing untrained model
2023-08-16 01:41:52,560:INFO:K Neighbors Classifier Imported successfully
2023-08-16 01:41:52,564:INFO:Starting cross validation
2023-08-16 01:41:52,565:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:41:52,652:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:41:52,652:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:41:52,667:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:41:52,683:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:41:52,686:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:41:52,695:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:41:52,697:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:41:52,699:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:41:52,719:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:41:52,719:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:41:53,469:INFO:Calculating mean and std
2023-08-16 01:41:53,470:INFO:Creating metrics dataframe
2023-08-16 01:41:53,572:INFO:Uploading results into container
2023-08-16 01:41:53,572:INFO:Uploading model into container now
2023-08-16 01:41:53,573:INFO:_master_model_container: 16
2023-08-16 01:41:53,573:INFO:_display_container: 3
2023-08-16 01:41:53,573:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-16 01:41:53,574:INFO:create_model() successfully completed......................................
2023-08-16 01:41:53,658:INFO:SubProcess create_model() end ==================================
2023-08-16 01:41:53,658:INFO:Creating metrics dataframe
2023-08-16 01:41:53,666:INFO:Initializing Naive Bayes
2023-08-16 01:41:53,666:INFO:Total runtime is 0.036595141887664794 minutes
2023-08-16 01:41:53,668:INFO:SubProcess create_model() called ==================================
2023-08-16 01:41:53,669:INFO:Initializing create_model()
2023-08-16 01:41:53,669:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586CEECE20>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586C66FF40>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:41:53,669:INFO:Checking exceptions
2023-08-16 01:41:53,669:INFO:Importing libraries
2023-08-16 01:41:53,669:INFO:Copying training dataset
2023-08-16 01:41:53,673:INFO:Defining folds
2023-08-16 01:41:53,673:INFO:Declaring metric variables
2023-08-16 01:41:53,676:INFO:Importing untrained model
2023-08-16 01:41:53,679:INFO:Naive Bayes Imported successfully
2023-08-16 01:41:53,684:INFO:Starting cross validation
2023-08-16 01:41:53,685:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:41:54,533:INFO:Calculating mean and std
2023-08-16 01:41:54,534:INFO:Creating metrics dataframe
2023-08-16 01:41:54,624:INFO:Uploading results into container
2023-08-16 01:41:54,624:INFO:Uploading model into container now
2023-08-16 01:41:54,625:INFO:_master_model_container: 17
2023-08-16 01:41:54,625:INFO:_display_container: 3
2023-08-16 01:41:54,625:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-16 01:41:54,625:INFO:create_model() successfully completed......................................
2023-08-16 01:41:54,693:INFO:SubProcess create_model() end ==================================
2023-08-16 01:41:54,693:INFO:Creating metrics dataframe
2023-08-16 01:41:54,701:INFO:Initializing Decision Tree Classifier
2023-08-16 01:41:54,701:INFO:Total runtime is 0.053836735089619954 minutes
2023-08-16 01:41:54,703:INFO:SubProcess create_model() called ==================================
2023-08-16 01:41:54,704:INFO:Initializing create_model()
2023-08-16 01:41:54,704:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586CEECE20>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586C66FF40>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:41:54,704:INFO:Checking exceptions
2023-08-16 01:41:54,704:INFO:Importing libraries
2023-08-16 01:41:54,704:INFO:Copying training dataset
2023-08-16 01:41:54,708:INFO:Defining folds
2023-08-16 01:41:54,709:INFO:Declaring metric variables
2023-08-16 01:41:54,712:INFO:Importing untrained model
2023-08-16 01:41:54,715:INFO:Decision Tree Classifier Imported successfully
2023-08-16 01:41:54,719:INFO:Starting cross validation
2023-08-16 01:41:54,720:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:41:55,549:INFO:Calculating mean and std
2023-08-16 01:41:55,550:INFO:Creating metrics dataframe
2023-08-16 01:41:55,642:INFO:Uploading results into container
2023-08-16 01:41:55,643:INFO:Uploading model into container now
2023-08-16 01:41:55,644:INFO:_master_model_container: 18
2023-08-16 01:41:55,644:INFO:_display_container: 3
2023-08-16 01:41:55,644:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-08-16 01:41:55,645:INFO:create_model() successfully completed......................................
2023-08-16 01:41:55,713:INFO:SubProcess create_model() end ==================================
2023-08-16 01:41:55,713:INFO:Creating metrics dataframe
2023-08-16 01:41:55,720:INFO:Initializing SVM - Linear Kernel
2023-08-16 01:41:55,720:INFO:Total runtime is 0.0708180586496989 minutes
2023-08-16 01:41:55,722:INFO:SubProcess create_model() called ==================================
2023-08-16 01:41:55,722:INFO:Initializing create_model()
2023-08-16 01:41:55,722:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586CEECE20>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586C66FF40>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:41:55,722:INFO:Checking exceptions
2023-08-16 01:41:55,722:INFO:Importing libraries
2023-08-16 01:41:55,722:INFO:Copying training dataset
2023-08-16 01:41:55,728:INFO:Defining folds
2023-08-16 01:41:55,728:INFO:Declaring metric variables
2023-08-16 01:41:55,731:INFO:Importing untrained model
2023-08-16 01:41:55,733:INFO:SVM - Linear Kernel Imported successfully
2023-08-16 01:41:55,737:INFO:Starting cross validation
2023-08-16 01:41:55,739:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:41:55,816:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:41:55,819:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:41:55,820:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:41:55,829:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:41:55,832:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:41:55,838:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:41:55,839:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:41:55,851:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:41:55,857:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:41:55,862:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:41:56,591:INFO:Calculating mean and std
2023-08-16 01:41:56,592:INFO:Creating metrics dataframe
2023-08-16 01:41:56,686:INFO:Uploading results into container
2023-08-16 01:41:56,686:INFO:Uploading model into container now
2023-08-16 01:41:56,686:INFO:_master_model_container: 19
2023-08-16 01:41:56,686:INFO:_display_container: 3
2023-08-16 01:41:56,687:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-16 01:41:56,687:INFO:create_model() successfully completed......................................
2023-08-16 01:41:56,754:INFO:SubProcess create_model() end ==================================
2023-08-16 01:41:56,754:INFO:Creating metrics dataframe
2023-08-16 01:41:56,761:INFO:Initializing Ridge Classifier
2023-08-16 01:41:56,761:INFO:Total runtime is 0.08816688855489095 minutes
2023-08-16 01:41:56,763:INFO:SubProcess create_model() called ==================================
2023-08-16 01:41:56,764:INFO:Initializing create_model()
2023-08-16 01:41:56,764:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586CEECE20>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586C66FF40>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:41:56,764:INFO:Checking exceptions
2023-08-16 01:41:56,764:INFO:Importing libraries
2023-08-16 01:41:56,764:INFO:Copying training dataset
2023-08-16 01:41:56,769:INFO:Defining folds
2023-08-16 01:41:56,769:INFO:Declaring metric variables
2023-08-16 01:41:56,772:INFO:Importing untrained model
2023-08-16 01:41:56,775:INFO:Ridge Classifier Imported successfully
2023-08-16 01:41:56,779:INFO:Starting cross validation
2023-08-16 01:41:56,780:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:41:56,832:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:41:56,832:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:41:56,842:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:41:56,842:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:41:56,853:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:41:56,855:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:41:56,858:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:41:56,861:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:41:56,863:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:41:56,865:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:41:57,610:INFO:Calculating mean and std
2023-08-16 01:41:57,611:INFO:Creating metrics dataframe
2023-08-16 01:41:57,706:INFO:Uploading results into container
2023-08-16 01:41:57,707:INFO:Uploading model into container now
2023-08-16 01:41:57,707:INFO:_master_model_container: 20
2023-08-16 01:41:57,707:INFO:_display_container: 3
2023-08-16 01:41:57,707:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=123, solver='auto', tol=0.001)
2023-08-16 01:41:57,707:INFO:create_model() successfully completed......................................
2023-08-16 01:41:57,773:INFO:SubProcess create_model() end ==================================
2023-08-16 01:41:57,774:INFO:Creating metrics dataframe
2023-08-16 01:41:57,781:INFO:Initializing Random Forest Classifier
2023-08-16 01:41:57,781:INFO:Total runtime is 0.10517581701278686 minutes
2023-08-16 01:41:57,783:INFO:SubProcess create_model() called ==================================
2023-08-16 01:41:57,783:INFO:Initializing create_model()
2023-08-16 01:41:57,783:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586CEECE20>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586C66FF40>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:41:57,783:INFO:Checking exceptions
2023-08-16 01:41:57,783:INFO:Importing libraries
2023-08-16 01:41:57,783:INFO:Copying training dataset
2023-08-16 01:41:57,788:INFO:Defining folds
2023-08-16 01:41:57,788:INFO:Declaring metric variables
2023-08-16 01:41:57,790:INFO:Importing untrained model
2023-08-16 01:41:57,793:INFO:Random Forest Classifier Imported successfully
2023-08-16 01:41:57,797:INFO:Starting cross validation
2023-08-16 01:41:57,797:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:41:58,866:INFO:Calculating mean and std
2023-08-16 01:41:58,867:INFO:Creating metrics dataframe
2023-08-16 01:41:58,966:INFO:Uploading results into container
2023-08-16 01:41:58,966:INFO:Uploading model into container now
2023-08-16 01:41:58,967:INFO:_master_model_container: 21
2023-08-16 01:41:58,967:INFO:_display_container: 3
2023-08-16 01:41:58,967:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-08-16 01:41:58,967:INFO:create_model() successfully completed......................................
2023-08-16 01:41:59,037:INFO:SubProcess create_model() end ==================================
2023-08-16 01:41:59,037:INFO:Creating metrics dataframe
2023-08-16 01:41:59,045:INFO:Initializing Quadratic Discriminant Analysis
2023-08-16 01:41:59,045:INFO:Total runtime is 0.12623835007349649 minutes
2023-08-16 01:41:59,047:INFO:SubProcess create_model() called ==================================
2023-08-16 01:41:59,047:INFO:Initializing create_model()
2023-08-16 01:41:59,048:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586CEECE20>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586C66FF40>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:41:59,048:INFO:Checking exceptions
2023-08-16 01:41:59,048:INFO:Importing libraries
2023-08-16 01:41:59,048:INFO:Copying training dataset
2023-08-16 01:41:59,053:INFO:Defining folds
2023-08-16 01:41:59,054:INFO:Declaring metric variables
2023-08-16 01:41:59,056:INFO:Importing untrained model
2023-08-16 01:41:59,059:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-16 01:41:59,063:INFO:Starting cross validation
2023-08-16 01:41:59,064:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:41:59,104:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:41:59,109:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:41:59,109:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:41:59,113:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:41:59,116:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:41:59,119:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:59,119:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:59,119:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:41:59,123:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:59,123:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:59,123:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:41:59,127:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:59,127:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:59,128:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:41:59,128:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:41:59,128:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:59,128:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:59,128:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:41:59,129:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:59,129:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:59,130:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:41:59,130:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:59,130:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:41:59,130:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:59,130:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:41:59,131:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:41:59,132:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:41:59,136:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:41:59,139:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:41:59,140:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:59,141:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:59,141:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:59,141:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:41:59,141:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:41:59,141:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:41:59,141:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:59,142:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:59,142:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:41:59,142:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:59,142:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:59,142:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:41:59,142:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:41:59,143:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:41:59,143:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:41:59,145:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:59,145:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:59,146:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:41:59,146:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:41:59,147:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:59,147:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:59,147:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:41:59,147:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:41:59,148:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:41:59,150:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:41:59,151:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:41:59,151:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:59,151:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:59,151:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:41:59,152:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:59,152:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:59,152:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:41:59,152:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:41:59,152:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:59,153:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:59,153:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:59,153:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:41:59,153:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:59,154:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:41:59,154:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:59,154:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:59,154:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:41:59,155:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:41:59,155:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:41:59,164:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:59,164:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:59,164:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:41:59,165:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:41:59,167:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:41:59,167:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:59,167:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:59,167:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:59,167:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:41:59,167:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:41:59,167:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:41:59,168:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:41:59,169:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:41:59,170:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:41:59,171:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:41:59,909:INFO:Calculating mean and std
2023-08-16 01:41:59,910:INFO:Creating metrics dataframe
2023-08-16 01:42:00,007:INFO:Uploading results into container
2023-08-16 01:42:00,007:INFO:Uploading model into container now
2023-08-16 01:42:00,008:INFO:_master_model_container: 22
2023-08-16 01:42:00,008:INFO:_display_container: 3
2023-08-16 01:42:00,008:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-16 01:42:00,008:INFO:create_model() successfully completed......................................
2023-08-16 01:42:00,076:INFO:SubProcess create_model() end ==================================
2023-08-16 01:42:00,076:INFO:Creating metrics dataframe
2023-08-16 01:42:00,085:INFO:Initializing Ada Boost Classifier
2023-08-16 01:42:00,085:INFO:Total runtime is 0.1435789704322815 minutes
2023-08-16 01:42:00,088:INFO:SubProcess create_model() called ==================================
2023-08-16 01:42:00,088:INFO:Initializing create_model()
2023-08-16 01:42:00,088:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586CEECE20>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586C66FF40>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:42:00,088:INFO:Checking exceptions
2023-08-16 01:42:00,088:INFO:Importing libraries
2023-08-16 01:42:00,088:INFO:Copying training dataset
2023-08-16 01:42:00,093:INFO:Defining folds
2023-08-16 01:42:00,093:INFO:Declaring metric variables
2023-08-16 01:42:00,096:INFO:Importing untrained model
2023-08-16 01:42:00,099:INFO:Ada Boost Classifier Imported successfully
2023-08-16 01:42:00,104:INFO:Starting cross validation
2023-08-16 01:42:00,105:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:42:01,004:INFO:Calculating mean and std
2023-08-16 01:42:01,005:INFO:Creating metrics dataframe
2023-08-16 01:42:01,099:INFO:Uploading results into container
2023-08-16 01:42:01,100:INFO:Uploading model into container now
2023-08-16 01:42:01,100:INFO:_master_model_container: 23
2023-08-16 01:42:01,100:INFO:_display_container: 3
2023-08-16 01:42:01,100:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2023-08-16 01:42:01,100:INFO:create_model() successfully completed......................................
2023-08-16 01:42:01,171:INFO:SubProcess create_model() end ==================================
2023-08-16 01:42:01,171:INFO:Creating metrics dataframe
2023-08-16 01:42:01,179:INFO:Initializing Gradient Boosting Classifier
2023-08-16 01:42:01,179:INFO:Total runtime is 0.16180846293767293 minutes
2023-08-16 01:42:01,182:INFO:SubProcess create_model() called ==================================
2023-08-16 01:42:01,182:INFO:Initializing create_model()
2023-08-16 01:42:01,182:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586CEECE20>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586C66FF40>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:42:01,182:INFO:Checking exceptions
2023-08-16 01:42:01,182:INFO:Importing libraries
2023-08-16 01:42:01,182:INFO:Copying training dataset
2023-08-16 01:42:01,187:INFO:Defining folds
2023-08-16 01:42:01,187:INFO:Declaring metric variables
2023-08-16 01:42:01,189:INFO:Importing untrained model
2023-08-16 01:42:01,191:INFO:Gradient Boosting Classifier Imported successfully
2023-08-16 01:42:01,196:INFO:Starting cross validation
2023-08-16 01:42:01,197:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:42:02,098:INFO:Calculating mean and std
2023-08-16 01:42:02,099:INFO:Creating metrics dataframe
2023-08-16 01:42:02,189:INFO:Uploading results into container
2023-08-16 01:42:02,190:INFO:Uploading model into container now
2023-08-16 01:42:02,190:INFO:_master_model_container: 24
2023-08-16 01:42:02,190:INFO:_display_container: 3
2023-08-16 01:42:02,190:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-16 01:42:02,191:INFO:create_model() successfully completed......................................
2023-08-16 01:42:02,260:INFO:SubProcess create_model() end ==================================
2023-08-16 01:42:02,260:INFO:Creating metrics dataframe
2023-08-16 01:42:02,267:INFO:Initializing Linear Discriminant Analysis
2023-08-16 01:42:02,267:INFO:Total runtime is 0.1799462795257568 minutes
2023-08-16 01:42:02,269:INFO:SubProcess create_model() called ==================================
2023-08-16 01:42:02,269:INFO:Initializing create_model()
2023-08-16 01:42:02,269:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586CEECE20>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586C66FF40>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:42:02,270:INFO:Checking exceptions
2023-08-16 01:42:02,270:INFO:Importing libraries
2023-08-16 01:42:02,270:INFO:Copying training dataset
2023-08-16 01:42:02,274:INFO:Defining folds
2023-08-16 01:42:02,274:INFO:Declaring metric variables
2023-08-16 01:42:02,278:INFO:Importing untrained model
2023-08-16 01:42:02,281:INFO:Linear Discriminant Analysis Imported successfully
2023-08-16 01:42:02,285:INFO:Starting cross validation
2023-08-16 01:42:02,285:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:42:03,133:INFO:Calculating mean and std
2023-08-16 01:42:03,134:INFO:Creating metrics dataframe
2023-08-16 01:42:03,223:INFO:Uploading results into container
2023-08-16 01:42:03,224:INFO:Uploading model into container now
2023-08-16 01:42:03,224:INFO:_master_model_container: 25
2023-08-16 01:42:03,224:INFO:_display_container: 3
2023-08-16 01:42:03,225:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-16 01:42:03,225:INFO:create_model() successfully completed......................................
2023-08-16 01:42:03,289:INFO:SubProcess create_model() end ==================================
2023-08-16 01:42:03,289:INFO:Creating metrics dataframe
2023-08-16 01:42:03,297:INFO:Initializing Extra Trees Classifier
2023-08-16 01:42:03,297:INFO:Total runtime is 0.1971105098724365 minutes
2023-08-16 01:42:03,299:INFO:SubProcess create_model() called ==================================
2023-08-16 01:42:03,300:INFO:Initializing create_model()
2023-08-16 01:42:03,300:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586CEECE20>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586C66FF40>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:42:03,300:INFO:Checking exceptions
2023-08-16 01:42:03,300:INFO:Importing libraries
2023-08-16 01:42:03,300:INFO:Copying training dataset
2023-08-16 01:42:03,304:INFO:Defining folds
2023-08-16 01:42:03,304:INFO:Declaring metric variables
2023-08-16 01:42:03,307:INFO:Importing untrained model
2023-08-16 01:42:03,309:INFO:Extra Trees Classifier Imported successfully
2023-08-16 01:42:03,314:INFO:Starting cross validation
2023-08-16 01:42:03,315:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:42:04,419:INFO:Calculating mean and std
2023-08-16 01:42:04,420:INFO:Creating metrics dataframe
2023-08-16 01:42:04,518:INFO:Uploading results into container
2023-08-16 01:42:04,518:INFO:Uploading model into container now
2023-08-16 01:42:04,519:INFO:_master_model_container: 26
2023-08-16 01:42:04,519:INFO:_display_container: 3
2023-08-16 01:42:04,519:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-08-16 01:42:04,519:INFO:create_model() successfully completed......................................
2023-08-16 01:42:04,584:INFO:SubProcess create_model() end ==================================
2023-08-16 01:42:04,584:INFO:Creating metrics dataframe
2023-08-16 01:42:04,592:INFO:Initializing Light Gradient Boosting Machine
2023-08-16 01:42:04,592:INFO:Total runtime is 0.21869337161382038 minutes
2023-08-16 01:42:04,595:INFO:SubProcess create_model() called ==================================
2023-08-16 01:42:04,595:INFO:Initializing create_model()
2023-08-16 01:42:04,595:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586CEECE20>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586C66FF40>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:42:04,595:INFO:Checking exceptions
2023-08-16 01:42:04,595:INFO:Importing libraries
2023-08-16 01:42:04,595:INFO:Copying training dataset
2023-08-16 01:42:04,600:INFO:Defining folds
2023-08-16 01:42:04,600:INFO:Declaring metric variables
2023-08-16 01:42:04,603:INFO:Importing untrained model
2023-08-16 01:42:04,606:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-16 01:42:04,610:INFO:Starting cross validation
2023-08-16 01:42:04,611:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:42:05,531:INFO:Calculating mean and std
2023-08-16 01:42:05,532:INFO:Creating metrics dataframe
2023-08-16 01:42:05,626:INFO:Uploading results into container
2023-08-16 01:42:05,627:INFO:Uploading model into container now
2023-08-16 01:42:05,627:INFO:_master_model_container: 27
2023-08-16 01:42:05,627:INFO:_display_container: 3
2023-08-16 01:42:05,627:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-16 01:42:05,627:INFO:create_model() successfully completed......................................
2023-08-16 01:42:05,719:INFO:SubProcess create_model() end ==================================
2023-08-16 01:42:05,720:INFO:Creating metrics dataframe
2023-08-16 01:42:05,728:INFO:Initializing Dummy Classifier
2023-08-16 01:42:05,728:INFO:Total runtime is 0.23761833906173704 minutes
2023-08-16 01:42:05,731:INFO:SubProcess create_model() called ==================================
2023-08-16 01:42:05,731:INFO:Initializing create_model()
2023-08-16 01:42:05,731:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586CEECE20>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586C66FF40>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:42:05,731:INFO:Checking exceptions
2023-08-16 01:42:05,731:INFO:Importing libraries
2023-08-16 01:42:05,731:INFO:Copying training dataset
2023-08-16 01:42:05,736:INFO:Defining folds
2023-08-16 01:42:05,736:INFO:Declaring metric variables
2023-08-16 01:42:05,739:INFO:Importing untrained model
2023-08-16 01:42:05,744:INFO:Dummy Classifier Imported successfully
2023-08-16 01:42:05,748:INFO:Starting cross validation
2023-08-16 01:42:05,748:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:42:05,814:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:42:05,816:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:42:05,817:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:42:05,823:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:42:05,830:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:42:05,834:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:42:05,835:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:42:05,836:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:42:05,840:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:42:05,845:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:42:06,577:INFO:Calculating mean and std
2023-08-16 01:42:06,578:INFO:Creating metrics dataframe
2023-08-16 01:42:06,669:INFO:Uploading results into container
2023-08-16 01:42:06,670:INFO:Uploading model into container now
2023-08-16 01:42:06,670:INFO:_master_model_container: 28
2023-08-16 01:42:06,670:INFO:_display_container: 3
2023-08-16 01:42:06,671:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-08-16 01:42:06,671:INFO:create_model() successfully completed......................................
2023-08-16 01:42:06,739:INFO:SubProcess create_model() end ==================================
2023-08-16 01:42:06,739:INFO:Creating metrics dataframe
2023-08-16 01:42:06,754:INFO:Initializing create_model()
2023-08-16 01:42:06,754:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586CEECE20>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:42:06,754:INFO:Checking exceptions
2023-08-16 01:42:06,755:INFO:Importing libraries
2023-08-16 01:42:06,756:INFO:Copying training dataset
2023-08-16 01:42:06,759:INFO:Defining folds
2023-08-16 01:42:06,759:INFO:Declaring metric variables
2023-08-16 01:42:06,760:INFO:Importing untrained model
2023-08-16 01:42:06,760:INFO:Declaring custom model
2023-08-16 01:42:06,760:INFO:Logistic Regression Imported successfully
2023-08-16 01:42:06,760:INFO:Cross validation set to False
2023-08-16 01:42:06,760:INFO:Fitting Model
2023-08-16 01:42:06,885:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-16 01:42:06,885:INFO:create_model() successfully completed......................................
2023-08-16 01:42:06,980:INFO:_master_model_container: 28
2023-08-16 01:42:06,980:INFO:_display_container: 3
2023-08-16 01:42:06,980:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-16 01:42:06,980:INFO:compare_models() successfully completed......................................
2023-08-16 01:42:33,015:INFO:Initializing plot_model()
2023-08-16 01:42:33,015:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586CEECE20>, system=True)
2023-08-16 01:42:33,016:INFO:Checking exceptions
2023-08-16 01:42:33,020:INFO:Preloading libraries
2023-08-16 01:42:33,020:INFO:Copying training dataset
2023-08-16 01:42:33,020:INFO:Plot type: confusion_matrix
2023-08-16 01:42:33,072:INFO:Fitting Model
2023-08-16 01:42:33,072:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2023-08-16 01:42:33,072:INFO:Scoring test/hold-out set
2023-08-16 01:42:33,141:INFO:Visual Rendered Successfully
2023-08-16 01:42:33,226:INFO:plot_model() successfully completed......................................
2023-08-16 01:43:17,237:INFO:Initializing plot_model()
2023-08-16 01:43:17,237:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586CEECE20>, system=True)
2023-08-16 01:43:17,238:INFO:Checking exceptions
2023-08-16 01:43:17,244:INFO:Preloading libraries
2023-08-16 01:43:17,245:INFO:Copying training dataset
2023-08-16 01:43:17,245:INFO:Plot type: feature
2023-08-16 01:43:17,358:INFO:Visual Rendered Successfully
2023-08-16 01:43:17,427:INFO:plot_model() successfully completed......................................
2023-08-16 01:44:27,659:INFO:Initializing plot_model()
2023-08-16 01:44:27,659:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586CEECE20>, system=True)
2023-08-16 01:44:27,659:INFO:Checking exceptions
2023-08-16 01:44:27,663:INFO:Preloading libraries
2023-08-16 01:44:27,663:INFO:Copying training dataset
2023-08-16 01:44:27,663:INFO:Plot type: auc
2023-08-16 01:44:27,713:INFO:Fitting Model
2023-08-16 01:44:27,714:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2023-08-16 01:44:27,714:INFO:Scoring test/hold-out set
2023-08-16 01:44:27,826:INFO:Visual Rendered Successfully
2023-08-16 01:44:27,919:INFO:plot_model() successfully completed......................................
2023-08-16 01:46:06,660:INFO:PyCaret ClassificationExperiment
2023-08-16 01:46:06,661:INFO:Logging name: clf-default-name
2023-08-16 01:46:06,661:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-16 01:46:06,661:INFO:version 3.0.4
2023-08-16 01:46:06,661:INFO:Initializing setup()
2023-08-16 01:46:06,661:INFO:self.USI: bce8
2023-08-16 01:46:06,661:INFO:self._variable_keys: {'logging_param', '_ml_usecase', 'n_jobs_param', 'exp_id', 'y_train', 'idx', 'fold_generator', 'memory', 'data', 'pipeline', 'fold_groups_param', 'fix_imbalance', 'USI', 'gpu_param', 'exp_name_log', 'gpu_n_jobs_param', 'X_train', 'X_test', 'X', 'y_test', '_available_plots', 'target_param', 'html_param', 'is_multiclass', 'fold_shuffle_param', 'log_plots_param', 'seed', 'y'}
2023-08-16 01:46:06,661:INFO:Checking environment
2023-08-16 01:46:06,661:INFO:python_version: 3.9.13
2023-08-16 01:46:06,661:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-08-16 01:46:06,661:INFO:machine: AMD64
2023-08-16 01:46:06,661:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-16 01:46:06,662:INFO:Memory: svmem(total=16905969664, available=1439211520, percent=91.5, used=15466758144, free=1439211520)
2023-08-16 01:46:06,662:INFO:Physical Core: 8
2023-08-16 01:46:06,662:INFO:Logical Core: 16
2023-08-16 01:46:06,662:INFO:Checking libraries
2023-08-16 01:46:06,662:INFO:System:
2023-08-16 01:46:06,662:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-08-16 01:46:06,662:INFO:executable: c:\Users\lmacciomaretto\anaconda3\python.exe
2023-08-16 01:46:06,662:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-16 01:46:06,662:INFO:PyCaret required dependencies:
2023-08-16 01:46:06,662:INFO:                 pip: 22.2.2
2023-08-16 01:46:06,662:INFO:          setuptools: 63.4.1
2023-08-16 01:46:06,662:INFO:             pycaret: 3.0.4
2023-08-16 01:46:06,662:INFO:             IPython: 7.31.1
2023-08-16 01:46:06,662:INFO:          ipywidgets: 7.6.5
2023-08-16 01:46:06,662:INFO:                tqdm: 4.64.1
2023-08-16 01:46:06,662:INFO:               numpy: 1.21.5
2023-08-16 01:46:06,662:INFO:              pandas: 1.4.4
2023-08-16 01:46:06,662:INFO:              jinja2: 2.11.3
2023-08-16 01:46:06,662:INFO:               scipy: 1.9.1
2023-08-16 01:46:06,662:INFO:              joblib: 1.3.2
2023-08-16 01:46:06,662:INFO:             sklearn: 1.0.2
2023-08-16 01:46:06,663:INFO:                pyod: 1.1.0
2023-08-16 01:46:06,663:INFO:            imblearn: 0.11.0
2023-08-16 01:46:06,663:INFO:   category_encoders: 2.6.2
2023-08-16 01:46:06,663:INFO:            lightgbm: 4.0.0
2023-08-16 01:46:06,663:INFO:               numba: 0.55.1
2023-08-16 01:46:06,663:INFO:            requests: 2.28.1
2023-08-16 01:46:06,663:INFO:          matplotlib: 3.5.2
2023-08-16 01:46:06,663:INFO:          scikitplot: 0.3.7
2023-08-16 01:46:06,663:INFO:         yellowbrick: 1.5
2023-08-16 01:46:06,663:INFO:              plotly: 5.9.0
2023-08-16 01:46:06,663:INFO:    plotly-resampler: Not installed
2023-08-16 01:46:06,663:INFO:             kaleido: 0.2.1
2023-08-16 01:46:06,663:INFO:           schemdraw: 0.15
2023-08-16 01:46:06,663:INFO:         statsmodels: 0.13.2
2023-08-16 01:46:06,663:INFO:              sktime: 0.21.0
2023-08-16 01:46:06,663:INFO:               tbats: 1.1.3
2023-08-16 01:46:06,663:INFO:            pmdarima: 2.0.3
2023-08-16 01:46:06,663:INFO:              psutil: 5.9.0
2023-08-16 01:46:06,663:INFO:          markupsafe: 2.0.1
2023-08-16 01:46:06,663:INFO:             pickle5: Not installed
2023-08-16 01:46:06,663:INFO:         cloudpickle: 2.0.0
2023-08-16 01:46:06,663:INFO:         deprecation: 2.1.0
2023-08-16 01:46:06,663:INFO:              xxhash: 3.3.0
2023-08-16 01:46:06,663:INFO:           wurlitzer: Not installed
2023-08-16 01:46:06,663:INFO:PyCaret optional dependencies:
2023-08-16 01:46:06,663:INFO:                shap: Not installed
2023-08-16 01:46:06,663:INFO:           interpret: Not installed
2023-08-16 01:46:06,663:INFO:                umap: Not installed
2023-08-16 01:46:06,663:INFO:    pandas_profiling: Not installed
2023-08-16 01:46:06,664:INFO:  explainerdashboard: Not installed
2023-08-16 01:46:06,664:INFO:             autoviz: Not installed
2023-08-16 01:46:06,664:INFO:           fairlearn: Not installed
2023-08-16 01:46:06,664:INFO:          deepchecks: Not installed
2023-08-16 01:46:06,664:INFO:             xgboost: Not installed
2023-08-16 01:46:06,664:INFO:            catboost: Not installed
2023-08-16 01:46:06,664:INFO:              kmodes: Not installed
2023-08-16 01:46:06,664:INFO:             mlxtend: Not installed
2023-08-16 01:46:06,664:INFO:       statsforecast: Not installed
2023-08-16 01:46:06,664:INFO:        tune_sklearn: Not installed
2023-08-16 01:46:06,664:INFO:                 ray: Not installed
2023-08-16 01:46:06,664:INFO:            hyperopt: Not installed
2023-08-16 01:46:06,664:INFO:              optuna: Not installed
2023-08-16 01:46:06,664:INFO:               skopt: Not installed
2023-08-16 01:46:06,664:INFO:              mlflow: Not installed
2023-08-16 01:46:06,664:INFO:              gradio: Not installed
2023-08-16 01:46:06,664:INFO:             fastapi: Not installed
2023-08-16 01:46:06,664:INFO:             uvicorn: Not installed
2023-08-16 01:46:06,665:INFO:              m2cgen: Not installed
2023-08-16 01:46:06,665:INFO:           evidently: Not installed
2023-08-16 01:46:06,665:INFO:               fugue: Not installed
2023-08-16 01:46:06,665:INFO:           streamlit: Not installed
2023-08-16 01:46:06,665:INFO:             prophet: Not installed
2023-08-16 01:46:06,665:INFO:None
2023-08-16 01:46:06,665:INFO:Set up data.
2023-08-16 01:46:06,671:INFO:Set up train/test split.
2023-08-16 01:46:06,677:INFO:Set up index.
2023-08-16 01:46:06,677:INFO:Set up folding strategy.
2023-08-16 01:46:06,677:INFO:Assigning column types.
2023-08-16 01:46:06,681:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-16 01:46:06,713:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-16 01:46:06,714:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:46:06,734:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:46:06,735:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:46:06,767:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-16 01:46:06,767:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:46:06,787:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:46:06,787:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:46:06,788:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-16 01:46:06,821:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:46:06,841:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:46:06,842:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:46:06,875:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:46:06,895:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:46:06,895:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:46:06,895:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-16 01:46:06,948:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:46:06,949:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:46:07,002:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:46:07,002:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:46:07,003:INFO:Preparing preprocessing pipeline...
2023-08-16 01:46:07,004:INFO:Set up simple imputation.
2023-08-16 01:46:07,018:INFO:Finished creating preprocessing pipeline.
2023-08-16 01:46:07,023:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\LMACCI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['CATAG3', 'HEALTH2', 'ANYHLTI2',
                                             'INCOME', 'POVERTY3', 'TOBFLAG',
                                             'MRJFLAG', 'PYUD5MRJ', 'MJYRTOT',
                                             'ALCFLAG', 'COCFLAG', 'CRKFLAG',
                                             'HERFLAG', 'LSDFLAG',
                                             'METHAMFLAG'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose=0))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose=0)))],
         verbose=False)
2023-08-16 01:46:07,023:INFO:Creating final display dataframe.
2023-08-16 01:46:07,070:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          ADSMMDEA
2                   Target type            Binary
3           Original data shape       (11678, 16)
4        Transformed data shape       (11678, 16)
5   Transformed train set shape        (8174, 16)
6    Transformed test set shape        (3504, 16)
7              Numeric features                15
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              bce8
2023-08-16 01:46:07,138:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:46:07,138:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:46:07,194:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:46:07,194:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:46:07,195:INFO:setup() successfully completed in 0.6s...............
2023-08-16 01:47:00,981:INFO:PyCaret ClassificationExperiment
2023-08-16 01:47:00,981:INFO:Logging name: clf-default-name
2023-08-16 01:47:00,981:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-16 01:47:00,981:INFO:version 3.0.4
2023-08-16 01:47:00,981:INFO:Initializing setup()
2023-08-16 01:47:00,981:INFO:self.USI: 0a5e
2023-08-16 01:47:00,981:INFO:self._variable_keys: {'logging_param', '_ml_usecase', 'n_jobs_param', 'exp_id', 'y_train', 'idx', 'fold_generator', 'memory', 'data', 'pipeline', 'fold_groups_param', 'fix_imbalance', 'USI', 'gpu_param', 'exp_name_log', 'gpu_n_jobs_param', 'X_train', 'X_test', 'X', 'y_test', '_available_plots', 'target_param', 'html_param', 'is_multiclass', 'fold_shuffle_param', 'log_plots_param', 'seed', 'y'}
2023-08-16 01:47:00,981:INFO:Checking environment
2023-08-16 01:47:00,982:INFO:python_version: 3.9.13
2023-08-16 01:47:00,982:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-08-16 01:47:00,982:INFO:machine: AMD64
2023-08-16 01:47:00,982:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-16 01:47:00,982:INFO:Memory: svmem(total=16905969664, available=1386020864, percent=91.8, used=15519948800, free=1386020864)
2023-08-16 01:47:00,982:INFO:Physical Core: 8
2023-08-16 01:47:00,982:INFO:Logical Core: 16
2023-08-16 01:47:00,982:INFO:Checking libraries
2023-08-16 01:47:00,982:INFO:System:
2023-08-16 01:47:00,982:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-08-16 01:47:00,982:INFO:executable: c:\Users\lmacciomaretto\anaconda3\python.exe
2023-08-16 01:47:00,982:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-16 01:47:00,982:INFO:PyCaret required dependencies:
2023-08-16 01:47:00,983:INFO:                 pip: 22.2.2
2023-08-16 01:47:00,983:INFO:          setuptools: 63.4.1
2023-08-16 01:47:00,983:INFO:             pycaret: 3.0.4
2023-08-16 01:47:00,983:INFO:             IPython: 7.31.1
2023-08-16 01:47:00,983:INFO:          ipywidgets: 7.6.5
2023-08-16 01:47:00,983:INFO:                tqdm: 4.64.1
2023-08-16 01:47:00,983:INFO:               numpy: 1.21.5
2023-08-16 01:47:00,983:INFO:              pandas: 1.4.4
2023-08-16 01:47:00,983:INFO:              jinja2: 2.11.3
2023-08-16 01:47:00,983:INFO:               scipy: 1.9.1
2023-08-16 01:47:00,983:INFO:              joblib: 1.3.2
2023-08-16 01:47:00,983:INFO:             sklearn: 1.0.2
2023-08-16 01:47:00,983:INFO:                pyod: 1.1.0
2023-08-16 01:47:00,983:INFO:            imblearn: 0.11.0
2023-08-16 01:47:00,983:INFO:   category_encoders: 2.6.2
2023-08-16 01:47:00,983:INFO:            lightgbm: 4.0.0
2023-08-16 01:47:00,983:INFO:               numba: 0.55.1
2023-08-16 01:47:00,983:INFO:            requests: 2.28.1
2023-08-16 01:47:00,983:INFO:          matplotlib: 3.5.2
2023-08-16 01:47:00,983:INFO:          scikitplot: 0.3.7
2023-08-16 01:47:00,983:INFO:         yellowbrick: 1.5
2023-08-16 01:47:00,983:INFO:              plotly: 5.9.0
2023-08-16 01:47:00,983:INFO:    plotly-resampler: Not installed
2023-08-16 01:47:00,983:INFO:             kaleido: 0.2.1
2023-08-16 01:47:00,983:INFO:           schemdraw: 0.15
2023-08-16 01:47:00,983:INFO:         statsmodels: 0.13.2
2023-08-16 01:47:00,983:INFO:              sktime: 0.21.0
2023-08-16 01:47:00,983:INFO:               tbats: 1.1.3
2023-08-16 01:47:00,984:INFO:            pmdarima: 2.0.3
2023-08-16 01:47:00,984:INFO:              psutil: 5.9.0
2023-08-16 01:47:00,984:INFO:          markupsafe: 2.0.1
2023-08-16 01:47:00,984:INFO:             pickle5: Not installed
2023-08-16 01:47:00,984:INFO:         cloudpickle: 2.0.0
2023-08-16 01:47:00,984:INFO:         deprecation: 2.1.0
2023-08-16 01:47:00,985:INFO:              xxhash: 3.3.0
2023-08-16 01:47:00,985:INFO:           wurlitzer: Not installed
2023-08-16 01:47:00,985:INFO:PyCaret optional dependencies:
2023-08-16 01:47:00,985:INFO:                shap: Not installed
2023-08-16 01:47:00,985:INFO:           interpret: Not installed
2023-08-16 01:47:00,985:INFO:                umap: Not installed
2023-08-16 01:47:00,985:INFO:    pandas_profiling: Not installed
2023-08-16 01:47:00,985:INFO:  explainerdashboard: Not installed
2023-08-16 01:47:00,985:INFO:             autoviz: Not installed
2023-08-16 01:47:00,985:INFO:           fairlearn: Not installed
2023-08-16 01:47:00,985:INFO:          deepchecks: Not installed
2023-08-16 01:47:00,985:INFO:             xgboost: Not installed
2023-08-16 01:47:00,985:INFO:            catboost: Not installed
2023-08-16 01:47:00,985:INFO:              kmodes: Not installed
2023-08-16 01:47:00,985:INFO:             mlxtend: Not installed
2023-08-16 01:47:00,985:INFO:       statsforecast: Not installed
2023-08-16 01:47:00,985:INFO:        tune_sklearn: Not installed
2023-08-16 01:47:00,985:INFO:                 ray: Not installed
2023-08-16 01:47:00,985:INFO:            hyperopt: Not installed
2023-08-16 01:47:00,985:INFO:              optuna: Not installed
2023-08-16 01:47:00,985:INFO:               skopt: Not installed
2023-08-16 01:47:00,985:INFO:              mlflow: Not installed
2023-08-16 01:47:00,985:INFO:              gradio: Not installed
2023-08-16 01:47:00,986:INFO:             fastapi: Not installed
2023-08-16 01:47:00,986:INFO:             uvicorn: Not installed
2023-08-16 01:47:00,986:INFO:              m2cgen: Not installed
2023-08-16 01:47:00,986:INFO:           evidently: Not installed
2023-08-16 01:47:00,986:INFO:               fugue: Not installed
2023-08-16 01:47:00,986:INFO:           streamlit: Not installed
2023-08-16 01:47:00,986:INFO:             prophet: Not installed
2023-08-16 01:47:00,986:INFO:None
2023-08-16 01:47:00,986:INFO:Set up data.
2023-08-16 01:47:00,992:INFO:Set up train/test split.
2023-08-16 01:47:00,997:INFO:Set up index.
2023-08-16 01:47:00,998:INFO:Set up folding strategy.
2023-08-16 01:47:00,998:INFO:Assigning column types.
2023-08-16 01:47:01,001:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-16 01:47:01,034:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-16 01:47:01,035:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:47:01,055:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:47:01,056:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:47:01,088:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-16 01:47:01,089:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:47:01,109:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:47:01,110:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:47:01,110:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-16 01:47:01,143:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:47:01,164:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:47:01,164:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:47:01,198:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:47:01,218:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:47:01,218:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:47:01,218:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-16 01:47:01,272:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:47:01,272:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:47:01,325:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:47:01,325:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:47:01,326:INFO:Preparing preprocessing pipeline...
2023-08-16 01:47:01,327:INFO:Set up simple imputation.
2023-08-16 01:47:01,341:INFO:Finished creating preprocessing pipeline.
2023-08-16 01:47:01,343:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\LMACCI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['CATAG3', 'HEALTH2', 'ANYHLTI2',
                                             'INCOME', 'POVERTY3', 'TOBFLAG',
                                             'MRJFLAG', 'PYUD5MRJ', 'MJYRTOT',
                                             'ALCFLAG', 'COCFLAG', 'CRKFLAG',
                                             'HERFLAG', 'LSDFLAG',
                                             'METHAMFLAG'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose=0))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose=0)))],
         verbose=False)
2023-08-16 01:47:01,343:INFO:Creating final display dataframe.
2023-08-16 01:47:01,387:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          ADSMMDEA
2                   Target type            Binary
3           Original data shape       (11678, 16)
4        Transformed data shape       (11678, 16)
5   Transformed train set shape        (8174, 16)
6    Transformed test set shape        (3504, 16)
7              Numeric features                15
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              0a5e
2023-08-16 01:47:01,449:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:47:01,449:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:47:01,507:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:47:01,507:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:47:01,507:INFO:setup() successfully completed in 0.59s...............
2023-08-16 01:47:12,952:INFO:Initializing compare_models()
2023-08-16 01:47:12,952:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586D24F8B0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002586D24F8B0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-16 01:47:12,952:INFO:Checking exceptions
2023-08-16 01:47:12,956:INFO:Preparing display monitor
2023-08-16 01:47:12,984:INFO:Initializing Logistic Regression
2023-08-16 01:47:12,984:INFO:Total runtime is 0.0 minutes
2023-08-16 01:47:12,986:INFO:SubProcess create_model() called ==================================
2023-08-16 01:47:12,987:INFO:Initializing create_model()
2023-08-16 01:47:12,987:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586D24F8B0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586D0FFA00>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:47:12,987:INFO:Checking exceptions
2023-08-16 01:47:12,987:INFO:Importing libraries
2023-08-16 01:47:12,987:INFO:Copying training dataset
2023-08-16 01:47:12,992:INFO:Defining folds
2023-08-16 01:47:12,992:INFO:Declaring metric variables
2023-08-16 01:47:12,995:INFO:Importing untrained model
2023-08-16 01:47:12,997:INFO:Logistic Regression Imported successfully
2023-08-16 01:47:13,003:INFO:Starting cross validation
2023-08-16 01:47:13,003:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:47:19,474:INFO:Calculating mean and std
2023-08-16 01:47:19,475:INFO:Creating metrics dataframe
2023-08-16 01:47:19,568:INFO:Uploading results into container
2023-08-16 01:47:19,569:INFO:Uploading model into container now
2023-08-16 01:47:19,569:INFO:_master_model_container: 1
2023-08-16 01:47:19,569:INFO:_display_container: 2
2023-08-16 01:47:19,569:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-16 01:47:19,569:INFO:create_model() successfully completed......................................
2023-08-16 01:47:19,641:INFO:SubProcess create_model() end ==================================
2023-08-16 01:47:19,641:INFO:Creating metrics dataframe
2023-08-16 01:47:19,646:INFO:Initializing K Neighbors Classifier
2023-08-16 01:47:19,647:INFO:Total runtime is 0.11105101903279622 minutes
2023-08-16 01:47:19,648:INFO:SubProcess create_model() called ==================================
2023-08-16 01:47:19,648:INFO:Initializing create_model()
2023-08-16 01:47:19,648:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586D24F8B0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586D0FFA00>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:47:19,648:INFO:Checking exceptions
2023-08-16 01:47:19,648:INFO:Importing libraries
2023-08-16 01:47:19,648:INFO:Copying training dataset
2023-08-16 01:47:19,653:INFO:Defining folds
2023-08-16 01:47:19,653:INFO:Declaring metric variables
2023-08-16 01:47:19,655:INFO:Importing untrained model
2023-08-16 01:47:19,658:INFO:K Neighbors Classifier Imported successfully
2023-08-16 01:47:19,662:INFO:Starting cross validation
2023-08-16 01:47:19,663:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:47:19,800:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:47:19,815:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:47:19,816:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:47:19,824:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:47:23,011:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:47:23,026:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:47:23,026:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:47:23,046:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:47:23,064:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:47:23,091:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:47:23,514:INFO:Calculating mean and std
2023-08-16 01:47:23,516:INFO:Creating metrics dataframe
2023-08-16 01:47:23,608:INFO:Uploading results into container
2023-08-16 01:47:23,610:INFO:Uploading model into container now
2023-08-16 01:47:23,611:INFO:_master_model_container: 2
2023-08-16 01:47:23,611:INFO:_display_container: 2
2023-08-16 01:47:23,611:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-16 01:47:23,611:INFO:create_model() successfully completed......................................
2023-08-16 01:47:23,674:INFO:SubProcess create_model() end ==================================
2023-08-16 01:47:23,676:INFO:Creating metrics dataframe
2023-08-16 01:47:23,682:INFO:Initializing Naive Bayes
2023-08-16 01:47:23,682:INFO:Total runtime is 0.17831154664357501 minutes
2023-08-16 01:47:23,685:INFO:SubProcess create_model() called ==================================
2023-08-16 01:47:23,685:INFO:Initializing create_model()
2023-08-16 01:47:23,685:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586D24F8B0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586D0FFA00>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:47:23,685:INFO:Checking exceptions
2023-08-16 01:47:23,685:INFO:Importing libraries
2023-08-16 01:47:23,685:INFO:Copying training dataset
2023-08-16 01:47:23,690:INFO:Defining folds
2023-08-16 01:47:23,690:INFO:Declaring metric variables
2023-08-16 01:47:23,693:INFO:Importing untrained model
2023-08-16 01:47:23,695:INFO:Naive Bayes Imported successfully
2023-08-16 01:47:23,700:INFO:Starting cross validation
2023-08-16 01:47:23,701:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:47:24,559:INFO:Calculating mean and std
2023-08-16 01:47:24,560:INFO:Creating metrics dataframe
2023-08-16 01:47:24,654:INFO:Uploading results into container
2023-08-16 01:47:24,654:INFO:Uploading model into container now
2023-08-16 01:47:24,654:INFO:_master_model_container: 3
2023-08-16 01:47:24,654:INFO:_display_container: 2
2023-08-16 01:47:24,655:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-16 01:47:24,655:INFO:create_model() successfully completed......................................
2023-08-16 01:47:24,720:INFO:SubProcess create_model() end ==================================
2023-08-16 01:47:24,720:INFO:Creating metrics dataframe
2023-08-16 01:47:24,727:INFO:Initializing Decision Tree Classifier
2023-08-16 01:47:24,727:INFO:Total runtime is 0.19571900367736814 minutes
2023-08-16 01:47:24,729:INFO:SubProcess create_model() called ==================================
2023-08-16 01:47:24,730:INFO:Initializing create_model()
2023-08-16 01:47:24,730:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586D24F8B0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586D0FFA00>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:47:24,730:INFO:Checking exceptions
2023-08-16 01:47:24,730:INFO:Importing libraries
2023-08-16 01:47:24,730:INFO:Copying training dataset
2023-08-16 01:47:24,736:INFO:Defining folds
2023-08-16 01:47:24,736:INFO:Declaring metric variables
2023-08-16 01:47:24,738:INFO:Importing untrained model
2023-08-16 01:47:24,741:INFO:Decision Tree Classifier Imported successfully
2023-08-16 01:47:24,746:INFO:Starting cross validation
2023-08-16 01:47:24,747:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:47:25,608:INFO:Calculating mean and std
2023-08-16 01:47:25,609:INFO:Creating metrics dataframe
2023-08-16 01:47:25,705:INFO:Uploading results into container
2023-08-16 01:47:25,706:INFO:Uploading model into container now
2023-08-16 01:47:25,706:INFO:_master_model_container: 4
2023-08-16 01:47:25,706:INFO:_display_container: 2
2023-08-16 01:47:25,706:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-08-16 01:47:25,706:INFO:create_model() successfully completed......................................
2023-08-16 01:47:25,774:INFO:SubProcess create_model() end ==================================
2023-08-16 01:47:25,774:INFO:Creating metrics dataframe
2023-08-16 01:47:25,781:INFO:Initializing SVM - Linear Kernel
2023-08-16 01:47:25,782:INFO:Total runtime is 0.21330858469009398 minutes
2023-08-16 01:47:25,784:INFO:SubProcess create_model() called ==================================
2023-08-16 01:47:25,784:INFO:Initializing create_model()
2023-08-16 01:47:25,784:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586D24F8B0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586D0FFA00>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:47:25,784:INFO:Checking exceptions
2023-08-16 01:47:25,784:INFO:Importing libraries
2023-08-16 01:47:25,784:INFO:Copying training dataset
2023-08-16 01:47:25,789:INFO:Defining folds
2023-08-16 01:47:25,789:INFO:Declaring metric variables
2023-08-16 01:47:25,792:INFO:Importing untrained model
2023-08-16 01:47:25,796:INFO:SVM - Linear Kernel Imported successfully
2023-08-16 01:47:25,801:INFO:Starting cross validation
2023-08-16 01:47:25,802:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:47:25,880:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:47:25,890:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:47:25,898:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:47:25,910:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:47:25,914:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:47:25,919:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:47:25,923:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:47:25,923:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:47:25,932:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:47:25,936:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:47:26,687:INFO:Calculating mean and std
2023-08-16 01:47:26,688:INFO:Creating metrics dataframe
2023-08-16 01:47:26,778:INFO:Uploading results into container
2023-08-16 01:47:26,778:INFO:Uploading model into container now
2023-08-16 01:47:26,779:INFO:_master_model_container: 5
2023-08-16 01:47:26,779:INFO:_display_container: 2
2023-08-16 01:47:26,779:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-16 01:47:26,779:INFO:create_model() successfully completed......................................
2023-08-16 01:47:26,848:INFO:SubProcess create_model() end ==================================
2023-08-16 01:47:26,848:INFO:Creating metrics dataframe
2023-08-16 01:47:26,854:INFO:Initializing Ridge Classifier
2023-08-16 01:47:26,854:INFO:Total runtime is 0.23117986520131428 minutes
2023-08-16 01:47:26,856:INFO:SubProcess create_model() called ==================================
2023-08-16 01:47:26,857:INFO:Initializing create_model()
2023-08-16 01:47:26,857:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586D24F8B0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586D0FFA00>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:47:26,857:INFO:Checking exceptions
2023-08-16 01:47:26,857:INFO:Importing libraries
2023-08-16 01:47:26,857:INFO:Copying training dataset
2023-08-16 01:47:26,862:INFO:Defining folds
2023-08-16 01:47:26,863:INFO:Declaring metric variables
2023-08-16 01:47:26,865:INFO:Importing untrained model
2023-08-16 01:47:26,868:INFO:Ridge Classifier Imported successfully
2023-08-16 01:47:26,872:INFO:Starting cross validation
2023-08-16 01:47:26,873:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:47:26,936:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:47:26,939:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:47:26,945:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:47:26,950:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:47:26,952:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:47:26,952:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:47:26,953:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:47:26,956:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:47:26,963:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:47:26,970:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:47:27,730:INFO:Calculating mean and std
2023-08-16 01:47:27,732:INFO:Creating metrics dataframe
2023-08-16 01:47:27,826:INFO:Uploading results into container
2023-08-16 01:47:27,828:INFO:Uploading model into container now
2023-08-16 01:47:27,828:INFO:_master_model_container: 6
2023-08-16 01:47:27,828:INFO:_display_container: 2
2023-08-16 01:47:27,828:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=123, solver='auto', tol=0.001)
2023-08-16 01:47:27,828:INFO:create_model() successfully completed......................................
2023-08-16 01:47:27,892:INFO:SubProcess create_model() end ==================================
2023-08-16 01:47:27,892:INFO:Creating metrics dataframe
2023-08-16 01:47:27,899:INFO:Initializing Random Forest Classifier
2023-08-16 01:47:27,900:INFO:Total runtime is 0.24859857161839802 minutes
2023-08-16 01:47:27,902:INFO:SubProcess create_model() called ==================================
2023-08-16 01:47:27,902:INFO:Initializing create_model()
2023-08-16 01:47:27,902:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586D24F8B0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586D0FFA00>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:47:27,902:INFO:Checking exceptions
2023-08-16 01:47:27,902:INFO:Importing libraries
2023-08-16 01:47:27,902:INFO:Copying training dataset
2023-08-16 01:47:27,907:INFO:Defining folds
2023-08-16 01:47:27,907:INFO:Declaring metric variables
2023-08-16 01:47:27,910:INFO:Importing untrained model
2023-08-16 01:47:27,913:INFO:Random Forest Classifier Imported successfully
2023-08-16 01:47:27,917:INFO:Starting cross validation
2023-08-16 01:47:27,918:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:47:29,532:INFO:Calculating mean and std
2023-08-16 01:47:29,534:INFO:Creating metrics dataframe
2023-08-16 01:47:29,652:INFO:Uploading results into container
2023-08-16 01:47:29,653:INFO:Uploading model into container now
2023-08-16 01:47:29,653:INFO:_master_model_container: 7
2023-08-16 01:47:29,653:INFO:_display_container: 2
2023-08-16 01:47:29,654:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-08-16 01:47:29,654:INFO:create_model() successfully completed......................................
2023-08-16 01:47:29,730:INFO:SubProcess create_model() end ==================================
2023-08-16 01:47:29,730:INFO:Creating metrics dataframe
2023-08-16 01:47:29,737:INFO:Initializing Quadratic Discriminant Analysis
2023-08-16 01:47:29,738:INFO:Total runtime is 0.27923735380172726 minutes
2023-08-16 01:47:29,740:INFO:SubProcess create_model() called ==================================
2023-08-16 01:47:29,741:INFO:Initializing create_model()
2023-08-16 01:47:29,741:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586D24F8B0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586D0FFA00>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:47:29,741:INFO:Checking exceptions
2023-08-16 01:47:29,741:INFO:Importing libraries
2023-08-16 01:47:29,741:INFO:Copying training dataset
2023-08-16 01:47:29,745:INFO:Defining folds
2023-08-16 01:47:29,745:INFO:Declaring metric variables
2023-08-16 01:47:29,747:INFO:Importing untrained model
2023-08-16 01:47:29,750:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-16 01:47:29,754:INFO:Starting cross validation
2023-08-16 01:47:29,754:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:47:29,802:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:47:29,810:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:47:29,816:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:47:29,816:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:47:29,816:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:47:29,822:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:47:29,826:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:47:29,827:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:47:29,828:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:47:29,829:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:47:29,829:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:47:29,831:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:47:29,836:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:47:29,836:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:47:29,836:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:47:29,839:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:47:29,839:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:47:29,840:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:47:29,841:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:47:29,844:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:47:29,844:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:47:29,845:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:47:29,845:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:47:29,846:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:47:29,846:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:47:29,846:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:47:29,848:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:47:29,848:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:47:29,848:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:47:29,849:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:47:29,849:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:47:29,853:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:47:29,853:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:47:29,853:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:47:29,854:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:47:29,856:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:47:29,856:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:47:29,861:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:47:29,861:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:47:29,862:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:47:29,865:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:47:29,865:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:47:29,865:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:47:29,866:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:47:29,867:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:47:29,867:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:47:29,867:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:47:29,867:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:47:29,867:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:47:29,867:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:47:29,868:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:47:29,870:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:47:29,870:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:47:29,870:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:47:29,870:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:47:29,871:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:47:29,874:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:47:29,874:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:47:29,875:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:47:29,875:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:47:29,875:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:47:29,875:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:47:29,878:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:47:29,879:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:47:29,879:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:47:29,880:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:47:29,882:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:47:29,882:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:47:29,882:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:47:29,883:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:47:29,883:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:47:29,883:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:47:29,885:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:47:29,887:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:47:29,887:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:47:29,888:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:47:29,890:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:47:29,891:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:47:29,895:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:47:29,897:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:47:29,897:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:47:29,898:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:47:29,899:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:47:29,899:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:47:29,899:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:47:29,900:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:47:29,901:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:47:29,903:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:47:29,905:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:47:30,675:INFO:Calculating mean and std
2023-08-16 01:47:30,676:INFO:Creating metrics dataframe
2023-08-16 01:47:30,777:INFO:Uploading results into container
2023-08-16 01:47:30,778:INFO:Uploading model into container now
2023-08-16 01:47:30,778:INFO:_master_model_container: 8
2023-08-16 01:47:30,778:INFO:_display_container: 2
2023-08-16 01:47:30,778:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-16 01:47:30,778:INFO:create_model() successfully completed......................................
2023-08-16 01:47:30,852:INFO:SubProcess create_model() end ==================================
2023-08-16 01:47:30,853:INFO:Creating metrics dataframe
2023-08-16 01:47:30,860:INFO:Initializing Ada Boost Classifier
2023-08-16 01:47:30,860:INFO:Total runtime is 0.29793507655461626 minutes
2023-08-16 01:47:30,862:INFO:SubProcess create_model() called ==================================
2023-08-16 01:47:30,862:INFO:Initializing create_model()
2023-08-16 01:47:30,862:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586D24F8B0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586D0FFA00>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:47:30,863:INFO:Checking exceptions
2023-08-16 01:47:30,863:INFO:Importing libraries
2023-08-16 01:47:30,863:INFO:Copying training dataset
2023-08-16 01:47:30,867:INFO:Defining folds
2023-08-16 01:47:30,867:INFO:Declaring metric variables
2023-08-16 01:47:30,869:INFO:Importing untrained model
2023-08-16 01:47:30,871:INFO:Ada Boost Classifier Imported successfully
2023-08-16 01:47:30,876:INFO:Starting cross validation
2023-08-16 01:47:30,876:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:47:32,103:INFO:Calculating mean and std
2023-08-16 01:47:32,104:INFO:Creating metrics dataframe
2023-08-16 01:47:32,211:INFO:Uploading results into container
2023-08-16 01:47:32,211:INFO:Uploading model into container now
2023-08-16 01:47:32,212:INFO:_master_model_container: 9
2023-08-16 01:47:32,212:INFO:_display_container: 2
2023-08-16 01:47:32,212:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2023-08-16 01:47:32,212:INFO:create_model() successfully completed......................................
2023-08-16 01:47:32,277:INFO:SubProcess create_model() end ==================================
2023-08-16 01:47:32,277:INFO:Creating metrics dataframe
2023-08-16 01:47:32,287:INFO:Initializing Gradient Boosting Classifier
2023-08-16 01:47:32,287:INFO:Total runtime is 0.32172480026880895 minutes
2023-08-16 01:47:32,289:INFO:SubProcess create_model() called ==================================
2023-08-16 01:47:32,289:INFO:Initializing create_model()
2023-08-16 01:47:32,289:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586D24F8B0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586D0FFA00>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:47:32,290:INFO:Checking exceptions
2023-08-16 01:47:32,290:INFO:Importing libraries
2023-08-16 01:47:32,290:INFO:Copying training dataset
2023-08-16 01:47:32,294:INFO:Defining folds
2023-08-16 01:47:32,294:INFO:Declaring metric variables
2023-08-16 01:47:32,296:INFO:Importing untrained model
2023-08-16 01:47:32,299:INFO:Gradient Boosting Classifier Imported successfully
2023-08-16 01:47:32,303:INFO:Starting cross validation
2023-08-16 01:47:32,303:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:47:33,794:INFO:Calculating mean and std
2023-08-16 01:47:33,795:INFO:Creating metrics dataframe
2023-08-16 01:47:33,901:INFO:Uploading results into container
2023-08-16 01:47:33,901:INFO:Uploading model into container now
2023-08-16 01:47:33,902:INFO:_master_model_container: 10
2023-08-16 01:47:33,902:INFO:_display_container: 2
2023-08-16 01:47:33,902:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-16 01:47:33,902:INFO:create_model() successfully completed......................................
2023-08-16 01:47:33,969:INFO:SubProcess create_model() end ==================================
2023-08-16 01:47:33,969:INFO:Creating metrics dataframe
2023-08-16 01:47:33,977:INFO:Initializing Linear Discriminant Analysis
2023-08-16 01:47:33,977:INFO:Total runtime is 0.3498928586641947 minutes
2023-08-16 01:47:33,980:INFO:SubProcess create_model() called ==================================
2023-08-16 01:47:33,981:INFO:Initializing create_model()
2023-08-16 01:47:33,981:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586D24F8B0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586D0FFA00>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:47:33,981:INFO:Checking exceptions
2023-08-16 01:47:33,981:INFO:Importing libraries
2023-08-16 01:47:33,981:INFO:Copying training dataset
2023-08-16 01:47:33,985:INFO:Defining folds
2023-08-16 01:47:33,985:INFO:Declaring metric variables
2023-08-16 01:47:33,987:INFO:Importing untrained model
2023-08-16 01:47:33,989:INFO:Linear Discriminant Analysis Imported successfully
2023-08-16 01:47:33,994:INFO:Starting cross validation
2023-08-16 01:47:33,994:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:47:34,989:INFO:Calculating mean and std
2023-08-16 01:47:34,991:INFO:Creating metrics dataframe
2023-08-16 01:47:35,097:INFO:Uploading results into container
2023-08-16 01:47:35,097:INFO:Uploading model into container now
2023-08-16 01:47:35,098:INFO:_master_model_container: 11
2023-08-16 01:47:35,098:INFO:_display_container: 2
2023-08-16 01:47:35,098:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-16 01:47:35,098:INFO:create_model() successfully completed......................................
2023-08-16 01:47:35,163:INFO:SubProcess create_model() end ==================================
2023-08-16 01:47:35,163:INFO:Creating metrics dataframe
2023-08-16 01:47:35,171:INFO:Initializing Extra Trees Classifier
2023-08-16 01:47:35,171:INFO:Total runtime is 0.36979276339213046 minutes
2023-08-16 01:47:35,174:INFO:SubProcess create_model() called ==================================
2023-08-16 01:47:35,174:INFO:Initializing create_model()
2023-08-16 01:47:35,174:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586D24F8B0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586D0FFA00>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:47:35,174:INFO:Checking exceptions
2023-08-16 01:47:35,174:INFO:Importing libraries
2023-08-16 01:47:35,174:INFO:Copying training dataset
2023-08-16 01:47:35,179:INFO:Defining folds
2023-08-16 01:47:35,179:INFO:Declaring metric variables
2023-08-16 01:47:35,182:INFO:Importing untrained model
2023-08-16 01:47:35,184:INFO:Extra Trees Classifier Imported successfully
2023-08-16 01:47:35,189:INFO:Starting cross validation
2023-08-16 01:47:35,190:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:47:36,924:INFO:Calculating mean and std
2023-08-16 01:47:36,925:INFO:Creating metrics dataframe
2023-08-16 01:47:37,037:INFO:Uploading results into container
2023-08-16 01:47:37,037:INFO:Uploading model into container now
2023-08-16 01:47:37,038:INFO:_master_model_container: 12
2023-08-16 01:47:37,038:INFO:_display_container: 2
2023-08-16 01:47:37,038:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-08-16 01:47:37,038:INFO:create_model() successfully completed......................................
2023-08-16 01:47:37,103:INFO:SubProcess create_model() end ==================================
2023-08-16 01:47:37,103:INFO:Creating metrics dataframe
2023-08-16 01:47:37,111:INFO:Initializing Light Gradient Boosting Machine
2023-08-16 01:47:37,112:INFO:Total runtime is 0.4021351774533589 minutes
2023-08-16 01:47:37,114:INFO:SubProcess create_model() called ==================================
2023-08-16 01:47:37,115:INFO:Initializing create_model()
2023-08-16 01:47:37,115:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586D24F8B0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586D0FFA00>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:47:37,115:INFO:Checking exceptions
2023-08-16 01:47:37,115:INFO:Importing libraries
2023-08-16 01:47:37,115:INFO:Copying training dataset
2023-08-16 01:47:37,122:INFO:Defining folds
2023-08-16 01:47:37,122:INFO:Declaring metric variables
2023-08-16 01:47:37,126:INFO:Importing untrained model
2023-08-16 01:47:37,128:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-16 01:47:37,133:INFO:Starting cross validation
2023-08-16 01:47:37,133:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:47:39,245:INFO:Calculating mean and std
2023-08-16 01:47:39,246:INFO:Creating metrics dataframe
2023-08-16 01:47:39,357:INFO:Uploading results into container
2023-08-16 01:47:39,357:INFO:Uploading model into container now
2023-08-16 01:47:39,357:INFO:_master_model_container: 13
2023-08-16 01:47:39,357:INFO:_display_container: 2
2023-08-16 01:47:39,358:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-16 01:47:39,358:INFO:create_model() successfully completed......................................
2023-08-16 01:47:39,426:INFO:SubProcess create_model() end ==================================
2023-08-16 01:47:39,427:INFO:Creating metrics dataframe
2023-08-16 01:47:39,435:INFO:Initializing Dummy Classifier
2023-08-16 01:47:39,435:INFO:Total runtime is 0.4408631324768066 minutes
2023-08-16 01:47:39,438:INFO:SubProcess create_model() called ==================================
2023-08-16 01:47:39,439:INFO:Initializing create_model()
2023-08-16 01:47:39,439:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586D24F8B0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002586D0FFA00>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:47:39,439:INFO:Checking exceptions
2023-08-16 01:47:39,439:INFO:Importing libraries
2023-08-16 01:47:39,439:INFO:Copying training dataset
2023-08-16 01:47:39,443:INFO:Defining folds
2023-08-16 01:47:39,443:INFO:Declaring metric variables
2023-08-16 01:47:39,445:INFO:Importing untrained model
2023-08-16 01:47:39,447:INFO:Dummy Classifier Imported successfully
2023-08-16 01:47:39,452:INFO:Starting cross validation
2023-08-16 01:47:39,453:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:47:39,509:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:47:39,520:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:47:39,523:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:47:39,524:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:47:39,525:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:47:39,536:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:47:39,537:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:47:39,546:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:47:39,549:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:47:39,561:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:47:40,496:INFO:Calculating mean and std
2023-08-16 01:47:40,497:INFO:Creating metrics dataframe
2023-08-16 01:47:40,605:INFO:Uploading results into container
2023-08-16 01:47:40,605:INFO:Uploading model into container now
2023-08-16 01:47:40,606:INFO:_master_model_container: 14
2023-08-16 01:47:40,606:INFO:_display_container: 2
2023-08-16 01:47:40,606:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-08-16 01:47:40,606:INFO:create_model() successfully completed......................................
2023-08-16 01:47:40,672:INFO:SubProcess create_model() end ==================================
2023-08-16 01:47:40,672:INFO:Creating metrics dataframe
2023-08-16 01:47:40,687:INFO:Initializing create_model()
2023-08-16 01:47:40,687:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586D24F8B0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:47:40,687:INFO:Checking exceptions
2023-08-16 01:47:40,688:INFO:Importing libraries
2023-08-16 01:47:40,688:INFO:Copying training dataset
2023-08-16 01:47:40,692:INFO:Defining folds
2023-08-16 01:47:40,692:INFO:Declaring metric variables
2023-08-16 01:47:40,692:INFO:Importing untrained model
2023-08-16 01:47:40,692:INFO:Declaring custom model
2023-08-16 01:47:40,693:INFO:Logistic Regression Imported successfully
2023-08-16 01:47:40,693:INFO:Cross validation set to False
2023-08-16 01:47:40,693:INFO:Fitting Model
2023-08-16 01:47:40,859:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-16 01:47:40,859:INFO:create_model() successfully completed......................................
2023-08-16 01:47:40,952:INFO:_master_model_container: 14
2023-08-16 01:47:40,953:INFO:_display_container: 2
2023-08-16 01:47:40,953:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-16 01:47:40,953:INFO:compare_models() successfully completed......................................
2023-08-16 01:48:03,726:INFO:Initializing plot_model()
2023-08-16 01:48:03,726:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586D24F8B0>, system=True)
2023-08-16 01:48:03,726:INFO:Checking exceptions
2023-08-16 01:48:03,730:INFO:Preloading libraries
2023-08-16 01:48:03,730:INFO:Copying training dataset
2023-08-16 01:48:03,730:INFO:Plot type: confusion_matrix
2023-08-16 01:48:03,786:INFO:Fitting Model
2023-08-16 01:48:03,786:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2023-08-16 01:48:03,787:INFO:Scoring test/hold-out set
2023-08-16 01:48:03,861:INFO:Visual Rendered Successfully
2023-08-16 01:48:03,945:INFO:plot_model() successfully completed......................................
2023-08-16 01:48:21,237:INFO:Initializing plot_model()
2023-08-16 01:48:21,237:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586D24F8B0>, system=True)
2023-08-16 01:48:21,237:INFO:Checking exceptions
2023-08-16 01:48:21,242:INFO:Preloading libraries
2023-08-16 01:48:21,242:INFO:Copying training dataset
2023-08-16 01:48:21,243:INFO:Plot type: feature
2023-08-16 01:48:21,348:INFO:Visual Rendered Successfully
2023-08-16 01:48:21,416:INFO:plot_model() successfully completed......................................
2023-08-16 01:48:33,523:INFO:Initializing plot_model()
2023-08-16 01:48:33,523:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586D24F8B0>, system=True)
2023-08-16 01:48:33,524:INFO:Checking exceptions
2023-08-16 01:48:33,529:INFO:Preloading libraries
2023-08-16 01:48:33,529:INFO:Copying training dataset
2023-08-16 01:48:33,529:INFO:Plot type: auc
2023-08-16 01:48:33,606:INFO:Fitting Model
2023-08-16 01:48:33,606:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2023-08-16 01:48:33,606:INFO:Scoring test/hold-out set
2023-08-16 01:48:33,726:INFO:Visual Rendered Successfully
2023-08-16 01:48:33,809:INFO:plot_model() successfully completed......................................
2023-08-16 01:49:28,972:INFO:Initializing plot_model()
2023-08-16 01:49:28,973:INFO:plot_model(plot=lr, fold=None, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002586D24F8B0>, system=True)
2023-08-16 01:49:28,973:INFO:Checking exceptions
2023-08-16 01:50:00,554:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-16 01:50:00,554:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-16 01:50:00,554:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-16 01:50:00,554:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-16 01:51:19,688:INFO:PyCaret ClassificationExperiment
2023-08-16 01:51:19,688:INFO:Logging name: clf-default-name
2023-08-16 01:51:19,688:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-16 01:51:19,688:INFO:version 3.0.4
2023-08-16 01:51:19,688:INFO:Initializing setup()
2023-08-16 01:51:19,688:INFO:self.USI: 019b
2023-08-16 01:51:19,688:INFO:self._variable_keys: {'pipeline', 'fold_groups_param', 'X_test', 'idx', '_available_plots', 'X_train', 'fix_imbalance', 'y_test', 'y', 'memory', 'gpu_n_jobs_param', 'n_jobs_param', 'logging_param', 'log_plots_param', 'USI', 'is_multiclass', 'fold_generator', 'target_param', 'exp_id', '_ml_usecase', 'fold_shuffle_param', 'data', 'gpu_param', 'y_train', 'html_param', 'exp_name_log', 'seed', 'X'}
2023-08-16 01:51:19,688:INFO:Checking environment
2023-08-16 01:51:19,688:INFO:python_version: 3.9.13
2023-08-16 01:51:19,688:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-08-16 01:51:19,688:INFO:machine: AMD64
2023-08-16 01:51:19,688:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-16 01:51:19,688:INFO:Memory: svmem(total=16905969664, available=3823456256, percent=77.4, used=13082513408, free=3823456256)
2023-08-16 01:51:19,688:INFO:Physical Core: 8
2023-08-16 01:51:19,688:INFO:Logical Core: 16
2023-08-16 01:51:19,688:INFO:Checking libraries
2023-08-16 01:51:19,688:INFO:System:
2023-08-16 01:51:19,688:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-08-16 01:51:19,688:INFO:executable: c:\Users\lmacciomaretto\anaconda3\python.exe
2023-08-16 01:51:19,688:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-16 01:51:19,688:INFO:PyCaret required dependencies:
2023-08-16 01:51:19,791:INFO:                 pip: 22.2.2
2023-08-16 01:51:19,791:INFO:          setuptools: 63.4.1
2023-08-16 01:51:19,791:INFO:             pycaret: 3.0.4
2023-08-16 01:51:19,791:INFO:             IPython: 7.31.1
2023-08-16 01:51:19,791:INFO:          ipywidgets: 7.6.5
2023-08-16 01:51:19,791:INFO:                tqdm: 4.64.1
2023-08-16 01:51:19,791:INFO:               numpy: 1.21.5
2023-08-16 01:51:19,791:INFO:              pandas: 1.4.4
2023-08-16 01:51:19,791:INFO:              jinja2: 2.11.3
2023-08-16 01:51:19,791:INFO:               scipy: 1.9.1
2023-08-16 01:51:19,791:INFO:              joblib: 1.3.2
2023-08-16 01:51:19,791:INFO:             sklearn: 1.0.2
2023-08-16 01:51:19,791:INFO:                pyod: 1.1.0
2023-08-16 01:51:19,791:INFO:            imblearn: 0.11.0
2023-08-16 01:51:19,791:INFO:   category_encoders: 2.6.2
2023-08-16 01:51:19,791:INFO:            lightgbm: 4.0.0
2023-08-16 01:51:19,791:INFO:               numba: 0.55.1
2023-08-16 01:51:19,791:INFO:            requests: 2.28.1
2023-08-16 01:51:19,791:INFO:          matplotlib: 3.5.2
2023-08-16 01:51:19,791:INFO:          scikitplot: 0.3.7
2023-08-16 01:51:19,791:INFO:         yellowbrick: 1.5
2023-08-16 01:51:19,791:INFO:              plotly: 5.9.0
2023-08-16 01:51:19,791:INFO:    plotly-resampler: Not installed
2023-08-16 01:51:19,791:INFO:             kaleido: 0.2.1
2023-08-16 01:51:19,791:INFO:           schemdraw: 0.15
2023-08-16 01:51:19,791:INFO:         statsmodels: 0.13.2
2023-08-16 01:51:19,791:INFO:              sktime: 0.21.0
2023-08-16 01:51:19,791:INFO:               tbats: 1.1.3
2023-08-16 01:51:19,791:INFO:            pmdarima: 2.0.3
2023-08-16 01:51:19,791:INFO:              psutil: 5.9.0
2023-08-16 01:51:19,791:INFO:          markupsafe: 2.0.1
2023-08-16 01:51:19,791:INFO:             pickle5: Not installed
2023-08-16 01:51:19,791:INFO:         cloudpickle: 2.0.0
2023-08-16 01:51:19,791:INFO:         deprecation: 2.1.0
2023-08-16 01:51:19,791:INFO:              xxhash: 3.3.0
2023-08-16 01:51:19,791:INFO:           wurlitzer: Not installed
2023-08-16 01:51:19,792:INFO:PyCaret optional dependencies:
2023-08-16 01:51:19,801:INFO:                shap: Not installed
2023-08-16 01:51:19,801:INFO:           interpret: Not installed
2023-08-16 01:51:19,801:INFO:                umap: Not installed
2023-08-16 01:51:19,801:INFO:    pandas_profiling: Not installed
2023-08-16 01:51:19,801:INFO:  explainerdashboard: Not installed
2023-08-16 01:51:19,801:INFO:             autoviz: Not installed
2023-08-16 01:51:19,801:INFO:           fairlearn: Not installed
2023-08-16 01:51:19,801:INFO:          deepchecks: Not installed
2023-08-16 01:51:19,801:INFO:             xgboost: Not installed
2023-08-16 01:51:19,801:INFO:            catboost: Not installed
2023-08-16 01:51:19,801:INFO:              kmodes: Not installed
2023-08-16 01:51:19,801:INFO:             mlxtend: Not installed
2023-08-16 01:51:19,801:INFO:       statsforecast: Not installed
2023-08-16 01:51:19,801:INFO:        tune_sklearn: Not installed
2023-08-16 01:51:19,801:INFO:                 ray: Not installed
2023-08-16 01:51:19,801:INFO:            hyperopt: Not installed
2023-08-16 01:51:19,801:INFO:              optuna: Not installed
2023-08-16 01:51:19,801:INFO:               skopt: Not installed
2023-08-16 01:51:19,801:INFO:              mlflow: Not installed
2023-08-16 01:51:19,801:INFO:              gradio: Not installed
2023-08-16 01:51:19,801:INFO:             fastapi: Not installed
2023-08-16 01:51:19,801:INFO:             uvicorn: Not installed
2023-08-16 01:51:19,801:INFO:              m2cgen: Not installed
2023-08-16 01:51:19,801:INFO:           evidently: Not installed
2023-08-16 01:51:19,801:INFO:               fugue: Not installed
2023-08-16 01:51:19,801:INFO:           streamlit: Not installed
2023-08-16 01:51:19,801:INFO:             prophet: Not installed
2023-08-16 01:51:19,801:INFO:None
2023-08-16 01:51:19,801:INFO:Set up data.
2023-08-16 01:51:19,808:INFO:Set up train/test split.
2023-08-16 01:51:19,814:INFO:Set up index.
2023-08-16 01:51:19,814:INFO:Set up folding strategy.
2023-08-16 01:51:19,814:INFO:Assigning column types.
2023-08-16 01:51:19,817:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-16 01:51:19,849:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-16 01:51:19,851:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:51:19,877:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:51:19,877:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:51:19,910:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-16 01:51:19,910:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:51:19,930:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:51:19,931:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:51:19,931:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-16 01:51:19,964:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:51:19,984:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:51:19,984:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:51:20,017:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:51:20,037:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:51:20,037:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:51:20,038:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-16 01:51:20,091:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:51:20,091:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:51:20,144:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:51:20,145:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:51:20,147:INFO:Preparing preprocessing pipeline...
2023-08-16 01:51:20,148:INFO:Set up simple imputation.
2023-08-16 01:51:20,169:INFO:Finished creating preprocessing pipeline.
2023-08-16 01:51:20,171:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\LMACCI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['CATAG3', 'HEALTH2', 'ANYHLTI2',
                                             'INCOME', 'POVERTY3', 'TOBFLAG',
                                             'MRJFLAG', 'PYUD5MRJ', 'MJYRTOT',
                                             'ALCFLAG', 'COCFLAG', 'CRKFLAG',
                                             'HERFLAG', 'LSDFLAG',
                                             'METHAMFLAG'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose=0))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose=0)))],
         verbose=False)
2023-08-16 01:51:20,171:INFO:Creating final display dataframe.
2023-08-16 01:51:20,228:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          ADSMMDEA
2                   Target type            Binary
3           Original data shape       (12654, 16)
4        Transformed data shape       (12654, 16)
5   Transformed train set shape        (8857, 16)
6    Transformed test set shape        (3797, 16)
7              Numeric features                15
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              019b
2023-08-16 01:51:20,299:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:51:20,299:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:51:20,353:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:51:20,353:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:51:20,354:INFO:setup() successfully completed in 0.76s...............
2023-08-16 01:51:32,824:INFO:PyCaret ClassificationExperiment
2023-08-16 01:51:32,824:INFO:Logging name: clf-default-name
2023-08-16 01:51:32,824:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-16 01:51:32,824:INFO:version 3.0.4
2023-08-16 01:51:32,824:INFO:Initializing setup()
2023-08-16 01:51:32,824:INFO:self.USI: 7b84
2023-08-16 01:51:32,824:INFO:self._variable_keys: {'pipeline', 'fold_groups_param', 'X_test', 'idx', '_available_plots', 'X_train', 'fix_imbalance', 'y_test', 'y', 'memory', 'gpu_n_jobs_param', 'n_jobs_param', 'logging_param', 'log_plots_param', 'USI', 'is_multiclass', 'fold_generator', 'target_param', 'exp_id', '_ml_usecase', 'fold_shuffle_param', 'data', 'gpu_param', 'y_train', 'html_param', 'exp_name_log', 'seed', 'X'}
2023-08-16 01:51:32,824:INFO:Checking environment
2023-08-16 01:51:32,824:INFO:python_version: 3.9.13
2023-08-16 01:51:32,824:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-08-16 01:51:32,824:INFO:machine: AMD64
2023-08-16 01:51:32,824:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-16 01:51:32,824:INFO:Memory: svmem(total=16905969664, available=3831480320, percent=77.3, used=13074489344, free=3831480320)
2023-08-16 01:51:32,825:INFO:Physical Core: 8
2023-08-16 01:51:32,825:INFO:Logical Core: 16
2023-08-16 01:51:32,825:INFO:Checking libraries
2023-08-16 01:51:32,825:INFO:System:
2023-08-16 01:51:32,825:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-08-16 01:51:32,825:INFO:executable: c:\Users\lmacciomaretto\anaconda3\python.exe
2023-08-16 01:51:32,825:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-16 01:51:32,825:INFO:PyCaret required dependencies:
2023-08-16 01:51:32,825:INFO:                 pip: 22.2.2
2023-08-16 01:51:32,825:INFO:          setuptools: 63.4.1
2023-08-16 01:51:32,825:INFO:             pycaret: 3.0.4
2023-08-16 01:51:32,825:INFO:             IPython: 7.31.1
2023-08-16 01:51:32,825:INFO:          ipywidgets: 7.6.5
2023-08-16 01:51:32,825:INFO:                tqdm: 4.64.1
2023-08-16 01:51:32,825:INFO:               numpy: 1.21.5
2023-08-16 01:51:32,826:INFO:              pandas: 1.4.4
2023-08-16 01:51:32,826:INFO:              jinja2: 2.11.3
2023-08-16 01:51:32,826:INFO:               scipy: 1.9.1
2023-08-16 01:51:32,826:INFO:              joblib: 1.3.2
2023-08-16 01:51:32,826:INFO:             sklearn: 1.0.2
2023-08-16 01:51:32,826:INFO:                pyod: 1.1.0
2023-08-16 01:51:32,826:INFO:            imblearn: 0.11.0
2023-08-16 01:51:32,826:INFO:   category_encoders: 2.6.2
2023-08-16 01:51:32,826:INFO:            lightgbm: 4.0.0
2023-08-16 01:51:32,826:INFO:               numba: 0.55.1
2023-08-16 01:51:32,826:INFO:            requests: 2.28.1
2023-08-16 01:51:32,826:INFO:          matplotlib: 3.5.2
2023-08-16 01:51:32,826:INFO:          scikitplot: 0.3.7
2023-08-16 01:51:32,826:INFO:         yellowbrick: 1.5
2023-08-16 01:51:32,826:INFO:              plotly: 5.9.0
2023-08-16 01:51:32,826:INFO:    plotly-resampler: Not installed
2023-08-16 01:51:32,826:INFO:             kaleido: 0.2.1
2023-08-16 01:51:32,826:INFO:           schemdraw: 0.15
2023-08-16 01:51:32,826:INFO:         statsmodels: 0.13.2
2023-08-16 01:51:32,826:INFO:              sktime: 0.21.0
2023-08-16 01:51:32,826:INFO:               tbats: 1.1.3
2023-08-16 01:51:32,826:INFO:            pmdarima: 2.0.3
2023-08-16 01:51:32,826:INFO:              psutil: 5.9.0
2023-08-16 01:51:32,826:INFO:          markupsafe: 2.0.1
2023-08-16 01:51:32,826:INFO:             pickle5: Not installed
2023-08-16 01:51:32,826:INFO:         cloudpickle: 2.0.0
2023-08-16 01:51:32,827:INFO:         deprecation: 2.1.0
2023-08-16 01:51:32,827:INFO:              xxhash: 3.3.0
2023-08-16 01:51:32,827:INFO:           wurlitzer: Not installed
2023-08-16 01:51:32,827:INFO:PyCaret optional dependencies:
2023-08-16 01:51:32,827:INFO:                shap: Not installed
2023-08-16 01:51:32,827:INFO:           interpret: Not installed
2023-08-16 01:51:32,827:INFO:                umap: Not installed
2023-08-16 01:51:32,827:INFO:    pandas_profiling: Not installed
2023-08-16 01:51:32,827:INFO:  explainerdashboard: Not installed
2023-08-16 01:51:32,827:INFO:             autoviz: Not installed
2023-08-16 01:51:32,827:INFO:           fairlearn: Not installed
2023-08-16 01:51:32,827:INFO:          deepchecks: Not installed
2023-08-16 01:51:32,827:INFO:             xgboost: Not installed
2023-08-16 01:51:32,827:INFO:            catboost: Not installed
2023-08-16 01:51:32,827:INFO:              kmodes: Not installed
2023-08-16 01:51:32,827:INFO:             mlxtend: Not installed
2023-08-16 01:51:32,827:INFO:       statsforecast: Not installed
2023-08-16 01:51:32,827:INFO:        tune_sklearn: Not installed
2023-08-16 01:51:32,827:INFO:                 ray: Not installed
2023-08-16 01:51:32,827:INFO:            hyperopt: Not installed
2023-08-16 01:51:32,827:INFO:              optuna: Not installed
2023-08-16 01:51:32,827:INFO:               skopt: Not installed
2023-08-16 01:51:32,827:INFO:              mlflow: Not installed
2023-08-16 01:51:32,827:INFO:              gradio: Not installed
2023-08-16 01:51:32,827:INFO:             fastapi: Not installed
2023-08-16 01:51:32,827:INFO:             uvicorn: Not installed
2023-08-16 01:51:32,827:INFO:              m2cgen: Not installed
2023-08-16 01:51:32,827:INFO:           evidently: Not installed
2023-08-16 01:51:32,827:INFO:               fugue: Not installed
2023-08-16 01:51:32,828:INFO:           streamlit: Not installed
2023-08-16 01:51:32,828:INFO:             prophet: Not installed
2023-08-16 01:51:32,828:INFO:None
2023-08-16 01:51:32,828:INFO:Set up data.
2023-08-16 01:51:32,835:INFO:Set up train/test split.
2023-08-16 01:51:32,842:INFO:Set up index.
2023-08-16 01:51:32,842:INFO:Set up folding strategy.
2023-08-16 01:51:32,842:INFO:Assigning column types.
2023-08-16 01:51:32,846:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-16 01:51:32,880:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-16 01:51:32,881:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:51:32,901:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:51:32,901:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:51:32,934:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-16 01:51:32,934:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:51:32,954:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:51:32,955:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:51:32,955:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-16 01:51:32,987:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:51:33,009:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:51:33,009:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:51:33,042:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:51:33,065:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:51:33,065:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:51:33,065:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-16 01:51:33,118:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:51:33,118:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:51:33,171:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:51:33,171:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:51:33,172:INFO:Preparing preprocessing pipeline...
2023-08-16 01:51:33,173:INFO:Set up simple imputation.
2023-08-16 01:51:33,188:INFO:Finished creating preprocessing pipeline.
2023-08-16 01:51:33,190:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\LMACCI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['CATAG3', 'HEALTH2', 'ANYHLTI2',
                                             'INCOME', 'POVERTY3', 'TOBFLAG',
                                             'MRJFLAG', 'PYUD5MRJ', 'MJYRTOT',
                                             'ALCFLAG', 'COCFLAG', 'CRKFLAG',
                                             'HERFLAG', 'LSDFLAG',
                                             'METHAMFLAG'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose=0))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose=0)))],
         verbose=False)
2023-08-16 01:51:33,191:INFO:Creating final display dataframe.
2023-08-16 01:51:33,239:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          ADSMMDEA
2                   Target type            Binary
3           Original data shape       (12654, 16)
4        Transformed data shape       (12654, 16)
5   Transformed train set shape        (8857, 16)
6    Transformed test set shape        (3797, 16)
7              Numeric features                15
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              7b84
2023-08-16 01:51:33,300:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:51:33,301:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:51:33,356:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:51:33,356:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:51:33,356:INFO:setup() successfully completed in 0.61s...............
2023-08-16 01:51:36,307:INFO:Initializing compare_models()
2023-08-16 01:51:36,307:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0F10>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0F10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-16 01:51:36,308:INFO:Checking exceptions
2023-08-16 01:51:36,312:INFO:Preparing display monitor
2023-08-16 01:51:36,342:INFO:Initializing Logistic Regression
2023-08-16 01:51:36,342:INFO:Total runtime is 0.0 minutes
2023-08-16 01:51:36,344:INFO:SubProcess create_model() called ==================================
2023-08-16 01:51:36,345:INFO:Initializing create_model()
2023-08-16 01:51:36,345:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0F10>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C06E0D90>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:51:36,345:INFO:Checking exceptions
2023-08-16 01:51:36,345:INFO:Importing libraries
2023-08-16 01:51:36,345:INFO:Copying training dataset
2023-08-16 01:51:36,350:INFO:Defining folds
2023-08-16 01:51:36,350:INFO:Declaring metric variables
2023-08-16 01:51:36,353:INFO:Importing untrained model
2023-08-16 01:51:36,355:INFO:Logistic Regression Imported successfully
2023-08-16 01:51:36,360:INFO:Starting cross validation
2023-08-16 01:51:36,360:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:51:41,955:INFO:Calculating mean and std
2023-08-16 01:51:41,956:INFO:Creating metrics dataframe
2023-08-16 01:51:42,077:INFO:Uploading results into container
2023-08-16 01:51:42,077:INFO:Uploading model into container now
2023-08-16 01:51:42,078:INFO:_master_model_container: 1
2023-08-16 01:51:42,078:INFO:_display_container: 2
2023-08-16 01:51:42,078:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-16 01:51:42,078:INFO:create_model() successfully completed......................................
2023-08-16 01:51:42,147:INFO:SubProcess create_model() end ==================================
2023-08-16 01:51:42,148:INFO:Creating metrics dataframe
2023-08-16 01:51:42,154:INFO:Initializing K Neighbors Classifier
2023-08-16 01:51:42,154:INFO:Total runtime is 0.09686801433563233 minutes
2023-08-16 01:51:42,158:INFO:SubProcess create_model() called ==================================
2023-08-16 01:51:42,158:INFO:Initializing create_model()
2023-08-16 01:51:42,158:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0F10>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C06E0D90>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:51:42,159:INFO:Checking exceptions
2023-08-16 01:51:42,159:INFO:Importing libraries
2023-08-16 01:51:42,159:INFO:Copying training dataset
2023-08-16 01:51:42,164:INFO:Defining folds
2023-08-16 01:51:42,165:INFO:Declaring metric variables
2023-08-16 01:51:42,167:INFO:Importing untrained model
2023-08-16 01:51:42,170:INFO:K Neighbors Classifier Imported successfully
2023-08-16 01:51:42,174:INFO:Starting cross validation
2023-08-16 01:51:42,175:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:51:42,294:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:51:42,308:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:51:42,324:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:51:42,340:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:51:45,563:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:51:45,599:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:51:45,601:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:51:45,616:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:51:45,616:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:51:45,616:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:51:46,127:INFO:Calculating mean and std
2023-08-16 01:51:46,130:INFO:Creating metrics dataframe
2023-08-16 01:51:46,259:INFO:Uploading results into container
2023-08-16 01:51:46,259:INFO:Uploading model into container now
2023-08-16 01:51:46,260:INFO:_master_model_container: 2
2023-08-16 01:51:46,260:INFO:_display_container: 2
2023-08-16 01:51:46,260:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-16 01:51:46,260:INFO:create_model() successfully completed......................................
2023-08-16 01:51:46,332:INFO:SubProcess create_model() end ==================================
2023-08-16 01:51:46,332:INFO:Creating metrics dataframe
2023-08-16 01:51:46,340:INFO:Initializing Naive Bayes
2023-08-16 01:51:46,340:INFO:Total runtime is 0.16664074659347533 minutes
2023-08-16 01:51:46,343:INFO:SubProcess create_model() called ==================================
2023-08-16 01:51:46,344:INFO:Initializing create_model()
2023-08-16 01:51:46,344:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0F10>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C06E0D90>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:51:46,344:INFO:Checking exceptions
2023-08-16 01:51:46,344:INFO:Importing libraries
2023-08-16 01:51:46,344:INFO:Copying training dataset
2023-08-16 01:51:46,348:INFO:Defining folds
2023-08-16 01:51:46,349:INFO:Declaring metric variables
2023-08-16 01:51:46,351:INFO:Importing untrained model
2023-08-16 01:51:46,353:INFO:Naive Bayes Imported successfully
2023-08-16 01:51:46,358:INFO:Starting cross validation
2023-08-16 01:51:46,358:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:51:47,409:INFO:Calculating mean and std
2023-08-16 01:51:47,410:INFO:Creating metrics dataframe
2023-08-16 01:51:47,524:INFO:Uploading results into container
2023-08-16 01:51:47,525:INFO:Uploading model into container now
2023-08-16 01:51:47,525:INFO:_master_model_container: 3
2023-08-16 01:51:47,525:INFO:_display_container: 2
2023-08-16 01:51:47,525:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-16 01:51:47,525:INFO:create_model() successfully completed......................................
2023-08-16 01:51:47,592:INFO:SubProcess create_model() end ==================================
2023-08-16 01:51:47,592:INFO:Creating metrics dataframe
2023-08-16 01:51:47,599:INFO:Initializing Decision Tree Classifier
2023-08-16 01:51:47,599:INFO:Total runtime is 0.18762192328770955 minutes
2023-08-16 01:51:47,601:INFO:SubProcess create_model() called ==================================
2023-08-16 01:51:47,601:INFO:Initializing create_model()
2023-08-16 01:51:47,602:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0F10>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C06E0D90>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:51:47,602:INFO:Checking exceptions
2023-08-16 01:51:47,602:INFO:Importing libraries
2023-08-16 01:51:47,602:INFO:Copying training dataset
2023-08-16 01:51:47,607:INFO:Defining folds
2023-08-16 01:51:47,607:INFO:Declaring metric variables
2023-08-16 01:51:47,609:INFO:Importing untrained model
2023-08-16 01:51:47,612:INFO:Decision Tree Classifier Imported successfully
2023-08-16 01:51:47,616:INFO:Starting cross validation
2023-08-16 01:51:47,617:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:51:48,636:INFO:Calculating mean and std
2023-08-16 01:51:48,639:INFO:Creating metrics dataframe
2023-08-16 01:51:48,760:INFO:Uploading results into container
2023-08-16 01:51:48,760:INFO:Uploading model into container now
2023-08-16 01:51:48,761:INFO:_master_model_container: 4
2023-08-16 01:51:48,761:INFO:_display_container: 2
2023-08-16 01:51:48,761:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-08-16 01:51:48,761:INFO:create_model() successfully completed......................................
2023-08-16 01:51:48,841:INFO:SubProcess create_model() end ==================================
2023-08-16 01:51:48,841:INFO:Creating metrics dataframe
2023-08-16 01:51:48,848:INFO:Initializing SVM - Linear Kernel
2023-08-16 01:51:48,849:INFO:Total runtime is 0.20845669905344644 minutes
2023-08-16 01:51:48,851:INFO:SubProcess create_model() called ==================================
2023-08-16 01:51:48,852:INFO:Initializing create_model()
2023-08-16 01:51:48,852:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0F10>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C06E0D90>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:51:48,852:INFO:Checking exceptions
2023-08-16 01:51:48,852:INFO:Importing libraries
2023-08-16 01:51:48,852:INFO:Copying training dataset
2023-08-16 01:51:48,858:INFO:Defining folds
2023-08-16 01:51:48,858:INFO:Declaring metric variables
2023-08-16 01:51:48,861:INFO:Importing untrained model
2023-08-16 01:51:48,863:INFO:SVM - Linear Kernel Imported successfully
2023-08-16 01:51:48,868:INFO:Starting cross validation
2023-08-16 01:51:48,869:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:51:48,964:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:51:48,973:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:51:48,992:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:51:48,992:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:51:48,999:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:51:49,011:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:51:49,020:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:51:49,031:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:51:49,032:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:51:49,032:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:51:49,928:INFO:Calculating mean and std
2023-08-16 01:51:49,928:INFO:Creating metrics dataframe
2023-08-16 01:51:50,039:INFO:Uploading results into container
2023-08-16 01:51:50,040:INFO:Uploading model into container now
2023-08-16 01:51:50,040:INFO:_master_model_container: 5
2023-08-16 01:51:50,040:INFO:_display_container: 2
2023-08-16 01:51:50,041:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-16 01:51:50,041:INFO:create_model() successfully completed......................................
2023-08-16 01:51:50,105:INFO:SubProcess create_model() end ==================================
2023-08-16 01:51:50,106:INFO:Creating metrics dataframe
2023-08-16 01:51:50,115:INFO:Initializing Ridge Classifier
2023-08-16 01:51:50,116:INFO:Total runtime is 0.2295690854390462 minutes
2023-08-16 01:51:50,120:INFO:SubProcess create_model() called ==================================
2023-08-16 01:51:50,120:INFO:Initializing create_model()
2023-08-16 01:51:50,120:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0F10>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C06E0D90>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:51:50,120:INFO:Checking exceptions
2023-08-16 01:51:50,120:INFO:Importing libraries
2023-08-16 01:51:50,120:INFO:Copying training dataset
2023-08-16 01:51:50,129:INFO:Defining folds
2023-08-16 01:51:50,129:INFO:Declaring metric variables
2023-08-16 01:51:50,133:INFO:Importing untrained model
2023-08-16 01:51:50,137:INFO:Ridge Classifier Imported successfully
2023-08-16 01:51:50,142:INFO:Starting cross validation
2023-08-16 01:51:50,143:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:51:50,213:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:51:50,214:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:51:50,217:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:51:50,219:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:51:50,222:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:51:50,223:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:51:50,235:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:51:50,241:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:51:50,242:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:51:50,249:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:51:51,153:INFO:Calculating mean and std
2023-08-16 01:51:51,154:INFO:Creating metrics dataframe
2023-08-16 01:51:51,277:INFO:Uploading results into container
2023-08-16 01:51:51,277:INFO:Uploading model into container now
2023-08-16 01:51:51,278:INFO:_master_model_container: 6
2023-08-16 01:51:51,278:INFO:_display_container: 2
2023-08-16 01:51:51,278:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=123, solver='auto', tol=0.001)
2023-08-16 01:51:51,278:INFO:create_model() successfully completed......................................
2023-08-16 01:51:51,341:INFO:SubProcess create_model() end ==================================
2023-08-16 01:51:51,341:INFO:Creating metrics dataframe
2023-08-16 01:51:51,349:INFO:Initializing Random Forest Classifier
2023-08-16 01:51:51,349:INFO:Total runtime is 0.250109334786733 minutes
2023-08-16 01:51:51,351:INFO:SubProcess create_model() called ==================================
2023-08-16 01:51:51,351:INFO:Initializing create_model()
2023-08-16 01:51:51,351:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0F10>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C06E0D90>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:51:51,351:INFO:Checking exceptions
2023-08-16 01:51:51,351:INFO:Importing libraries
2023-08-16 01:51:51,351:INFO:Copying training dataset
2023-08-16 01:51:51,356:INFO:Defining folds
2023-08-16 01:51:51,356:INFO:Declaring metric variables
2023-08-16 01:51:51,358:INFO:Importing untrained model
2023-08-16 01:51:51,360:INFO:Random Forest Classifier Imported successfully
2023-08-16 01:51:51,364:INFO:Starting cross validation
2023-08-16 01:51:51,365:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:51:52,679:INFO:Calculating mean and std
2023-08-16 01:51:52,680:INFO:Creating metrics dataframe
2023-08-16 01:51:52,802:INFO:Uploading results into container
2023-08-16 01:51:52,803:INFO:Uploading model into container now
2023-08-16 01:51:52,804:INFO:_master_model_container: 7
2023-08-16 01:51:52,804:INFO:_display_container: 2
2023-08-16 01:51:52,804:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-08-16 01:51:52,804:INFO:create_model() successfully completed......................................
2023-08-16 01:51:52,873:INFO:SubProcess create_model() end ==================================
2023-08-16 01:51:52,873:INFO:Creating metrics dataframe
2023-08-16 01:51:52,881:INFO:Initializing Quadratic Discriminant Analysis
2023-08-16 01:51:52,881:INFO:Total runtime is 0.2756457964579264 minutes
2023-08-16 01:51:52,883:INFO:SubProcess create_model() called ==================================
2023-08-16 01:51:52,884:INFO:Initializing create_model()
2023-08-16 01:51:52,884:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0F10>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C06E0D90>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:51:52,884:INFO:Checking exceptions
2023-08-16 01:51:52,884:INFO:Importing libraries
2023-08-16 01:51:52,884:INFO:Copying training dataset
2023-08-16 01:51:52,888:INFO:Defining folds
2023-08-16 01:51:52,888:INFO:Declaring metric variables
2023-08-16 01:51:52,890:INFO:Importing untrained model
2023-08-16 01:51:52,893:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-16 01:51:52,897:INFO:Starting cross validation
2023-08-16 01:51:52,898:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:51:52,938:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:51:52,940:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:51:52,943:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:51:52,946:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:51:52,954:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:51:52,954:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:51:52,954:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:51:52,955:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:51:52,956:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:51:52,956:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:51:52,957:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:51:52,957:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:51:52,960:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:51:52,960:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:51:52,960:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:51:52,960:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:51:52,961:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:51:52,961:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:51:52,967:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:51:52,968:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:51:52,968:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:51:52,968:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:51:52,968:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:51:52,968:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:51:52,968:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:51:52,971:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:51:52,972:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:51:52,972:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:51:52,972:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:51:52,974:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:51:52,975:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:51:52,975:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:51:52,975:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:51:52,976:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:51:52,976:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:51:52,976:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:51:52,977:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:51:52,977:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:51:52,978:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:51:52,979:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:51:52,980:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:51:52,980:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:51:52,980:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:51:52,980:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:51:52,981:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:51:52,981:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:51:52,982:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:51:52,983:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:51:52,983:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:51:52,983:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:51:52,983:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:51:52,983:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:51:52,986:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:51:52,986:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:51:52,987:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:51:52,988:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:51:52,994:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:51:52,994:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:51:52,995:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:51:52,995:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:51:52,995:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:51:52,995:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:51:52,998:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:51:53,000:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:51:53,000:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:51:53,000:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:51:53,000:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:51:53,001:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:51:53,001:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:51:53,002:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:51:53,004:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:51:53,005:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:51:53,005:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:51:53,005:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:51:53,007:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:51:53,008:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:51:53,008:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:51:53,009:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:51:53,011:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:51:53,015:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:51:53,015:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:51:53,015:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:51:53,016:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:51:53,018:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:51:53,018:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:51:53,018:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:51:53,018:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:51:53,020:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:51:53,021:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:51:53,023:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:51:53,906:INFO:Calculating mean and std
2023-08-16 01:51:53,907:INFO:Creating metrics dataframe
2023-08-16 01:51:54,027:INFO:Uploading results into container
2023-08-16 01:51:54,028:INFO:Uploading model into container now
2023-08-16 01:51:54,029:INFO:_master_model_container: 8
2023-08-16 01:51:54,029:INFO:_display_container: 2
2023-08-16 01:51:54,029:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-16 01:51:54,029:INFO:create_model() successfully completed......................................
2023-08-16 01:51:54,092:INFO:SubProcess create_model() end ==================================
2023-08-16 01:51:54,092:INFO:Creating metrics dataframe
2023-08-16 01:51:54,099:INFO:Initializing Ada Boost Classifier
2023-08-16 01:51:54,099:INFO:Total runtime is 0.2959439078966776 minutes
2023-08-16 01:51:54,101:INFO:SubProcess create_model() called ==================================
2023-08-16 01:51:54,101:INFO:Initializing create_model()
2023-08-16 01:51:54,101:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0F10>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C06E0D90>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:51:54,102:INFO:Checking exceptions
2023-08-16 01:51:54,102:INFO:Importing libraries
2023-08-16 01:51:54,102:INFO:Copying training dataset
2023-08-16 01:51:54,106:INFO:Defining folds
2023-08-16 01:51:54,106:INFO:Declaring metric variables
2023-08-16 01:51:54,108:INFO:Importing untrained model
2023-08-16 01:51:54,110:INFO:Ada Boost Classifier Imported successfully
2023-08-16 01:51:54,115:INFO:Starting cross validation
2023-08-16 01:51:54,115:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:51:55,164:INFO:Calculating mean and std
2023-08-16 01:51:55,165:INFO:Creating metrics dataframe
2023-08-16 01:51:55,284:INFO:Uploading results into container
2023-08-16 01:51:55,285:INFO:Uploading model into container now
2023-08-16 01:51:55,285:INFO:_master_model_container: 9
2023-08-16 01:51:55,285:INFO:_display_container: 2
2023-08-16 01:51:55,285:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2023-08-16 01:51:55,285:INFO:create_model() successfully completed......................................
2023-08-16 01:51:55,351:INFO:SubProcess create_model() end ==================================
2023-08-16 01:51:55,351:INFO:Creating metrics dataframe
2023-08-16 01:51:55,360:INFO:Initializing Gradient Boosting Classifier
2023-08-16 01:51:55,360:INFO:Total runtime is 0.31696762641270954 minutes
2023-08-16 01:51:55,362:INFO:SubProcess create_model() called ==================================
2023-08-16 01:51:55,363:INFO:Initializing create_model()
2023-08-16 01:51:55,363:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0F10>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C06E0D90>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:51:55,363:INFO:Checking exceptions
2023-08-16 01:51:55,363:INFO:Importing libraries
2023-08-16 01:51:55,363:INFO:Copying training dataset
2023-08-16 01:51:55,367:INFO:Defining folds
2023-08-16 01:51:55,367:INFO:Declaring metric variables
2023-08-16 01:51:55,369:INFO:Importing untrained model
2023-08-16 01:51:55,372:INFO:Gradient Boosting Classifier Imported successfully
2023-08-16 01:51:55,377:INFO:Starting cross validation
2023-08-16 01:51:55,377:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:51:56,485:INFO:Calculating mean and std
2023-08-16 01:51:56,486:INFO:Creating metrics dataframe
2023-08-16 01:51:56,607:INFO:Uploading results into container
2023-08-16 01:51:56,608:INFO:Uploading model into container now
2023-08-16 01:51:56,608:INFO:_master_model_container: 10
2023-08-16 01:51:56,608:INFO:_display_container: 2
2023-08-16 01:51:56,609:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-16 01:51:56,609:INFO:create_model() successfully completed......................................
2023-08-16 01:51:56,673:INFO:SubProcess create_model() end ==================================
2023-08-16 01:51:56,673:INFO:Creating metrics dataframe
2023-08-16 01:51:56,681:INFO:Initializing Linear Discriminant Analysis
2023-08-16 01:51:56,681:INFO:Total runtime is 0.3389778971672058 minutes
2023-08-16 01:51:56,684:INFO:SubProcess create_model() called ==================================
2023-08-16 01:51:56,684:INFO:Initializing create_model()
2023-08-16 01:51:56,684:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0F10>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C06E0D90>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:51:56,684:INFO:Checking exceptions
2023-08-16 01:51:56,684:INFO:Importing libraries
2023-08-16 01:51:56,684:INFO:Copying training dataset
2023-08-16 01:51:56,689:INFO:Defining folds
2023-08-16 01:51:56,689:INFO:Declaring metric variables
2023-08-16 01:51:56,692:INFO:Importing untrained model
2023-08-16 01:51:56,694:INFO:Linear Discriminant Analysis Imported successfully
2023-08-16 01:51:56,698:INFO:Starting cross validation
2023-08-16 01:51:56,699:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:51:57,727:INFO:Calculating mean and std
2023-08-16 01:51:57,728:INFO:Creating metrics dataframe
2023-08-16 01:51:57,843:INFO:Uploading results into container
2023-08-16 01:51:57,844:INFO:Uploading model into container now
2023-08-16 01:51:57,844:INFO:_master_model_container: 11
2023-08-16 01:51:57,844:INFO:_display_container: 2
2023-08-16 01:51:57,844:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-16 01:51:57,844:INFO:create_model() successfully completed......................................
2023-08-16 01:51:57,909:INFO:SubProcess create_model() end ==================================
2023-08-16 01:51:57,909:INFO:Creating metrics dataframe
2023-08-16 01:51:57,917:INFO:Initializing Extra Trees Classifier
2023-08-16 01:51:57,917:INFO:Total runtime is 0.35957779089609776 minutes
2023-08-16 01:51:57,919:INFO:SubProcess create_model() called ==================================
2023-08-16 01:51:57,919:INFO:Initializing create_model()
2023-08-16 01:51:57,919:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0F10>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C06E0D90>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:51:57,920:INFO:Checking exceptions
2023-08-16 01:51:57,920:INFO:Importing libraries
2023-08-16 01:51:57,920:INFO:Copying training dataset
2023-08-16 01:51:57,924:INFO:Defining folds
2023-08-16 01:51:57,924:INFO:Declaring metric variables
2023-08-16 01:51:57,926:INFO:Importing untrained model
2023-08-16 01:51:57,929:INFO:Extra Trees Classifier Imported successfully
2023-08-16 01:51:57,933:INFO:Starting cross validation
2023-08-16 01:51:57,934:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:51:59,361:INFO:Calculating mean and std
2023-08-16 01:51:59,362:INFO:Creating metrics dataframe
2023-08-16 01:51:59,482:INFO:Uploading results into container
2023-08-16 01:51:59,482:INFO:Uploading model into container now
2023-08-16 01:51:59,483:INFO:_master_model_container: 12
2023-08-16 01:51:59,483:INFO:_display_container: 2
2023-08-16 01:51:59,483:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-08-16 01:51:59,483:INFO:create_model() successfully completed......................................
2023-08-16 01:51:59,549:INFO:SubProcess create_model() end ==================================
2023-08-16 01:51:59,549:INFO:Creating metrics dataframe
2023-08-16 01:51:59,557:INFO:Initializing Light Gradient Boosting Machine
2023-08-16 01:51:59,557:INFO:Total runtime is 0.38690780003865555 minutes
2023-08-16 01:51:59,560:INFO:SubProcess create_model() called ==================================
2023-08-16 01:51:59,560:INFO:Initializing create_model()
2023-08-16 01:51:59,561:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0F10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C06E0D90>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:51:59,561:INFO:Checking exceptions
2023-08-16 01:51:59,561:INFO:Importing libraries
2023-08-16 01:51:59,561:INFO:Copying training dataset
2023-08-16 01:51:59,566:INFO:Defining folds
2023-08-16 01:51:59,566:INFO:Declaring metric variables
2023-08-16 01:51:59,569:INFO:Importing untrained model
2023-08-16 01:51:59,571:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-16 01:51:59,575:INFO:Starting cross validation
2023-08-16 01:51:59,575:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:52:00,738:INFO:Calculating mean and std
2023-08-16 01:52:00,739:INFO:Creating metrics dataframe
2023-08-16 01:52:00,853:INFO:Uploading results into container
2023-08-16 01:52:00,854:INFO:Uploading model into container now
2023-08-16 01:52:00,854:INFO:_master_model_container: 13
2023-08-16 01:52:00,854:INFO:_display_container: 2
2023-08-16 01:52:00,855:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-16 01:52:00,855:INFO:create_model() successfully completed......................................
2023-08-16 01:52:00,918:INFO:SubProcess create_model() end ==================================
2023-08-16 01:52:00,918:INFO:Creating metrics dataframe
2023-08-16 01:52:00,926:INFO:Initializing Dummy Classifier
2023-08-16 01:52:00,926:INFO:Total runtime is 0.4097329417864481 minutes
2023-08-16 01:52:00,929:INFO:SubProcess create_model() called ==================================
2023-08-16 01:52:00,930:INFO:Initializing create_model()
2023-08-16 01:52:00,930:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0F10>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C06E0D90>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:52:00,930:INFO:Checking exceptions
2023-08-16 01:52:00,930:INFO:Importing libraries
2023-08-16 01:52:00,930:INFO:Copying training dataset
2023-08-16 01:52:00,935:INFO:Defining folds
2023-08-16 01:52:00,935:INFO:Declaring metric variables
2023-08-16 01:52:00,937:INFO:Importing untrained model
2023-08-16 01:52:00,939:INFO:Dummy Classifier Imported successfully
2023-08-16 01:52:00,944:INFO:Starting cross validation
2023-08-16 01:52:00,945:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:52:01,001:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:52:01,002:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:52:01,016:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:52:01,017:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:52:01,018:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:52:01,034:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:52:01,037:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:52:01,038:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:52:01,043:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:52:01,047:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:52:01,977:INFO:Calculating mean and std
2023-08-16 01:52:01,978:INFO:Creating metrics dataframe
2023-08-16 01:52:02,091:INFO:Uploading results into container
2023-08-16 01:52:02,092:INFO:Uploading model into container now
2023-08-16 01:52:02,092:INFO:_master_model_container: 14
2023-08-16 01:52:02,092:INFO:_display_container: 2
2023-08-16 01:52:02,093:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-08-16 01:52:02,093:INFO:create_model() successfully completed......................................
2023-08-16 01:52:02,157:INFO:SubProcess create_model() end ==================================
2023-08-16 01:52:02,157:INFO:Creating metrics dataframe
2023-08-16 01:52:02,170:INFO:Initializing create_model()
2023-08-16 01:52:02,170:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0F10>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:52:02,170:INFO:Checking exceptions
2023-08-16 01:52:02,172:INFO:Importing libraries
2023-08-16 01:52:02,172:INFO:Copying training dataset
2023-08-16 01:52:02,176:INFO:Defining folds
2023-08-16 01:52:02,176:INFO:Declaring metric variables
2023-08-16 01:52:02,177:INFO:Importing untrained model
2023-08-16 01:52:02,177:INFO:Declaring custom model
2023-08-16 01:52:02,177:INFO:Ada Boost Classifier Imported successfully
2023-08-16 01:52:02,177:INFO:Cross validation set to False
2023-08-16 01:52:02,177:INFO:Fitting Model
2023-08-16 01:52:02,278:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2023-08-16 01:52:02,278:INFO:create_model() successfully completed......................................
2023-08-16 01:52:02,373:INFO:_master_model_container: 14
2023-08-16 01:52:02,373:INFO:_display_container: 2
2023-08-16 01:52:02,374:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2023-08-16 01:52:02,374:INFO:compare_models() successfully completed......................................
2023-08-16 01:55:43,574:INFO:Initializing compare_models()
2023-08-16 01:55:43,574:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0F10>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0F10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-16 01:55:43,574:INFO:Checking exceptions
2023-08-16 01:55:43,577:INFO:Preparing display monitor
2023-08-16 01:55:43,604:INFO:Initializing Logistic Regression
2023-08-16 01:55:43,605:INFO:Total runtime is 0.0 minutes
2023-08-16 01:55:43,607:INFO:SubProcess create_model() called ==================================
2023-08-16 01:55:43,608:INFO:Initializing create_model()
2023-08-16 01:55:43,608:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0F10>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C0BE0100>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:55:43,608:INFO:Checking exceptions
2023-08-16 01:55:43,608:INFO:Importing libraries
2023-08-16 01:55:43,608:INFO:Copying training dataset
2023-08-16 01:55:43,613:INFO:Defining folds
2023-08-16 01:55:43,613:INFO:Declaring metric variables
2023-08-16 01:55:43,616:INFO:Importing untrained model
2023-08-16 01:55:43,618:INFO:Logistic Regression Imported successfully
2023-08-16 01:55:43,623:INFO:Starting cross validation
2023-08-16 01:55:43,625:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:55:44,644:INFO:Calculating mean and std
2023-08-16 01:55:44,646:INFO:Creating metrics dataframe
2023-08-16 01:55:44,759:INFO:Uploading results into container
2023-08-16 01:55:44,760:INFO:Uploading model into container now
2023-08-16 01:55:44,760:INFO:_master_model_container: 15
2023-08-16 01:55:44,760:INFO:_display_container: 3
2023-08-16 01:55:44,761:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-16 01:55:44,761:INFO:create_model() successfully completed......................................
2023-08-16 01:55:44,840:INFO:SubProcess create_model() end ==================================
2023-08-16 01:55:44,840:INFO:Creating metrics dataframe
2023-08-16 01:55:44,847:INFO:Initializing K Neighbors Classifier
2023-08-16 01:55:44,847:INFO:Total runtime is 0.02071543534596761 minutes
2023-08-16 01:55:44,850:INFO:SubProcess create_model() called ==================================
2023-08-16 01:55:44,851:INFO:Initializing create_model()
2023-08-16 01:55:44,851:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0F10>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C0BE0100>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:55:44,851:INFO:Checking exceptions
2023-08-16 01:55:44,851:INFO:Importing libraries
2023-08-16 01:55:44,851:INFO:Copying training dataset
2023-08-16 01:55:44,855:INFO:Defining folds
2023-08-16 01:55:44,855:INFO:Declaring metric variables
2023-08-16 01:55:44,857:INFO:Importing untrained model
2023-08-16 01:55:44,860:INFO:K Neighbors Classifier Imported successfully
2023-08-16 01:55:44,868:INFO:Starting cross validation
2023-08-16 01:55:44,869:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:55:44,971:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:55:44,986:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:55:44,987:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:55:44,987:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:55:44,999:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:55:45,002:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:55:45,003:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:55:45,016:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:55:45,017:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:55:45,030:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:55:45,989:INFO:Calculating mean and std
2023-08-16 01:55:45,989:INFO:Creating metrics dataframe
2023-08-16 01:55:46,095:INFO:Uploading results into container
2023-08-16 01:55:46,095:INFO:Uploading model into container now
2023-08-16 01:55:46,096:INFO:_master_model_container: 16
2023-08-16 01:55:46,096:INFO:_display_container: 3
2023-08-16 01:55:46,096:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-16 01:55:46,096:INFO:create_model() successfully completed......................................
2023-08-16 01:55:46,164:INFO:SubProcess create_model() end ==================================
2023-08-16 01:55:46,165:INFO:Creating metrics dataframe
2023-08-16 01:55:46,170:INFO:Initializing Naive Bayes
2023-08-16 01:55:46,170:INFO:Total runtime is 0.04277052481969197 minutes
2023-08-16 01:55:46,172:INFO:SubProcess create_model() called ==================================
2023-08-16 01:55:46,172:INFO:Initializing create_model()
2023-08-16 01:55:46,172:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0F10>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C0BE0100>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:55:46,172:INFO:Checking exceptions
2023-08-16 01:55:46,172:INFO:Importing libraries
2023-08-16 01:55:46,172:INFO:Copying training dataset
2023-08-16 01:55:46,178:INFO:Defining folds
2023-08-16 01:55:46,179:INFO:Declaring metric variables
2023-08-16 01:55:46,182:INFO:Importing untrained model
2023-08-16 01:55:46,184:INFO:Naive Bayes Imported successfully
2023-08-16 01:55:46,189:INFO:Starting cross validation
2023-08-16 01:55:46,190:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:55:47,191:INFO:Calculating mean and std
2023-08-16 01:55:47,192:INFO:Creating metrics dataframe
2023-08-16 01:55:47,310:INFO:Uploading results into container
2023-08-16 01:55:47,311:INFO:Uploading model into container now
2023-08-16 01:55:47,311:INFO:_master_model_container: 17
2023-08-16 01:55:47,311:INFO:_display_container: 3
2023-08-16 01:55:47,312:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-16 01:55:47,312:INFO:create_model() successfully completed......................................
2023-08-16 01:55:47,382:INFO:SubProcess create_model() end ==================================
2023-08-16 01:55:47,383:INFO:Creating metrics dataframe
2023-08-16 01:55:47,390:INFO:Initializing Decision Tree Classifier
2023-08-16 01:55:47,391:INFO:Total runtime is 0.06310669978459676 minutes
2023-08-16 01:55:47,393:INFO:SubProcess create_model() called ==================================
2023-08-16 01:55:47,394:INFO:Initializing create_model()
2023-08-16 01:55:47,394:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0F10>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C0BE0100>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:55:47,394:INFO:Checking exceptions
2023-08-16 01:55:47,394:INFO:Importing libraries
2023-08-16 01:55:47,394:INFO:Copying training dataset
2023-08-16 01:55:47,399:INFO:Defining folds
2023-08-16 01:55:47,399:INFO:Declaring metric variables
2023-08-16 01:55:47,401:INFO:Importing untrained model
2023-08-16 01:55:47,403:INFO:Decision Tree Classifier Imported successfully
2023-08-16 01:55:47,408:INFO:Starting cross validation
2023-08-16 01:55:47,409:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:55:48,440:INFO:Calculating mean and std
2023-08-16 01:55:48,441:INFO:Creating metrics dataframe
2023-08-16 01:55:48,555:INFO:Uploading results into container
2023-08-16 01:55:48,556:INFO:Uploading model into container now
2023-08-16 01:55:48,556:INFO:_master_model_container: 18
2023-08-16 01:55:48,556:INFO:_display_container: 3
2023-08-16 01:55:48,557:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-08-16 01:55:48,557:INFO:create_model() successfully completed......................................
2023-08-16 01:55:48,625:INFO:SubProcess create_model() end ==================================
2023-08-16 01:55:48,626:INFO:Creating metrics dataframe
2023-08-16 01:55:48,632:INFO:Initializing SVM - Linear Kernel
2023-08-16 01:55:48,632:INFO:Total runtime is 0.08379517793655396 minutes
2023-08-16 01:55:48,635:INFO:SubProcess create_model() called ==================================
2023-08-16 01:55:48,635:INFO:Initializing create_model()
2023-08-16 01:55:48,635:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0F10>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C0BE0100>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:55:48,636:INFO:Checking exceptions
2023-08-16 01:55:48,636:INFO:Importing libraries
2023-08-16 01:55:48,636:INFO:Copying training dataset
2023-08-16 01:55:48,641:INFO:Defining folds
2023-08-16 01:55:48,641:INFO:Declaring metric variables
2023-08-16 01:55:48,643:INFO:Importing untrained model
2023-08-16 01:55:48,645:INFO:SVM - Linear Kernel Imported successfully
2023-08-16 01:55:48,650:INFO:Starting cross validation
2023-08-16 01:55:48,651:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:55:48,745:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:55:48,753:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:55:48,768:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:55:48,772:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:55:48,772:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:55:48,781:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:55:48,783:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:55:48,786:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:55:48,809:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:55:48,810:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:55:49,660:INFO:Calculating mean and std
2023-08-16 01:55:49,661:INFO:Creating metrics dataframe
2023-08-16 01:55:49,780:INFO:Uploading results into container
2023-08-16 01:55:49,781:INFO:Uploading model into container now
2023-08-16 01:55:49,781:INFO:_master_model_container: 19
2023-08-16 01:55:49,781:INFO:_display_container: 3
2023-08-16 01:55:49,782:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-16 01:55:49,782:INFO:create_model() successfully completed......................................
2023-08-16 01:55:49,874:INFO:SubProcess create_model() end ==================================
2023-08-16 01:55:49,874:INFO:Creating metrics dataframe
2023-08-16 01:55:49,881:INFO:Initializing Ridge Classifier
2023-08-16 01:55:49,881:INFO:Total runtime is 0.1046107808748881 minutes
2023-08-16 01:55:49,884:INFO:SubProcess create_model() called ==================================
2023-08-16 01:55:49,884:INFO:Initializing create_model()
2023-08-16 01:55:49,884:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0F10>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C0BE0100>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:55:49,884:INFO:Checking exceptions
2023-08-16 01:55:49,884:INFO:Importing libraries
2023-08-16 01:55:49,884:INFO:Copying training dataset
2023-08-16 01:55:49,889:INFO:Defining folds
2023-08-16 01:55:49,890:INFO:Declaring metric variables
2023-08-16 01:55:49,892:INFO:Importing untrained model
2023-08-16 01:55:49,895:INFO:Ridge Classifier Imported successfully
2023-08-16 01:55:49,899:INFO:Starting cross validation
2023-08-16 01:55:49,900:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:55:49,964:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:55:49,971:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:55:49,976:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:55:49,980:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:55:49,983:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:55:49,985:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:55:49,996:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:55:50,002:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:55:50,004:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:55:50,006:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:55:50,916:INFO:Calculating mean and std
2023-08-16 01:55:50,917:INFO:Creating metrics dataframe
2023-08-16 01:55:51,031:INFO:Uploading results into container
2023-08-16 01:55:51,032:INFO:Uploading model into container now
2023-08-16 01:55:51,032:INFO:_master_model_container: 20
2023-08-16 01:55:51,032:INFO:_display_container: 3
2023-08-16 01:55:51,033:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=123, solver='auto', tol=0.001)
2023-08-16 01:55:51,033:INFO:create_model() successfully completed......................................
2023-08-16 01:55:51,103:INFO:SubProcess create_model() end ==================================
2023-08-16 01:55:51,103:INFO:Creating metrics dataframe
2023-08-16 01:55:51,110:INFO:Initializing Random Forest Classifier
2023-08-16 01:55:51,110:INFO:Total runtime is 0.1250898043314616 minutes
2023-08-16 01:55:51,112:INFO:SubProcess create_model() called ==================================
2023-08-16 01:55:51,113:INFO:Initializing create_model()
2023-08-16 01:55:51,113:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0F10>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C0BE0100>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:55:51,113:INFO:Checking exceptions
2023-08-16 01:55:51,113:INFO:Importing libraries
2023-08-16 01:55:51,113:INFO:Copying training dataset
2023-08-16 01:55:51,118:INFO:Defining folds
2023-08-16 01:55:51,118:INFO:Declaring metric variables
2023-08-16 01:55:51,120:INFO:Importing untrained model
2023-08-16 01:55:51,123:INFO:Random Forest Classifier Imported successfully
2023-08-16 01:55:51,127:INFO:Starting cross validation
2023-08-16 01:55:51,128:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:55:52,390:INFO:Calculating mean and std
2023-08-16 01:55:52,391:INFO:Creating metrics dataframe
2023-08-16 01:55:52,505:INFO:Uploading results into container
2023-08-16 01:55:52,506:INFO:Uploading model into container now
2023-08-16 01:55:52,506:INFO:_master_model_container: 21
2023-08-16 01:55:52,506:INFO:_display_container: 3
2023-08-16 01:55:52,506:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-08-16 01:55:52,506:INFO:create_model() successfully completed......................................
2023-08-16 01:55:52,592:INFO:SubProcess create_model() end ==================================
2023-08-16 01:55:52,592:INFO:Creating metrics dataframe
2023-08-16 01:55:52,600:INFO:Initializing Quadratic Discriminant Analysis
2023-08-16 01:55:52,600:INFO:Total runtime is 0.1499281366666158 minutes
2023-08-16 01:55:52,603:INFO:SubProcess create_model() called ==================================
2023-08-16 01:55:52,603:INFO:Initializing create_model()
2023-08-16 01:55:52,603:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0F10>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C0BE0100>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:55:52,604:INFO:Checking exceptions
2023-08-16 01:55:52,604:INFO:Importing libraries
2023-08-16 01:55:52,604:INFO:Copying training dataset
2023-08-16 01:55:52,610:INFO:Defining folds
2023-08-16 01:55:52,610:INFO:Declaring metric variables
2023-08-16 01:55:52,612:INFO:Importing untrained model
2023-08-16 01:55:52,615:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-16 01:55:52,619:INFO:Starting cross validation
2023-08-16 01:55:52,620:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:55:52,656:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:55:52,665:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:55:52,668:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:55:52,672:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:55:52,674:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:55:52,674:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:55:52,674:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:55:52,676:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:55:52,682:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:55:52,682:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:55:52,683:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:55:52,685:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:55:52,686:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:55:52,686:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:55:52,688:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:55:52,688:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:55:52,691:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:55:52,691:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:55:52,691:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:55:52,692:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:55:52,693:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:55:52,693:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:55:52,694:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:55:52,694:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:55:52,694:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:55:52,694:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:55:52,695:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:55:52,695:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:55:52,696:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:55:52,696:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:55:52,697:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:55:52,699:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:55:52,701:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:55:52,702:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:55:52,702:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:55:52,702:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:55:52,702:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:55:52,703:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:55:52,703:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:55:52,703:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:55:52,703:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:55:52,703:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:55:52,703:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:55:52,704:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:55:52,704:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:55:52,705:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:55:52,705:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:55:52,705:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:55:52,705:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:55:52,706:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:55:52,707:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:55:52,710:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:55:52,710:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:55:52,711:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:55:52,712:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:55:52,715:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:55:52,715:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:55:52,715:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:55:52,715:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:55:52,716:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:55:52,716:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:55:52,716:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:55:52,719:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:55:52,719:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:55:52,719:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:55:52,719:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:55:52,720:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:55:52,721:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:55:52,722:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:55:52,722:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:55:52,722:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:55:52,723:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:55:52,725:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:55:52,726:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:55:52,726:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:55:52,728:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:55:52,728:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:55:52,728:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:55:52,730:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:55:52,733:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:55:52,734:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:55:52,734:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:55:52,734:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:55:52,736:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:55:52,738:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:55:52,739:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:55:52,739:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:55:52,739:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:55:52,740:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:55:52,742:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:55:53,627:INFO:Calculating mean and std
2023-08-16 01:55:53,628:INFO:Creating metrics dataframe
2023-08-16 01:55:53,749:INFO:Uploading results into container
2023-08-16 01:55:53,750:INFO:Uploading model into container now
2023-08-16 01:55:53,750:INFO:_master_model_container: 22
2023-08-16 01:55:53,750:INFO:_display_container: 3
2023-08-16 01:55:53,751:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-16 01:55:53,751:INFO:create_model() successfully completed......................................
2023-08-16 01:55:53,826:INFO:SubProcess create_model() end ==================================
2023-08-16 01:55:53,826:INFO:Creating metrics dataframe
2023-08-16 01:55:53,833:INFO:Initializing Ada Boost Classifier
2023-08-16 01:55:53,833:INFO:Total runtime is 0.17047422329584758 minutes
2023-08-16 01:55:53,835:INFO:SubProcess create_model() called ==================================
2023-08-16 01:55:53,835:INFO:Initializing create_model()
2023-08-16 01:55:53,835:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0F10>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C0BE0100>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:55:53,835:INFO:Checking exceptions
2023-08-16 01:55:53,835:INFO:Importing libraries
2023-08-16 01:55:53,835:INFO:Copying training dataset
2023-08-16 01:55:53,840:INFO:Defining folds
2023-08-16 01:55:53,840:INFO:Declaring metric variables
2023-08-16 01:55:53,843:INFO:Importing untrained model
2023-08-16 01:55:53,845:INFO:Ada Boost Classifier Imported successfully
2023-08-16 01:55:53,849:INFO:Starting cross validation
2023-08-16 01:55:53,850:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:55:54,925:INFO:Calculating mean and std
2023-08-16 01:55:54,925:INFO:Creating metrics dataframe
2023-08-16 01:55:55,042:INFO:Uploading results into container
2023-08-16 01:55:55,042:INFO:Uploading model into container now
2023-08-16 01:55:55,043:INFO:_master_model_container: 23
2023-08-16 01:55:55,043:INFO:_display_container: 3
2023-08-16 01:55:55,043:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2023-08-16 01:55:55,043:INFO:create_model() successfully completed......................................
2023-08-16 01:55:55,115:INFO:SubProcess create_model() end ==================================
2023-08-16 01:55:55,115:INFO:Creating metrics dataframe
2023-08-16 01:55:55,123:INFO:Initializing Gradient Boosting Classifier
2023-08-16 01:55:55,123:INFO:Total runtime is 0.19198625087738036 minutes
2023-08-16 01:55:55,126:INFO:SubProcess create_model() called ==================================
2023-08-16 01:55:55,126:INFO:Initializing create_model()
2023-08-16 01:55:55,126:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0F10>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C0BE0100>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:55:55,126:INFO:Checking exceptions
2023-08-16 01:55:55,126:INFO:Importing libraries
2023-08-16 01:55:55,126:INFO:Copying training dataset
2023-08-16 01:55:55,130:INFO:Defining folds
2023-08-16 01:55:55,130:INFO:Declaring metric variables
2023-08-16 01:55:55,132:INFO:Importing untrained model
2023-08-16 01:55:55,135:INFO:Gradient Boosting Classifier Imported successfully
2023-08-16 01:55:55,140:INFO:Starting cross validation
2023-08-16 01:55:55,141:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:55:56,198:INFO:Calculating mean and std
2023-08-16 01:55:56,199:INFO:Creating metrics dataframe
2023-08-16 01:55:56,311:INFO:Uploading results into container
2023-08-16 01:55:56,311:INFO:Uploading model into container now
2023-08-16 01:55:56,312:INFO:_master_model_container: 24
2023-08-16 01:55:56,312:INFO:_display_container: 3
2023-08-16 01:55:56,312:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-16 01:55:56,312:INFO:create_model() successfully completed......................................
2023-08-16 01:55:56,384:INFO:SubProcess create_model() end ==================================
2023-08-16 01:55:56,385:INFO:Creating metrics dataframe
2023-08-16 01:55:56,392:INFO:Initializing Linear Discriminant Analysis
2023-08-16 01:55:56,392:INFO:Total runtime is 0.21312780380249022 minutes
2023-08-16 01:55:56,395:INFO:SubProcess create_model() called ==================================
2023-08-16 01:55:56,395:INFO:Initializing create_model()
2023-08-16 01:55:56,395:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0F10>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C0BE0100>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:55:56,395:INFO:Checking exceptions
2023-08-16 01:55:56,395:INFO:Importing libraries
2023-08-16 01:55:56,395:INFO:Copying training dataset
2023-08-16 01:55:56,399:INFO:Defining folds
2023-08-16 01:55:56,399:INFO:Declaring metric variables
2023-08-16 01:55:56,402:INFO:Importing untrained model
2023-08-16 01:55:56,404:INFO:Linear Discriminant Analysis Imported successfully
2023-08-16 01:55:56,409:INFO:Starting cross validation
2023-08-16 01:55:56,409:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:55:57,400:INFO:Calculating mean and std
2023-08-16 01:55:57,402:INFO:Creating metrics dataframe
2023-08-16 01:55:57,524:INFO:Uploading results into container
2023-08-16 01:55:57,525:INFO:Uploading model into container now
2023-08-16 01:55:57,525:INFO:_master_model_container: 25
2023-08-16 01:55:57,525:INFO:_display_container: 3
2023-08-16 01:55:57,526:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-16 01:55:57,526:INFO:create_model() successfully completed......................................
2023-08-16 01:55:57,599:INFO:SubProcess create_model() end ==================================
2023-08-16 01:55:57,599:INFO:Creating metrics dataframe
2023-08-16 01:55:57,607:INFO:Initializing Extra Trees Classifier
2023-08-16 01:55:57,607:INFO:Total runtime is 0.23338050047556558 minutes
2023-08-16 01:55:57,609:INFO:SubProcess create_model() called ==================================
2023-08-16 01:55:57,610:INFO:Initializing create_model()
2023-08-16 01:55:57,610:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0F10>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C0BE0100>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:55:57,610:INFO:Checking exceptions
2023-08-16 01:55:57,610:INFO:Importing libraries
2023-08-16 01:55:57,610:INFO:Copying training dataset
2023-08-16 01:55:57,614:INFO:Defining folds
2023-08-16 01:55:57,614:INFO:Declaring metric variables
2023-08-16 01:55:57,617:INFO:Importing untrained model
2023-08-16 01:55:57,619:INFO:Extra Trees Classifier Imported successfully
2023-08-16 01:55:57,624:INFO:Starting cross validation
2023-08-16 01:55:57,625:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:55:58,925:INFO:Calculating mean and std
2023-08-16 01:55:58,927:INFO:Creating metrics dataframe
2023-08-16 01:55:59,046:INFO:Uploading results into container
2023-08-16 01:55:59,047:INFO:Uploading model into container now
2023-08-16 01:55:59,047:INFO:_master_model_container: 26
2023-08-16 01:55:59,047:INFO:_display_container: 3
2023-08-16 01:55:59,048:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-08-16 01:55:59,048:INFO:create_model() successfully completed......................................
2023-08-16 01:55:59,113:INFO:SubProcess create_model() end ==================================
2023-08-16 01:55:59,113:INFO:Creating metrics dataframe
2023-08-16 01:55:59,122:INFO:Initializing Light Gradient Boosting Machine
2023-08-16 01:55:59,122:INFO:Total runtime is 0.2586215615272522 minutes
2023-08-16 01:55:59,124:INFO:SubProcess create_model() called ==================================
2023-08-16 01:55:59,124:INFO:Initializing create_model()
2023-08-16 01:55:59,124:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0F10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C0BE0100>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:55:59,124:INFO:Checking exceptions
2023-08-16 01:55:59,124:INFO:Importing libraries
2023-08-16 01:55:59,124:INFO:Copying training dataset
2023-08-16 01:55:59,129:INFO:Defining folds
2023-08-16 01:55:59,130:INFO:Declaring metric variables
2023-08-16 01:55:59,132:INFO:Importing untrained model
2023-08-16 01:55:59,135:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-16 01:55:59,139:INFO:Starting cross validation
2023-08-16 01:55:59,140:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:56:00,289:INFO:Calculating mean and std
2023-08-16 01:56:00,290:INFO:Creating metrics dataframe
2023-08-16 01:56:00,404:INFO:Uploading results into container
2023-08-16 01:56:00,405:INFO:Uploading model into container now
2023-08-16 01:56:00,405:INFO:_master_model_container: 27
2023-08-16 01:56:00,405:INFO:_display_container: 3
2023-08-16 01:56:00,405:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-16 01:56:00,405:INFO:create_model() successfully completed......................................
2023-08-16 01:56:00,472:INFO:SubProcess create_model() end ==================================
2023-08-16 01:56:00,472:INFO:Creating metrics dataframe
2023-08-16 01:56:00,481:INFO:Initializing Dummy Classifier
2023-08-16 01:56:00,481:INFO:Total runtime is 0.28127773602803546 minutes
2023-08-16 01:56:00,483:INFO:SubProcess create_model() called ==================================
2023-08-16 01:56:00,483:INFO:Initializing create_model()
2023-08-16 01:56:00,483:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0F10>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C0BE0100>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:56:00,483:INFO:Checking exceptions
2023-08-16 01:56:00,483:INFO:Importing libraries
2023-08-16 01:56:00,483:INFO:Copying training dataset
2023-08-16 01:56:00,489:INFO:Defining folds
2023-08-16 01:56:00,489:INFO:Declaring metric variables
2023-08-16 01:56:00,490:INFO:Importing untrained model
2023-08-16 01:56:00,492:INFO:Dummy Classifier Imported successfully
2023-08-16 01:56:00,497:INFO:Starting cross validation
2023-08-16 01:56:00,498:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:56:00,588:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:56:00,596:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:56:00,603:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:56:00,610:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:56:00,614:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:56:00,616:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:56:00,619:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:56:00,620:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:56:00,628:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:56:00,628:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:56:01,509:INFO:Calculating mean and std
2023-08-16 01:56:01,511:INFO:Creating metrics dataframe
2023-08-16 01:56:01,631:INFO:Uploading results into container
2023-08-16 01:56:01,631:INFO:Uploading model into container now
2023-08-16 01:56:01,632:INFO:_master_model_container: 28
2023-08-16 01:56:01,632:INFO:_display_container: 3
2023-08-16 01:56:01,632:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-08-16 01:56:01,632:INFO:create_model() successfully completed......................................
2023-08-16 01:56:01,701:INFO:SubProcess create_model() end ==================================
2023-08-16 01:56:01,701:INFO:Creating metrics dataframe
2023-08-16 01:56:01,715:INFO:Initializing create_model()
2023-08-16 01:56:01,715:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0F10>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:56:01,716:INFO:Checking exceptions
2023-08-16 01:56:01,718:INFO:Importing libraries
2023-08-16 01:56:01,718:INFO:Copying training dataset
2023-08-16 01:56:01,722:INFO:Defining folds
2023-08-16 01:56:01,722:INFO:Declaring metric variables
2023-08-16 01:56:01,722:INFO:Importing untrained model
2023-08-16 01:56:01,723:INFO:Declaring custom model
2023-08-16 01:56:01,723:INFO:Ada Boost Classifier Imported successfully
2023-08-16 01:56:01,723:INFO:Cross validation set to False
2023-08-16 01:56:01,723:INFO:Fitting Model
2023-08-16 01:56:01,823:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2023-08-16 01:56:01,824:INFO:create_model() successfully completed......................................
2023-08-16 01:56:01,909:INFO:_master_model_container: 28
2023-08-16 01:56:01,910:INFO:_display_container: 3
2023-08-16 01:56:01,910:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2023-08-16 01:56:01,910:INFO:compare_models() successfully completed......................................
2023-08-16 01:56:18,810:INFO:Initializing compare_models()
2023-08-16 01:56:18,810:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0CD0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0CD0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-16 01:56:18,810:INFO:Checking exceptions
2023-08-16 01:56:18,814:INFO:Preparing display monitor
2023-08-16 01:56:18,839:INFO:Initializing Logistic Regression
2023-08-16 01:56:18,839:INFO:Total runtime is 0.0 minutes
2023-08-16 01:56:18,841:INFO:SubProcess create_model() called ==================================
2023-08-16 01:56:18,841:INFO:Initializing create_model()
2023-08-16 01:56:18,842:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0CD0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C10DC160>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:56:18,842:INFO:Checking exceptions
2023-08-16 01:56:18,842:INFO:Importing libraries
2023-08-16 01:56:18,842:INFO:Copying training dataset
2023-08-16 01:56:18,848:INFO:Defining folds
2023-08-16 01:56:18,849:INFO:Declaring metric variables
2023-08-16 01:56:18,852:INFO:Importing untrained model
2023-08-16 01:56:18,854:INFO:Logistic Regression Imported successfully
2023-08-16 01:56:18,859:INFO:Starting cross validation
2023-08-16 01:56:18,860:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:56:19,868:INFO:Calculating mean and std
2023-08-16 01:56:19,869:INFO:Creating metrics dataframe
2023-08-16 01:56:20,006:INFO:Uploading results into container
2023-08-16 01:56:20,007:INFO:Uploading model into container now
2023-08-16 01:56:20,007:INFO:_master_model_container: 1
2023-08-16 01:56:20,007:INFO:_display_container: 2
2023-08-16 01:56:20,008:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-16 01:56:20,008:INFO:create_model() successfully completed......................................
2023-08-16 01:56:20,073:INFO:SubProcess create_model() end ==================================
2023-08-16 01:56:20,073:INFO:Creating metrics dataframe
2023-08-16 01:56:20,079:INFO:Initializing K Neighbors Classifier
2023-08-16 01:56:20,079:INFO:Total runtime is 0.02065600554148356 minutes
2023-08-16 01:56:20,081:INFO:SubProcess create_model() called ==================================
2023-08-16 01:56:20,081:INFO:Initializing create_model()
2023-08-16 01:56:20,081:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0CD0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C10DC160>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:56:20,082:INFO:Checking exceptions
2023-08-16 01:56:20,082:INFO:Importing libraries
2023-08-16 01:56:20,082:INFO:Copying training dataset
2023-08-16 01:56:20,086:INFO:Defining folds
2023-08-16 01:56:20,087:INFO:Declaring metric variables
2023-08-16 01:56:20,089:INFO:Importing untrained model
2023-08-16 01:56:20,091:INFO:K Neighbors Classifier Imported successfully
2023-08-16 01:56:20,096:INFO:Starting cross validation
2023-08-16 01:56:20,097:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:56:20,194:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:56:20,211:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:56:20,224:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:56:20,224:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:56:20,225:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:56:20,226:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:56:20,240:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:56:20,241:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:56:20,257:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:56:20,259:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:56:21,214:INFO:Calculating mean and std
2023-08-16 01:56:21,215:INFO:Creating metrics dataframe
2023-08-16 01:56:21,324:INFO:Uploading results into container
2023-08-16 01:56:21,325:INFO:Uploading model into container now
2023-08-16 01:56:21,325:INFO:_master_model_container: 2
2023-08-16 01:56:21,325:INFO:_display_container: 2
2023-08-16 01:56:21,325:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-16 01:56:21,325:INFO:create_model() successfully completed......................................
2023-08-16 01:56:21,392:INFO:SubProcess create_model() end ==================================
2023-08-16 01:56:21,392:INFO:Creating metrics dataframe
2023-08-16 01:56:21,399:INFO:Initializing Naive Bayes
2023-08-16 01:56:21,399:INFO:Total runtime is 0.04266660610834758 minutes
2023-08-16 01:56:21,402:INFO:SubProcess create_model() called ==================================
2023-08-16 01:56:21,402:INFO:Initializing create_model()
2023-08-16 01:56:21,402:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0CD0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C10DC160>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:56:21,402:INFO:Checking exceptions
2023-08-16 01:56:21,402:INFO:Importing libraries
2023-08-16 01:56:21,402:INFO:Copying training dataset
2023-08-16 01:56:21,407:INFO:Defining folds
2023-08-16 01:56:21,407:INFO:Declaring metric variables
2023-08-16 01:56:21,409:INFO:Importing untrained model
2023-08-16 01:56:21,411:INFO:Naive Bayes Imported successfully
2023-08-16 01:56:21,416:INFO:Starting cross validation
2023-08-16 01:56:21,416:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:56:22,417:INFO:Calculating mean and std
2023-08-16 01:56:22,418:INFO:Creating metrics dataframe
2023-08-16 01:56:22,535:INFO:Uploading results into container
2023-08-16 01:56:22,536:INFO:Uploading model into container now
2023-08-16 01:56:22,537:INFO:_master_model_container: 3
2023-08-16 01:56:22,537:INFO:_display_container: 2
2023-08-16 01:56:22,537:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-16 01:56:22,537:INFO:create_model() successfully completed......................................
2023-08-16 01:56:22,634:INFO:SubProcess create_model() end ==================================
2023-08-16 01:56:22,634:INFO:Creating metrics dataframe
2023-08-16 01:56:22,641:INFO:Initializing Decision Tree Classifier
2023-08-16 01:56:22,641:INFO:Total runtime is 0.06336516936620076 minutes
2023-08-16 01:56:22,643:INFO:SubProcess create_model() called ==================================
2023-08-16 01:56:22,643:INFO:Initializing create_model()
2023-08-16 01:56:22,644:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0CD0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C10DC160>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:56:22,644:INFO:Checking exceptions
2023-08-16 01:56:22,644:INFO:Importing libraries
2023-08-16 01:56:22,644:INFO:Copying training dataset
2023-08-16 01:56:22,650:INFO:Defining folds
2023-08-16 01:56:22,650:INFO:Declaring metric variables
2023-08-16 01:56:22,653:INFO:Importing untrained model
2023-08-16 01:56:22,657:INFO:Decision Tree Classifier Imported successfully
2023-08-16 01:56:22,662:INFO:Starting cross validation
2023-08-16 01:56:22,663:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:56:23,658:INFO:Calculating mean and std
2023-08-16 01:56:23,659:INFO:Creating metrics dataframe
2023-08-16 01:56:23,773:INFO:Uploading results into container
2023-08-16 01:56:23,774:INFO:Uploading model into container now
2023-08-16 01:56:23,774:INFO:_master_model_container: 4
2023-08-16 01:56:23,774:INFO:_display_container: 2
2023-08-16 01:56:23,774:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-08-16 01:56:23,774:INFO:create_model() successfully completed......................................
2023-08-16 01:56:23,837:INFO:SubProcess create_model() end ==================================
2023-08-16 01:56:23,837:INFO:Creating metrics dataframe
2023-08-16 01:56:23,844:INFO:Initializing SVM - Linear Kernel
2023-08-16 01:56:23,844:INFO:Total runtime is 0.08341500361760457 minutes
2023-08-16 01:56:23,847:INFO:SubProcess create_model() called ==================================
2023-08-16 01:56:23,847:INFO:Initializing create_model()
2023-08-16 01:56:23,847:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0CD0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C10DC160>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:56:23,847:INFO:Checking exceptions
2023-08-16 01:56:23,847:INFO:Importing libraries
2023-08-16 01:56:23,847:INFO:Copying training dataset
2023-08-16 01:56:23,852:INFO:Defining folds
2023-08-16 01:56:23,852:INFO:Declaring metric variables
2023-08-16 01:56:23,855:INFO:Importing untrained model
2023-08-16 01:56:23,857:INFO:SVM - Linear Kernel Imported successfully
2023-08-16 01:56:23,862:INFO:Starting cross validation
2023-08-16 01:56:23,862:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:56:23,942:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:56:23,964:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:56:23,972:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:56:23,975:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:56:23,980:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:56:23,982:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:56:23,982:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:56:23,984:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:56:23,984:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:56:24,006:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:56:24,880:INFO:Calculating mean and std
2023-08-16 01:56:24,882:INFO:Creating metrics dataframe
2023-08-16 01:56:25,010:INFO:Uploading results into container
2023-08-16 01:56:25,011:INFO:Uploading model into container now
2023-08-16 01:56:25,011:INFO:_master_model_container: 5
2023-08-16 01:56:25,011:INFO:_display_container: 2
2023-08-16 01:56:25,011:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-16 01:56:25,011:INFO:create_model() successfully completed......................................
2023-08-16 01:56:25,075:INFO:SubProcess create_model() end ==================================
2023-08-16 01:56:25,075:INFO:Creating metrics dataframe
2023-08-16 01:56:25,084:INFO:Initializing Ridge Classifier
2023-08-16 01:56:25,084:INFO:Total runtime is 0.10407920281092325 minutes
2023-08-16 01:56:25,087:INFO:SubProcess create_model() called ==================================
2023-08-16 01:56:25,087:INFO:Initializing create_model()
2023-08-16 01:56:25,087:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0CD0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C10DC160>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:56:25,087:INFO:Checking exceptions
2023-08-16 01:56:25,087:INFO:Importing libraries
2023-08-16 01:56:25,087:INFO:Copying training dataset
2023-08-16 01:56:25,092:INFO:Defining folds
2023-08-16 01:56:25,092:INFO:Declaring metric variables
2023-08-16 01:56:25,094:INFO:Importing untrained model
2023-08-16 01:56:25,096:INFO:Ridge Classifier Imported successfully
2023-08-16 01:56:25,101:INFO:Starting cross validation
2023-08-16 01:56:25,102:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:56:25,162:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:56:25,164:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:56:25,172:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:56:25,175:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:56:25,185:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:56:25,185:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:56:25,191:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:56:25,199:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:56:25,204:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:56:25,208:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:56:26,100:INFO:Calculating mean and std
2023-08-16 01:56:26,101:INFO:Creating metrics dataframe
2023-08-16 01:56:26,216:INFO:Uploading results into container
2023-08-16 01:56:26,217:INFO:Uploading model into container now
2023-08-16 01:56:26,217:INFO:_master_model_container: 6
2023-08-16 01:56:26,217:INFO:_display_container: 2
2023-08-16 01:56:26,217:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=123, solver='auto', tol=0.001)
2023-08-16 01:56:26,217:INFO:create_model() successfully completed......................................
2023-08-16 01:56:26,285:INFO:SubProcess create_model() end ==================================
2023-08-16 01:56:26,285:INFO:Creating metrics dataframe
2023-08-16 01:56:26,292:INFO:Initializing Random Forest Classifier
2023-08-16 01:56:26,292:INFO:Total runtime is 0.12421144247055053 minutes
2023-08-16 01:56:26,295:INFO:SubProcess create_model() called ==================================
2023-08-16 01:56:26,295:INFO:Initializing create_model()
2023-08-16 01:56:26,295:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0CD0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C10DC160>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:56:26,296:INFO:Checking exceptions
2023-08-16 01:56:26,296:INFO:Importing libraries
2023-08-16 01:56:26,296:INFO:Copying training dataset
2023-08-16 01:56:26,301:INFO:Defining folds
2023-08-16 01:56:26,301:INFO:Declaring metric variables
2023-08-16 01:56:26,303:INFO:Importing untrained model
2023-08-16 01:56:26,306:INFO:Random Forest Classifier Imported successfully
2023-08-16 01:56:26,310:INFO:Starting cross validation
2023-08-16 01:56:26,311:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:56:27,509:INFO:Calculating mean and std
2023-08-16 01:56:27,511:INFO:Creating metrics dataframe
2023-08-16 01:56:27,628:INFO:Uploading results into container
2023-08-16 01:56:27,629:INFO:Uploading model into container now
2023-08-16 01:56:27,629:INFO:_master_model_container: 7
2023-08-16 01:56:27,629:INFO:_display_container: 2
2023-08-16 01:56:27,630:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-08-16 01:56:27,630:INFO:create_model() successfully completed......................................
2023-08-16 01:56:27,698:INFO:SubProcess create_model() end ==================================
2023-08-16 01:56:27,699:INFO:Creating metrics dataframe
2023-08-16 01:56:27,706:INFO:Initializing Quadratic Discriminant Analysis
2023-08-16 01:56:27,706:INFO:Total runtime is 0.14777374664942422 minutes
2023-08-16 01:56:27,708:INFO:SubProcess create_model() called ==================================
2023-08-16 01:56:27,708:INFO:Initializing create_model()
2023-08-16 01:56:27,708:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0CD0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C10DC160>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:56:27,708:INFO:Checking exceptions
2023-08-16 01:56:27,708:INFO:Importing libraries
2023-08-16 01:56:27,708:INFO:Copying training dataset
2023-08-16 01:56:27,713:INFO:Defining folds
2023-08-16 01:56:27,713:INFO:Declaring metric variables
2023-08-16 01:56:27,715:INFO:Importing untrained model
2023-08-16 01:56:27,717:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-16 01:56:27,721:INFO:Starting cross validation
2023-08-16 01:56:27,722:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:56:27,777:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:56:27,783:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:56:27,787:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:56:27,792:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:56:27,795:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:27,795:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:27,795:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:56:27,799:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:56:27,801:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:56:27,801:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:27,801:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:27,801:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:56:27,804:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:27,804:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:27,804:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:56:27,805:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:56:27,806:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:27,807:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:27,807:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:56:27,808:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:56:27,810:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:56:27,813:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:27,813:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:27,813:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:27,813:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:56:27,813:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:56:27,815:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:56:27,817:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:56:27,817:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:56:27,817:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:27,817:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:27,817:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:56:27,818:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:56:27,818:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:27,818:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:27,819:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:27,819:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:27,819:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:56:27,819:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:56:27,820:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:56:27,823:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:27,823:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:27,824:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:56:27,825:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:56:27,828:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:27,828:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:27,828:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:56:27,828:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:56:27,829:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:56:27,830:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:27,830:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:27,831:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:56:27,831:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:56:27,832:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:56:27,833:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:27,833:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:27,833:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:56:27,833:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:27,833:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:27,834:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:56:27,834:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:27,834:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:27,834:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:56:27,834:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:27,835:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:56:27,835:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:27,835:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:27,835:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:56:27,835:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:56:27,835:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:56:27,836:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:56:27,838:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:56:27,839:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:56:27,845:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:27,845:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:27,845:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:56:27,845:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:27,845:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:27,846:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:56:27,846:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:56:27,848:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:56:27,848:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:56:27,851:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:27,851:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:56:27,851:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:27,851:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:56:27,852:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:56:27,854:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:56:28,731:INFO:Calculating mean and std
2023-08-16 01:56:28,732:INFO:Creating metrics dataframe
2023-08-16 01:56:28,852:INFO:Uploading results into container
2023-08-16 01:56:28,852:INFO:Uploading model into container now
2023-08-16 01:56:28,852:INFO:_master_model_container: 8
2023-08-16 01:56:28,853:INFO:_display_container: 2
2023-08-16 01:56:28,853:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-16 01:56:28,853:INFO:create_model() successfully completed......................................
2023-08-16 01:56:28,919:INFO:SubProcess create_model() end ==================================
2023-08-16 01:56:28,919:INFO:Creating metrics dataframe
2023-08-16 01:56:28,927:INFO:Initializing Ada Boost Classifier
2023-08-16 01:56:28,927:INFO:Total runtime is 0.16813276211420694 minutes
2023-08-16 01:56:28,929:INFO:SubProcess create_model() called ==================================
2023-08-16 01:56:28,929:INFO:Initializing create_model()
2023-08-16 01:56:28,929:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0CD0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C10DC160>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:56:28,929:INFO:Checking exceptions
2023-08-16 01:56:28,929:INFO:Importing libraries
2023-08-16 01:56:28,929:INFO:Copying training dataset
2023-08-16 01:56:28,934:INFO:Defining folds
2023-08-16 01:56:28,934:INFO:Declaring metric variables
2023-08-16 01:56:28,936:INFO:Importing untrained model
2023-08-16 01:56:28,938:INFO:Ada Boost Classifier Imported successfully
2023-08-16 01:56:28,943:INFO:Starting cross validation
2023-08-16 01:56:28,944:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:56:29,984:INFO:Calculating mean and std
2023-08-16 01:56:29,986:INFO:Creating metrics dataframe
2023-08-16 01:56:30,107:INFO:Uploading results into container
2023-08-16 01:56:30,108:INFO:Uploading model into container now
2023-08-16 01:56:30,108:INFO:_master_model_container: 9
2023-08-16 01:56:30,108:INFO:_display_container: 2
2023-08-16 01:56:30,108:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2023-08-16 01:56:30,109:INFO:create_model() successfully completed......................................
2023-08-16 01:56:30,172:INFO:SubProcess create_model() end ==================================
2023-08-16 01:56:30,172:INFO:Creating metrics dataframe
2023-08-16 01:56:30,180:INFO:Initializing Gradient Boosting Classifier
2023-08-16 01:56:30,180:INFO:Total runtime is 0.1890138546625773 minutes
2023-08-16 01:56:30,183:INFO:SubProcess create_model() called ==================================
2023-08-16 01:56:30,183:INFO:Initializing create_model()
2023-08-16 01:56:30,183:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0CD0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C10DC160>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:56:30,183:INFO:Checking exceptions
2023-08-16 01:56:30,183:INFO:Importing libraries
2023-08-16 01:56:30,183:INFO:Copying training dataset
2023-08-16 01:56:30,189:INFO:Defining folds
2023-08-16 01:56:30,189:INFO:Declaring metric variables
2023-08-16 01:56:30,191:INFO:Importing untrained model
2023-08-16 01:56:30,194:INFO:Gradient Boosting Classifier Imported successfully
2023-08-16 01:56:30,198:INFO:Starting cross validation
2023-08-16 01:56:30,199:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:56:31,267:INFO:Calculating mean and std
2023-08-16 01:56:31,268:INFO:Creating metrics dataframe
2023-08-16 01:56:31,385:INFO:Uploading results into container
2023-08-16 01:56:31,386:INFO:Uploading model into container now
2023-08-16 01:56:31,387:INFO:_master_model_container: 10
2023-08-16 01:56:31,387:INFO:_display_container: 2
2023-08-16 01:56:31,387:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-16 01:56:31,387:INFO:create_model() successfully completed......................................
2023-08-16 01:56:31,456:INFO:SubProcess create_model() end ==================================
2023-08-16 01:56:31,456:INFO:Creating metrics dataframe
2023-08-16 01:56:31,464:INFO:Initializing Linear Discriminant Analysis
2023-08-16 01:56:31,464:INFO:Total runtime is 0.21041405200958252 minutes
2023-08-16 01:56:31,467:INFO:SubProcess create_model() called ==================================
2023-08-16 01:56:31,467:INFO:Initializing create_model()
2023-08-16 01:56:31,467:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0CD0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C10DC160>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:56:31,467:INFO:Checking exceptions
2023-08-16 01:56:31,467:INFO:Importing libraries
2023-08-16 01:56:31,467:INFO:Copying training dataset
2023-08-16 01:56:31,472:INFO:Defining folds
2023-08-16 01:56:31,472:INFO:Declaring metric variables
2023-08-16 01:56:31,474:INFO:Importing untrained model
2023-08-16 01:56:31,476:INFO:Linear Discriminant Analysis Imported successfully
2023-08-16 01:56:31,481:INFO:Starting cross validation
2023-08-16 01:56:31,482:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:56:32,487:INFO:Calculating mean and std
2023-08-16 01:56:32,488:INFO:Creating metrics dataframe
2023-08-16 01:56:32,605:INFO:Uploading results into container
2023-08-16 01:56:32,606:INFO:Uploading model into container now
2023-08-16 01:56:32,606:INFO:_master_model_container: 11
2023-08-16 01:56:32,606:INFO:_display_container: 2
2023-08-16 01:56:32,606:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-16 01:56:32,606:INFO:create_model() successfully completed......................................
2023-08-16 01:56:32,671:INFO:SubProcess create_model() end ==================================
2023-08-16 01:56:32,671:INFO:Creating metrics dataframe
2023-08-16 01:56:32,680:INFO:Initializing Extra Trees Classifier
2023-08-16 01:56:32,680:INFO:Total runtime is 0.23068068424860635 minutes
2023-08-16 01:56:32,682:INFO:SubProcess create_model() called ==================================
2023-08-16 01:56:32,683:INFO:Initializing create_model()
2023-08-16 01:56:32,683:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0CD0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C10DC160>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:56:32,683:INFO:Checking exceptions
2023-08-16 01:56:32,683:INFO:Importing libraries
2023-08-16 01:56:32,683:INFO:Copying training dataset
2023-08-16 01:56:32,688:INFO:Defining folds
2023-08-16 01:56:32,688:INFO:Declaring metric variables
2023-08-16 01:56:32,690:INFO:Importing untrained model
2023-08-16 01:56:32,692:INFO:Extra Trees Classifier Imported successfully
2023-08-16 01:56:32,696:INFO:Starting cross validation
2023-08-16 01:56:32,697:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:56:33,944:INFO:Calculating mean and std
2023-08-16 01:56:33,945:INFO:Creating metrics dataframe
2023-08-16 01:56:34,070:INFO:Uploading results into container
2023-08-16 01:56:34,071:INFO:Uploading model into container now
2023-08-16 01:56:34,071:INFO:_master_model_container: 12
2023-08-16 01:56:34,072:INFO:_display_container: 2
2023-08-16 01:56:34,072:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-08-16 01:56:34,072:INFO:create_model() successfully completed......................................
2023-08-16 01:56:34,142:INFO:SubProcess create_model() end ==================================
2023-08-16 01:56:34,142:INFO:Creating metrics dataframe
2023-08-16 01:56:34,150:INFO:Initializing Light Gradient Boosting Machine
2023-08-16 01:56:34,150:INFO:Total runtime is 0.2551781137784322 minutes
2023-08-16 01:56:34,153:INFO:SubProcess create_model() called ==================================
2023-08-16 01:56:34,153:INFO:Initializing create_model()
2023-08-16 01:56:34,154:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0CD0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C10DC160>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:56:34,154:INFO:Checking exceptions
2023-08-16 01:56:34,154:INFO:Importing libraries
2023-08-16 01:56:34,154:INFO:Copying training dataset
2023-08-16 01:56:34,158:INFO:Defining folds
2023-08-16 01:56:34,158:INFO:Declaring metric variables
2023-08-16 01:56:34,160:INFO:Importing untrained model
2023-08-16 01:56:34,163:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-16 01:56:34,168:INFO:Starting cross validation
2023-08-16 01:56:34,169:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:56:35,293:INFO:Calculating mean and std
2023-08-16 01:56:35,294:INFO:Creating metrics dataframe
2023-08-16 01:56:35,408:INFO:Uploading results into container
2023-08-16 01:56:35,409:INFO:Uploading model into container now
2023-08-16 01:56:35,409:INFO:_master_model_container: 13
2023-08-16 01:56:35,409:INFO:_display_container: 2
2023-08-16 01:56:35,410:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-16 01:56:35,410:INFO:create_model() successfully completed......................................
2023-08-16 01:56:35,477:INFO:SubProcess create_model() end ==================================
2023-08-16 01:56:35,477:INFO:Creating metrics dataframe
2023-08-16 01:56:35,486:INFO:Initializing Dummy Classifier
2023-08-16 01:56:35,486:INFO:Total runtime is 0.27744276126225786 minutes
2023-08-16 01:56:35,488:INFO:SubProcess create_model() called ==================================
2023-08-16 01:56:35,489:INFO:Initializing create_model()
2023-08-16 01:56:35,489:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0CD0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C10DC160>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:56:35,489:INFO:Checking exceptions
2023-08-16 01:56:35,489:INFO:Importing libraries
2023-08-16 01:56:35,489:INFO:Copying training dataset
2023-08-16 01:56:35,494:INFO:Defining folds
2023-08-16 01:56:35,494:INFO:Declaring metric variables
2023-08-16 01:56:35,497:INFO:Importing untrained model
2023-08-16 01:56:35,499:INFO:Dummy Classifier Imported successfully
2023-08-16 01:56:35,503:INFO:Starting cross validation
2023-08-16 01:56:35,504:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:56:35,555:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:56:35,559:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:56:35,574:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:56:35,575:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:56:35,575:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:56:35,580:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:56:35,583:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:56:35,591:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:56:35,597:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:56:35,599:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:56:36,503:INFO:Calculating mean and std
2023-08-16 01:56:36,504:INFO:Creating metrics dataframe
2023-08-16 01:56:36,625:INFO:Uploading results into container
2023-08-16 01:56:36,626:INFO:Uploading model into container now
2023-08-16 01:56:36,626:INFO:_master_model_container: 14
2023-08-16 01:56:36,626:INFO:_display_container: 2
2023-08-16 01:56:36,627:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-08-16 01:56:36,627:INFO:create_model() successfully completed......................................
2023-08-16 01:56:36,692:INFO:SubProcess create_model() end ==================================
2023-08-16 01:56:36,692:INFO:Creating metrics dataframe
2023-08-16 01:56:36,706:INFO:Initializing create_model()
2023-08-16 01:56:36,706:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0CD0>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:56:36,706:INFO:Checking exceptions
2023-08-16 01:56:36,708:INFO:Importing libraries
2023-08-16 01:56:36,709:INFO:Copying training dataset
2023-08-16 01:56:36,714:INFO:Defining folds
2023-08-16 01:56:36,714:INFO:Declaring metric variables
2023-08-16 01:56:36,714:INFO:Importing untrained model
2023-08-16 01:56:36,714:INFO:Declaring custom model
2023-08-16 01:56:36,715:INFO:Ada Boost Classifier Imported successfully
2023-08-16 01:56:36,715:INFO:Cross validation set to False
2023-08-16 01:56:36,715:INFO:Fitting Model
2023-08-16 01:56:36,814:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2023-08-16 01:56:36,814:INFO:create_model() successfully completed......................................
2023-08-16 01:56:36,896:INFO:_master_model_container: 14
2023-08-16 01:56:36,897:INFO:_display_container: 2
2023-08-16 01:56:36,897:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2023-08-16 01:56:36,897:INFO:compare_models() successfully completed......................................
2023-08-16 01:56:43,833:INFO:Initializing compare_models()
2023-08-16 01:56:43,833:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0CD0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0CD0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-16 01:56:43,833:INFO:Checking exceptions
2023-08-16 01:56:43,836:INFO:Preparing display monitor
2023-08-16 01:56:43,862:INFO:Initializing Logistic Regression
2023-08-16 01:56:43,863:INFO:Total runtime is 1.6860167185465495e-05 minutes
2023-08-16 01:56:43,866:INFO:SubProcess create_model() called ==================================
2023-08-16 01:56:43,866:INFO:Initializing create_model()
2023-08-16 01:56:43,866:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0CD0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C116C220>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:56:43,866:INFO:Checking exceptions
2023-08-16 01:56:43,866:INFO:Importing libraries
2023-08-16 01:56:43,866:INFO:Copying training dataset
2023-08-16 01:56:43,872:INFO:Defining folds
2023-08-16 01:56:43,872:INFO:Declaring metric variables
2023-08-16 01:56:43,874:INFO:Importing untrained model
2023-08-16 01:56:43,877:INFO:Logistic Regression Imported successfully
2023-08-16 01:56:43,882:INFO:Starting cross validation
2023-08-16 01:56:43,883:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:56:44,892:INFO:Calculating mean and std
2023-08-16 01:56:44,893:INFO:Creating metrics dataframe
2023-08-16 01:56:45,023:INFO:Uploading results into container
2023-08-16 01:56:45,024:INFO:Uploading model into container now
2023-08-16 01:56:45,024:INFO:_master_model_container: 15
2023-08-16 01:56:45,024:INFO:_display_container: 3
2023-08-16 01:56:45,025:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-16 01:56:45,025:INFO:create_model() successfully completed......................................
2023-08-16 01:56:45,088:INFO:SubProcess create_model() end ==================================
2023-08-16 01:56:45,088:INFO:Creating metrics dataframe
2023-08-16 01:56:45,094:INFO:Initializing K Neighbors Classifier
2023-08-16 01:56:45,094:INFO:Total runtime is 0.02054303487141927 minutes
2023-08-16 01:56:45,096:INFO:SubProcess create_model() called ==================================
2023-08-16 01:56:45,096:INFO:Initializing create_model()
2023-08-16 01:56:45,097:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0CD0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C116C220>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:56:45,097:INFO:Checking exceptions
2023-08-16 01:56:45,097:INFO:Importing libraries
2023-08-16 01:56:45,097:INFO:Copying training dataset
2023-08-16 01:56:45,102:INFO:Defining folds
2023-08-16 01:56:45,102:INFO:Declaring metric variables
2023-08-16 01:56:45,105:INFO:Importing untrained model
2023-08-16 01:56:45,107:INFO:K Neighbors Classifier Imported successfully
2023-08-16 01:56:45,111:INFO:Starting cross validation
2023-08-16 01:56:45,112:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:56:45,213:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:56:45,215:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:56:45,230:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:56:45,231:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:56:45,249:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:56:45,249:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:56:45,259:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:56:45,259:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:56:45,274:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:56:45,289:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:56:46,235:INFO:Calculating mean and std
2023-08-16 01:56:46,236:INFO:Creating metrics dataframe
2023-08-16 01:56:46,347:INFO:Uploading results into container
2023-08-16 01:56:46,348:INFO:Uploading model into container now
2023-08-16 01:56:46,348:INFO:_master_model_container: 16
2023-08-16 01:56:46,348:INFO:_display_container: 3
2023-08-16 01:56:46,349:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-16 01:56:46,349:INFO:create_model() successfully completed......................................
2023-08-16 01:56:46,417:INFO:SubProcess create_model() end ==================================
2023-08-16 01:56:46,417:INFO:Creating metrics dataframe
2023-08-16 01:56:46,424:INFO:Initializing Naive Bayes
2023-08-16 01:56:46,424:INFO:Total runtime is 0.042705309391021726 minutes
2023-08-16 01:56:46,427:INFO:SubProcess create_model() called ==================================
2023-08-16 01:56:46,427:INFO:Initializing create_model()
2023-08-16 01:56:46,427:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0CD0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C116C220>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:56:46,427:INFO:Checking exceptions
2023-08-16 01:56:46,427:INFO:Importing libraries
2023-08-16 01:56:46,427:INFO:Copying training dataset
2023-08-16 01:56:46,432:INFO:Defining folds
2023-08-16 01:56:46,432:INFO:Declaring metric variables
2023-08-16 01:56:46,434:INFO:Importing untrained model
2023-08-16 01:56:46,436:INFO:Naive Bayes Imported successfully
2023-08-16 01:56:46,440:INFO:Starting cross validation
2023-08-16 01:56:46,441:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:56:47,471:INFO:Calculating mean and std
2023-08-16 01:56:47,472:INFO:Creating metrics dataframe
2023-08-16 01:56:47,583:INFO:Uploading results into container
2023-08-16 01:56:47,583:INFO:Uploading model into container now
2023-08-16 01:56:47,584:INFO:_master_model_container: 17
2023-08-16 01:56:47,584:INFO:_display_container: 3
2023-08-16 01:56:47,584:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-16 01:56:47,584:INFO:create_model() successfully completed......................................
2023-08-16 01:56:47,652:INFO:SubProcess create_model() end ==================================
2023-08-16 01:56:47,653:INFO:Creating metrics dataframe
2023-08-16 01:56:47,659:INFO:Initializing Decision Tree Classifier
2023-08-16 01:56:47,660:INFO:Total runtime is 0.06330573558807373 minutes
2023-08-16 01:56:47,662:INFO:SubProcess create_model() called ==================================
2023-08-16 01:56:47,662:INFO:Initializing create_model()
2023-08-16 01:56:47,662:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0CD0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C116C220>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:56:47,663:INFO:Checking exceptions
2023-08-16 01:56:47,663:INFO:Importing libraries
2023-08-16 01:56:47,663:INFO:Copying training dataset
2023-08-16 01:56:47,667:INFO:Defining folds
2023-08-16 01:56:47,667:INFO:Declaring metric variables
2023-08-16 01:56:47,670:INFO:Importing untrained model
2023-08-16 01:56:47,672:INFO:Decision Tree Classifier Imported successfully
2023-08-16 01:56:47,676:INFO:Starting cross validation
2023-08-16 01:56:47,677:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:56:48,697:INFO:Calculating mean and std
2023-08-16 01:56:48,698:INFO:Creating metrics dataframe
2023-08-16 01:56:48,835:INFO:Uploading results into container
2023-08-16 01:56:48,835:INFO:Uploading model into container now
2023-08-16 01:56:48,836:INFO:_master_model_container: 18
2023-08-16 01:56:48,836:INFO:_display_container: 3
2023-08-16 01:56:48,836:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-08-16 01:56:48,836:INFO:create_model() successfully completed......................................
2023-08-16 01:56:48,925:INFO:SubProcess create_model() end ==================================
2023-08-16 01:56:48,926:INFO:Creating metrics dataframe
2023-08-16 01:56:48,934:INFO:Initializing SVM - Linear Kernel
2023-08-16 01:56:48,934:INFO:Total runtime is 0.08454409440358479 minutes
2023-08-16 01:56:48,936:INFO:SubProcess create_model() called ==================================
2023-08-16 01:56:48,936:INFO:Initializing create_model()
2023-08-16 01:56:48,936:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0CD0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C116C220>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:56:48,937:INFO:Checking exceptions
2023-08-16 01:56:48,937:INFO:Importing libraries
2023-08-16 01:56:48,937:INFO:Copying training dataset
2023-08-16 01:56:48,943:INFO:Defining folds
2023-08-16 01:56:48,943:INFO:Declaring metric variables
2023-08-16 01:56:48,946:INFO:Importing untrained model
2023-08-16 01:56:48,949:INFO:SVM - Linear Kernel Imported successfully
2023-08-16 01:56:48,953:INFO:Starting cross validation
2023-08-16 01:56:48,953:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:56:49,050:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:56:49,054:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:56:49,060:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:56:49,066:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:56:49,094:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:56:49,098:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:56:49,100:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:56:49,111:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:56:49,113:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:56:49,116:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:56:49,982:INFO:Calculating mean and std
2023-08-16 01:56:49,984:INFO:Creating metrics dataframe
2023-08-16 01:56:50,097:INFO:Uploading results into container
2023-08-16 01:56:50,097:INFO:Uploading model into container now
2023-08-16 01:56:50,097:INFO:_master_model_container: 19
2023-08-16 01:56:50,098:INFO:_display_container: 3
2023-08-16 01:56:50,098:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-16 01:56:50,098:INFO:create_model() successfully completed......................................
2023-08-16 01:56:50,164:INFO:SubProcess create_model() end ==================================
2023-08-16 01:56:50,164:INFO:Creating metrics dataframe
2023-08-16 01:56:50,172:INFO:Initializing Ridge Classifier
2023-08-16 01:56:50,173:INFO:Total runtime is 0.10519503752390542 minutes
2023-08-16 01:56:50,175:INFO:SubProcess create_model() called ==================================
2023-08-16 01:56:50,176:INFO:Initializing create_model()
2023-08-16 01:56:50,176:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0CD0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C116C220>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:56:50,176:INFO:Checking exceptions
2023-08-16 01:56:50,176:INFO:Importing libraries
2023-08-16 01:56:50,176:INFO:Copying training dataset
2023-08-16 01:56:50,180:INFO:Defining folds
2023-08-16 01:56:50,180:INFO:Declaring metric variables
2023-08-16 01:56:50,182:INFO:Importing untrained model
2023-08-16 01:56:50,184:INFO:Ridge Classifier Imported successfully
2023-08-16 01:56:50,189:INFO:Starting cross validation
2023-08-16 01:56:50,190:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:56:50,253:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:56:50,261:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:56:50,263:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:56:50,266:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:56:50,274:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:56:50,277:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:56:50,278:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:56:50,284:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:56:50,292:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:56:50,300:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:56:51,182:INFO:Calculating mean and std
2023-08-16 01:56:51,184:INFO:Creating metrics dataframe
2023-08-16 01:56:51,303:INFO:Uploading results into container
2023-08-16 01:56:51,304:INFO:Uploading model into container now
2023-08-16 01:56:51,304:INFO:_master_model_container: 20
2023-08-16 01:56:51,304:INFO:_display_container: 3
2023-08-16 01:56:51,305:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=123, solver='auto', tol=0.001)
2023-08-16 01:56:51,305:INFO:create_model() successfully completed......................................
2023-08-16 01:56:51,371:INFO:SubProcess create_model() end ==================================
2023-08-16 01:56:51,371:INFO:Creating metrics dataframe
2023-08-16 01:56:51,378:INFO:Initializing Random Forest Classifier
2023-08-16 01:56:51,378:INFO:Total runtime is 0.12527751922607422 minutes
2023-08-16 01:56:51,380:INFO:SubProcess create_model() called ==================================
2023-08-16 01:56:51,380:INFO:Initializing create_model()
2023-08-16 01:56:51,380:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0CD0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C116C220>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:56:51,380:INFO:Checking exceptions
2023-08-16 01:56:51,380:INFO:Importing libraries
2023-08-16 01:56:51,380:INFO:Copying training dataset
2023-08-16 01:56:51,385:INFO:Defining folds
2023-08-16 01:56:51,385:INFO:Declaring metric variables
2023-08-16 01:56:51,388:INFO:Importing untrained model
2023-08-16 01:56:51,390:INFO:Random Forest Classifier Imported successfully
2023-08-16 01:56:51,395:INFO:Starting cross validation
2023-08-16 01:56:51,395:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:56:52,671:INFO:Calculating mean and std
2023-08-16 01:56:52,672:INFO:Creating metrics dataframe
2023-08-16 01:56:52,780:INFO:Uploading results into container
2023-08-16 01:56:52,781:INFO:Uploading model into container now
2023-08-16 01:56:52,782:INFO:_master_model_container: 21
2023-08-16 01:56:52,782:INFO:_display_container: 3
2023-08-16 01:56:52,782:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-08-16 01:56:52,782:INFO:create_model() successfully completed......................................
2023-08-16 01:56:52,848:INFO:SubProcess create_model() end ==================================
2023-08-16 01:56:52,849:INFO:Creating metrics dataframe
2023-08-16 01:56:52,856:INFO:Initializing Quadratic Discriminant Analysis
2023-08-16 01:56:52,856:INFO:Total runtime is 0.14990886449813842 minutes
2023-08-16 01:56:52,859:INFO:SubProcess create_model() called ==================================
2023-08-16 01:56:52,859:INFO:Initializing create_model()
2023-08-16 01:56:52,859:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0CD0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C116C220>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:56:52,859:INFO:Checking exceptions
2023-08-16 01:56:52,859:INFO:Importing libraries
2023-08-16 01:56:52,859:INFO:Copying training dataset
2023-08-16 01:56:52,864:INFO:Defining folds
2023-08-16 01:56:52,864:INFO:Declaring metric variables
2023-08-16 01:56:52,866:INFO:Importing untrained model
2023-08-16 01:56:52,869:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-16 01:56:52,873:INFO:Starting cross validation
2023-08-16 01:56:52,874:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:56:52,912:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:56:52,923:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:56:52,928:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:56:52,929:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:56:52,934:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:52,935:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:52,935:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:56:52,935:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:56:52,938:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:52,938:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:52,938:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:56:52,941:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:52,942:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:52,942:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:56:52,946:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

.5)))

2023-08-16 01:56:52,946:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:52,946:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:56:52,947:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:52,947:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:52,947:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:56:52,947:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:56:52,948:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:56:52,949:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:52,949:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:52,949:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:52,949:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:52,949:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:56:52,950:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:56:52,950:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:56:52,951:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:56:52,951:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:56:52,952:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:56:52,953:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:56:52,954:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:52,954:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:52,954:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:56:52,955:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:56:52,957:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:56:52,957:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 01:56:52,960:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:52,960:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:52,960:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:56:52,962:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:52,962:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:52,962:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:56:52,962:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:52,962:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:52,963:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:56:52,964:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:56:52,966:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:56:52,967:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:52,967:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:52,968:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:56:52,968:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:52,968:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:52,968:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:52,969:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:52,968:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:56:52,969:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:56:52,971:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:56:52,972:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:52,972:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:52,972:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:56:52,973:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:56:52,974:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:56:52,974:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:52,975:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:52,975:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:56:52,976:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:56:52,978:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:52,978:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:52,978:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:56:52,979:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:56:52,979:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:52,980:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:52,980:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:56:52,981:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:56:52,982:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:56:52,983:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:56:52,987:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:52,987:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:52,987:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:56:52,988:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:56:52,990:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:56:52,991:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:52,991:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 01:56:52,991:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 01:56:52,992:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 309, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_ranking.py", line 546, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 800, in check_array
    _assert_all_finite(array, allow_nan=force_all_finite == "allow-nan")
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\validation.py", line 114, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').

  warnings.warn(

2023-08-16 01:56:52,995:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:56:53,877:INFO:Calculating mean and std
2023-08-16 01:56:53,879:INFO:Creating metrics dataframe
2023-08-16 01:56:54,006:INFO:Uploading results into container
2023-08-16 01:56:54,007:INFO:Uploading model into container now
2023-08-16 01:56:54,007:INFO:_master_model_container: 22
2023-08-16 01:56:54,007:INFO:_display_container: 3
2023-08-16 01:56:54,008:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-16 01:56:54,008:INFO:create_model() successfully completed......................................
2023-08-16 01:56:54,077:INFO:SubProcess create_model() end ==================================
2023-08-16 01:56:54,077:INFO:Creating metrics dataframe
2023-08-16 01:56:54,085:INFO:Initializing Ada Boost Classifier
2023-08-16 01:56:54,085:INFO:Total runtime is 0.17038967609405517 minutes
2023-08-16 01:56:54,088:INFO:SubProcess create_model() called ==================================
2023-08-16 01:56:54,088:INFO:Initializing create_model()
2023-08-16 01:56:54,088:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0CD0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C116C220>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:56:54,089:INFO:Checking exceptions
2023-08-16 01:56:54,089:INFO:Importing libraries
2023-08-16 01:56:54,089:INFO:Copying training dataset
2023-08-16 01:56:54,094:INFO:Defining folds
2023-08-16 01:56:54,094:INFO:Declaring metric variables
2023-08-16 01:56:54,096:INFO:Importing untrained model
2023-08-16 01:56:54,098:INFO:Ada Boost Classifier Imported successfully
2023-08-16 01:56:54,103:INFO:Starting cross validation
2023-08-16 01:56:54,103:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:56:55,153:INFO:Calculating mean and std
2023-08-16 01:56:55,154:INFO:Creating metrics dataframe
2023-08-16 01:56:55,271:INFO:Uploading results into container
2023-08-16 01:56:55,271:INFO:Uploading model into container now
2023-08-16 01:56:55,272:INFO:_master_model_container: 23
2023-08-16 01:56:55,272:INFO:_display_container: 3
2023-08-16 01:56:55,272:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2023-08-16 01:56:55,272:INFO:create_model() successfully completed......................................
2023-08-16 01:56:55,338:INFO:SubProcess create_model() end ==================================
2023-08-16 01:56:55,338:INFO:Creating metrics dataframe
2023-08-16 01:56:55,346:INFO:Initializing Gradient Boosting Classifier
2023-08-16 01:56:55,346:INFO:Total runtime is 0.19139843781789143 minutes
2023-08-16 01:56:55,348:INFO:SubProcess create_model() called ==================================
2023-08-16 01:56:55,348:INFO:Initializing create_model()
2023-08-16 01:56:55,348:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0CD0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C116C220>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:56:55,348:INFO:Checking exceptions
2023-08-16 01:56:55,348:INFO:Importing libraries
2023-08-16 01:56:55,348:INFO:Copying training dataset
2023-08-16 01:56:55,353:INFO:Defining folds
2023-08-16 01:56:55,353:INFO:Declaring metric variables
2023-08-16 01:56:55,355:INFO:Importing untrained model
2023-08-16 01:56:55,357:INFO:Gradient Boosting Classifier Imported successfully
2023-08-16 01:56:55,362:INFO:Starting cross validation
2023-08-16 01:56:55,362:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:56:56,424:INFO:Calculating mean and std
2023-08-16 01:56:56,426:INFO:Creating metrics dataframe
2023-08-16 01:56:56,542:INFO:Uploading results into container
2023-08-16 01:56:56,543:INFO:Uploading model into container now
2023-08-16 01:56:56,543:INFO:_master_model_container: 24
2023-08-16 01:56:56,544:INFO:_display_container: 3
2023-08-16 01:56:56,544:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-16 01:56:56,544:INFO:create_model() successfully completed......................................
2023-08-16 01:56:56,608:INFO:SubProcess create_model() end ==================================
2023-08-16 01:56:56,608:INFO:Creating metrics dataframe
2023-08-16 01:56:56,616:INFO:Initializing Linear Discriminant Analysis
2023-08-16 01:56:56,616:INFO:Total runtime is 0.2125722845395406 minutes
2023-08-16 01:56:56,618:INFO:SubProcess create_model() called ==================================
2023-08-16 01:56:56,619:INFO:Initializing create_model()
2023-08-16 01:56:56,619:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0CD0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C116C220>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:56:56,619:INFO:Checking exceptions
2023-08-16 01:56:56,619:INFO:Importing libraries
2023-08-16 01:56:56,619:INFO:Copying training dataset
2023-08-16 01:56:56,623:INFO:Defining folds
2023-08-16 01:56:56,623:INFO:Declaring metric variables
2023-08-16 01:56:56,625:INFO:Importing untrained model
2023-08-16 01:56:56,627:INFO:Linear Discriminant Analysis Imported successfully
2023-08-16 01:56:56,632:INFO:Starting cross validation
2023-08-16 01:56:56,632:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:56:57,645:INFO:Calculating mean and std
2023-08-16 01:56:57,646:INFO:Creating metrics dataframe
2023-08-16 01:56:57,761:INFO:Uploading results into container
2023-08-16 01:56:57,762:INFO:Uploading model into container now
2023-08-16 01:56:57,762:INFO:_master_model_container: 25
2023-08-16 01:56:57,763:INFO:_display_container: 3
2023-08-16 01:56:57,763:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-16 01:56:57,763:INFO:create_model() successfully completed......................................
2023-08-16 01:56:57,826:INFO:SubProcess create_model() end ==================================
2023-08-16 01:56:57,827:INFO:Creating metrics dataframe
2023-08-16 01:56:57,834:INFO:Initializing Extra Trees Classifier
2023-08-16 01:56:57,835:INFO:Total runtime is 0.23288447856903077 minutes
2023-08-16 01:56:57,837:INFO:SubProcess create_model() called ==================================
2023-08-16 01:56:57,838:INFO:Initializing create_model()
2023-08-16 01:56:57,838:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0CD0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C116C220>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:56:57,838:INFO:Checking exceptions
2023-08-16 01:56:57,838:INFO:Importing libraries
2023-08-16 01:56:57,838:INFO:Copying training dataset
2023-08-16 01:56:57,842:INFO:Defining folds
2023-08-16 01:56:57,842:INFO:Declaring metric variables
2023-08-16 01:56:57,844:INFO:Importing untrained model
2023-08-16 01:56:57,846:INFO:Extra Trees Classifier Imported successfully
2023-08-16 01:56:57,851:INFO:Starting cross validation
2023-08-16 01:56:57,851:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:56:59,131:INFO:Calculating mean and std
2023-08-16 01:56:59,132:INFO:Creating metrics dataframe
2023-08-16 01:56:59,246:INFO:Uploading results into container
2023-08-16 01:56:59,246:INFO:Uploading model into container now
2023-08-16 01:56:59,247:INFO:_master_model_container: 26
2023-08-16 01:56:59,247:INFO:_display_container: 3
2023-08-16 01:56:59,247:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-08-16 01:56:59,247:INFO:create_model() successfully completed......................................
2023-08-16 01:56:59,311:INFO:SubProcess create_model() end ==================================
2023-08-16 01:56:59,312:INFO:Creating metrics dataframe
2023-08-16 01:56:59,320:INFO:Initializing Light Gradient Boosting Machine
2023-08-16 01:56:59,320:INFO:Total runtime is 0.2576310952504476 minutes
2023-08-16 01:56:59,323:INFO:SubProcess create_model() called ==================================
2023-08-16 01:56:59,323:INFO:Initializing create_model()
2023-08-16 01:56:59,323:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0CD0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C116C220>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:56:59,324:INFO:Checking exceptions
2023-08-16 01:56:59,324:INFO:Importing libraries
2023-08-16 01:56:59,324:INFO:Copying training dataset
2023-08-16 01:56:59,328:INFO:Defining folds
2023-08-16 01:56:59,328:INFO:Declaring metric variables
2023-08-16 01:56:59,330:INFO:Importing untrained model
2023-08-16 01:56:59,332:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-16 01:56:59,337:INFO:Starting cross validation
2023-08-16 01:56:59,338:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:57:00,443:INFO:Calculating mean and std
2023-08-16 01:57:00,444:INFO:Creating metrics dataframe
2023-08-16 01:57:00,557:INFO:Uploading results into container
2023-08-16 01:57:00,558:INFO:Uploading model into container now
2023-08-16 01:57:00,558:INFO:_master_model_container: 27
2023-08-16 01:57:00,558:INFO:_display_container: 3
2023-08-16 01:57:00,558:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-16 01:57:00,558:INFO:create_model() successfully completed......................................
2023-08-16 01:57:00,623:INFO:SubProcess create_model() end ==================================
2023-08-16 01:57:00,623:INFO:Creating metrics dataframe
2023-08-16 01:57:00,632:INFO:Initializing Dummy Classifier
2023-08-16 01:57:00,632:INFO:Total runtime is 0.27950984239578247 minutes
2023-08-16 01:57:00,634:INFO:SubProcess create_model() called ==================================
2023-08-16 01:57:00,634:INFO:Initializing create_model()
2023-08-16 01:57:00,635:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0CD0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C116C220>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:57:00,635:INFO:Checking exceptions
2023-08-16 01:57:00,635:INFO:Importing libraries
2023-08-16 01:57:00,635:INFO:Copying training dataset
2023-08-16 01:57:00,639:INFO:Defining folds
2023-08-16 01:57:00,639:INFO:Declaring metric variables
2023-08-16 01:57:00,641:INFO:Importing untrained model
2023-08-16 01:57:00,643:INFO:Dummy Classifier Imported successfully
2023-08-16 01:57:00,647:INFO:Starting cross validation
2023-08-16 01:57:00,648:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:57:00,719:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:57:00,721:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:57:00,724:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:57:00,729:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:57:00,733:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:57:00,739:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:57:00,740:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:57:00,740:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:57:00,746:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:57:00,751:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:57:01,647:INFO:Calculating mean and std
2023-08-16 01:57:01,648:INFO:Creating metrics dataframe
2023-08-16 01:57:01,759:INFO:Uploading results into container
2023-08-16 01:57:01,760:INFO:Uploading model into container now
2023-08-16 01:57:01,761:INFO:_master_model_container: 28
2023-08-16 01:57:01,761:INFO:_display_container: 3
2023-08-16 01:57:01,761:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-08-16 01:57:01,761:INFO:create_model() successfully completed......................................
2023-08-16 01:57:01,846:INFO:SubProcess create_model() end ==================================
2023-08-16 01:57:01,846:INFO:Creating metrics dataframe
2023-08-16 01:57:01,860:INFO:Initializing create_model()
2023-08-16 01:57:01,860:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0CD0>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:57:01,860:INFO:Checking exceptions
2023-08-16 01:57:01,862:INFO:Importing libraries
2023-08-16 01:57:01,862:INFO:Copying training dataset
2023-08-16 01:57:01,866:INFO:Defining folds
2023-08-16 01:57:01,866:INFO:Declaring metric variables
2023-08-16 01:57:01,866:INFO:Importing untrained model
2023-08-16 01:57:01,866:INFO:Declaring custom model
2023-08-16 01:57:01,867:INFO:Ada Boost Classifier Imported successfully
2023-08-16 01:57:01,867:INFO:Cross validation set to False
2023-08-16 01:57:01,867:INFO:Fitting Model
2023-08-16 01:57:01,966:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2023-08-16 01:57:01,966:INFO:create_model() successfully completed......................................
2023-08-16 01:57:02,050:INFO:_master_model_container: 28
2023-08-16 01:57:02,051:INFO:_display_container: 3
2023-08-16 01:57:02,051:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2023-08-16 01:57:02,051:INFO:compare_models() successfully completed......................................
2023-08-16 01:57:34,991:INFO:Initializing plot_model()
2023-08-16 01:57:34,991:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0F10>, system=True)
2023-08-16 01:57:34,991:INFO:Checking exceptions
2023-08-16 01:57:34,996:INFO:Preloading libraries
2023-08-16 01:57:34,999:INFO:Copying training dataset
2023-08-16 01:57:34,999:INFO:Plot type: confusion_matrix
2023-08-16 01:57:35,060:INFO:Fitting Model
2023-08-16 01:57:35,063:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names
  warnings.warn(

2023-08-16 01:57:35,063:INFO:Scoring test/hold-out set
2023-08-16 01:57:35,199:INFO:Visual Rendered Successfully
2023-08-16 01:57:35,277:INFO:plot_model() successfully completed......................................
2023-08-16 01:57:41,798:INFO:Initializing plot_model()
2023-08-16 01:57:41,798:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0F10>, system=True)
2023-08-16 01:57:41,799:INFO:Checking exceptions
2023-08-16 01:57:41,803:INFO:Preloading libraries
2023-08-16 01:57:41,807:INFO:Copying training dataset
2023-08-16 01:57:41,807:INFO:Plot type: auc
2023-08-16 01:57:41,866:INFO:Fitting Model
2023-08-16 01:57:41,866:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names
  warnings.warn(

2023-08-16 01:57:41,866:INFO:Scoring test/hold-out set
2023-08-16 01:57:42,008:INFO:Visual Rendered Successfully
2023-08-16 01:57:42,077:INFO:plot_model() successfully completed......................................
2023-08-16 01:57:46,686:INFO:Initializing plot_model()
2023-08-16 01:57:46,686:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C06E0F10>, system=True)
2023-08-16 01:57:46,686:INFO:Checking exceptions
2023-08-16 01:57:46,692:INFO:Preloading libraries
2023-08-16 01:57:46,695:INFO:Copying training dataset
2023-08-16 01:57:46,695:INFO:Plot type: feature
2023-08-16 01:57:46,696:WARNING:No coef_ found. Trying feature_importances_
2023-08-16 01:57:46,784:INFO:Visual Rendered Successfully
2023-08-16 01:57:46,850:INFO:plot_model() successfully completed......................................
2023-08-16 01:57:57,181:INFO:PyCaret ClassificationExperiment
2023-08-16 01:57:57,181:INFO:Logging name: clf-default-name
2023-08-16 01:57:57,181:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-16 01:57:57,181:INFO:version 3.0.4
2023-08-16 01:57:57,181:INFO:Initializing setup()
2023-08-16 01:57:57,181:INFO:self.USI: 53d3
2023-08-16 01:57:57,181:INFO:self._variable_keys: {'pipeline', 'fold_groups_param', 'X_test', 'idx', '_available_plots', 'X_train', 'fix_imbalance', 'y_test', 'y', 'memory', 'gpu_n_jobs_param', 'n_jobs_param', 'logging_param', 'log_plots_param', 'USI', 'is_multiclass', 'fold_generator', 'target_param', 'exp_id', '_ml_usecase', 'fold_shuffle_param', 'data', 'gpu_param', 'y_train', 'html_param', 'exp_name_log', 'seed', 'X'}
2023-08-16 01:57:57,181:INFO:Checking environment
2023-08-16 01:57:57,181:INFO:python_version: 3.9.13
2023-08-16 01:57:57,181:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-08-16 01:57:57,181:INFO:machine: AMD64
2023-08-16 01:57:57,181:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-16 01:57:57,181:INFO:Memory: svmem(total=16905969664, available=2315485184, percent=86.3, used=14590484480, free=2315485184)
2023-08-16 01:57:57,182:INFO:Physical Core: 8
2023-08-16 01:57:57,182:INFO:Logical Core: 16
2023-08-16 01:57:57,182:INFO:Checking libraries
2023-08-16 01:57:57,182:INFO:System:
2023-08-16 01:57:57,182:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-08-16 01:57:57,182:INFO:executable: c:\Users\lmacciomaretto\anaconda3\python.exe
2023-08-16 01:57:57,182:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-16 01:57:57,182:INFO:PyCaret required dependencies:
2023-08-16 01:57:57,182:INFO:                 pip: 22.2.2
2023-08-16 01:57:57,182:INFO:          setuptools: 63.4.1
2023-08-16 01:57:57,182:INFO:             pycaret: 3.0.4
2023-08-16 01:57:57,182:INFO:             IPython: 7.31.1
2023-08-16 01:57:57,182:INFO:          ipywidgets: 7.6.5
2023-08-16 01:57:57,182:INFO:                tqdm: 4.64.1
2023-08-16 01:57:57,182:INFO:               numpy: 1.21.5
2023-08-16 01:57:57,183:INFO:              pandas: 1.4.4
2023-08-16 01:57:57,183:INFO:              jinja2: 2.11.3
2023-08-16 01:57:57,183:INFO:               scipy: 1.9.1
2023-08-16 01:57:57,183:INFO:              joblib: 1.3.2
2023-08-16 01:57:57,183:INFO:             sklearn: 1.0.2
2023-08-16 01:57:57,183:INFO:                pyod: 1.1.0
2023-08-16 01:57:57,183:INFO:            imblearn: 0.11.0
2023-08-16 01:57:57,183:INFO:   category_encoders: 2.6.2
2023-08-16 01:57:57,183:INFO:            lightgbm: 4.0.0
2023-08-16 01:57:57,183:INFO:               numba: 0.55.1
2023-08-16 01:57:57,183:INFO:            requests: 2.28.1
2023-08-16 01:57:57,183:INFO:          matplotlib: 3.5.2
2023-08-16 01:57:57,183:INFO:          scikitplot: 0.3.7
2023-08-16 01:57:57,183:INFO:         yellowbrick: 1.5
2023-08-16 01:57:57,183:INFO:              plotly: 5.9.0
2023-08-16 01:57:57,183:INFO:    plotly-resampler: Not installed
2023-08-16 01:57:57,183:INFO:             kaleido: 0.2.1
2023-08-16 01:57:57,183:INFO:           schemdraw: 0.15
2023-08-16 01:57:57,183:INFO:         statsmodels: 0.13.2
2023-08-16 01:57:57,183:INFO:              sktime: 0.21.0
2023-08-16 01:57:57,183:INFO:               tbats: 1.1.3
2023-08-16 01:57:57,183:INFO:            pmdarima: 2.0.3
2023-08-16 01:57:57,183:INFO:              psutil: 5.9.0
2023-08-16 01:57:57,183:INFO:          markupsafe: 2.0.1
2023-08-16 01:57:57,183:INFO:             pickle5: Not installed
2023-08-16 01:57:57,183:INFO:         cloudpickle: 2.0.0
2023-08-16 01:57:57,184:INFO:         deprecation: 2.1.0
2023-08-16 01:57:57,184:INFO:              xxhash: 3.3.0
2023-08-16 01:57:57,184:INFO:           wurlitzer: Not installed
2023-08-16 01:57:57,184:INFO:PyCaret optional dependencies:
2023-08-16 01:57:57,184:INFO:                shap: Not installed
2023-08-16 01:57:57,184:INFO:           interpret: Not installed
2023-08-16 01:57:57,184:INFO:                umap: Not installed
2023-08-16 01:57:57,184:INFO:    pandas_profiling: Not installed
2023-08-16 01:57:57,184:INFO:  explainerdashboard: Not installed
2023-08-16 01:57:57,184:INFO:             autoviz: Not installed
2023-08-16 01:57:57,184:INFO:           fairlearn: Not installed
2023-08-16 01:57:57,184:INFO:          deepchecks: Not installed
2023-08-16 01:57:57,184:INFO:             xgboost: Not installed
2023-08-16 01:57:57,185:INFO:            catboost: Not installed
2023-08-16 01:57:57,185:INFO:              kmodes: Not installed
2023-08-16 01:57:57,185:INFO:             mlxtend: Not installed
2023-08-16 01:57:57,185:INFO:       statsforecast: Not installed
2023-08-16 01:57:57,185:INFO:        tune_sklearn: Not installed
2023-08-16 01:57:57,185:INFO:                 ray: Not installed
2023-08-16 01:57:57,185:INFO:            hyperopt: Not installed
2023-08-16 01:57:57,185:INFO:              optuna: Not installed
2023-08-16 01:57:57,185:INFO:               skopt: Not installed
2023-08-16 01:57:57,185:INFO:              mlflow: Not installed
2023-08-16 01:57:57,185:INFO:              gradio: Not installed
2023-08-16 01:57:57,185:INFO:             fastapi: Not installed
2023-08-16 01:57:57,185:INFO:             uvicorn: Not installed
2023-08-16 01:57:57,185:INFO:              m2cgen: Not installed
2023-08-16 01:57:57,185:INFO:           evidently: Not installed
2023-08-16 01:57:57,186:INFO:               fugue: Not installed
2023-08-16 01:57:57,186:INFO:           streamlit: Not installed
2023-08-16 01:57:57,186:INFO:             prophet: Not installed
2023-08-16 01:57:57,186:INFO:None
2023-08-16 01:57:57,186:INFO:Set up data.
2023-08-16 01:57:57,195:INFO:Set up train/test split.
2023-08-16 01:57:57,203:INFO:Set up index.
2023-08-16 01:57:57,203:INFO:Set up folding strategy.
2023-08-16 01:57:57,203:INFO:Assigning column types.
2023-08-16 01:57:57,208:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-16 01:57:57,240:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-16 01:57:57,241:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:57:57,261:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:57:57,261:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:57:57,293:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-16 01:57:57,294:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:57:57,314:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:57:57,314:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:57:57,314:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-16 01:57:57,347:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:57:57,368:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:57:57,368:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:57:57,402:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:57:57,423:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:57:57,423:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:57:57,423:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-16 01:57:57,476:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:57:57,476:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:57:57,528:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:57:57,529:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:57:57,530:INFO:Preparing preprocessing pipeline...
2023-08-16 01:57:57,531:INFO:Set up simple imputation.
2023-08-16 01:57:57,548:INFO:Finished creating preprocessing pipeline.
2023-08-16 01:57:57,551:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\LMACCI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['CATAG3', 'HEALTH2', 'ANYHLTI2',
                                             'INCOME', 'POVERTY3', 'TOBFLAG',
                                             'MRJFLAG', 'PYUD5MRJ', 'MJYRTOT',
                                             'ALCFLAG', 'COCFLAG', 'CRKFLAG',
                                             'HERFLAG', 'LSDFLAG',
                                             'METHAMFLAG'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose=0))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose=0)))],
         verbose=False)
2023-08-16 01:57:57,551:INFO:Creating final display dataframe.
2023-08-16 01:57:57,604:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          ADSMMDEA
2                   Target type            Binary
3           Original data shape       (20523, 16)
4        Transformed data shape       (20523, 16)
5   Transformed train set shape       (14366, 16)
6    Transformed test set shape        (6157, 16)
7              Numeric features                15
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              53d3
2023-08-16 01:57:57,666:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:57:57,666:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:57:57,723:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:57:57,724:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:57:57,724:INFO:setup() successfully completed in 0.62s...............
2023-08-16 01:58:06,835:INFO:PyCaret ClassificationExperiment
2023-08-16 01:58:06,835:INFO:Logging name: clf-default-name
2023-08-16 01:58:06,836:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-16 01:58:06,836:INFO:version 3.0.4
2023-08-16 01:58:06,836:INFO:Initializing setup()
2023-08-16 01:58:06,836:INFO:self.USI: 8c9b
2023-08-16 01:58:06,836:INFO:self._variable_keys: {'pipeline', 'fold_groups_param', 'X_test', 'idx', '_available_plots', 'X_train', 'fix_imbalance', 'y_test', 'y', 'memory', 'gpu_n_jobs_param', 'n_jobs_param', 'logging_param', 'log_plots_param', 'USI', 'is_multiclass', 'fold_generator', 'target_param', 'exp_id', '_ml_usecase', 'fold_shuffle_param', 'data', 'gpu_param', 'y_train', 'html_param', 'exp_name_log', 'seed', 'X'}
2023-08-16 01:58:06,836:INFO:Checking environment
2023-08-16 01:58:06,836:INFO:python_version: 3.9.13
2023-08-16 01:58:06,836:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-08-16 01:58:06,836:INFO:machine: AMD64
2023-08-16 01:58:06,836:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-16 01:58:06,836:INFO:Memory: svmem(total=16905969664, available=2333421568, percent=86.2, used=14572548096, free=2333421568)
2023-08-16 01:58:06,836:INFO:Physical Core: 8
2023-08-16 01:58:06,836:INFO:Logical Core: 16
2023-08-16 01:58:06,836:INFO:Checking libraries
2023-08-16 01:58:06,837:INFO:System:
2023-08-16 01:58:06,837:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-08-16 01:58:06,837:INFO:executable: c:\Users\lmacciomaretto\anaconda3\python.exe
2023-08-16 01:58:06,837:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-16 01:58:06,837:INFO:PyCaret required dependencies:
2023-08-16 01:58:06,837:INFO:                 pip: 22.2.2
2023-08-16 01:58:06,837:INFO:          setuptools: 63.4.1
2023-08-16 01:58:06,837:INFO:             pycaret: 3.0.4
2023-08-16 01:58:06,837:INFO:             IPython: 7.31.1
2023-08-16 01:58:06,837:INFO:          ipywidgets: 7.6.5
2023-08-16 01:58:06,837:INFO:                tqdm: 4.64.1
2023-08-16 01:58:06,837:INFO:               numpy: 1.21.5
2023-08-16 01:58:06,837:INFO:              pandas: 1.4.4
2023-08-16 01:58:06,837:INFO:              jinja2: 2.11.3
2023-08-16 01:58:06,837:INFO:               scipy: 1.9.1
2023-08-16 01:58:06,837:INFO:              joblib: 1.3.2
2023-08-16 01:58:06,837:INFO:             sklearn: 1.0.2
2023-08-16 01:58:06,838:INFO:                pyod: 1.1.0
2023-08-16 01:58:06,838:INFO:            imblearn: 0.11.0
2023-08-16 01:58:06,838:INFO:   category_encoders: 2.6.2
2023-08-16 01:58:06,838:INFO:            lightgbm: 4.0.0
2023-08-16 01:58:06,838:INFO:               numba: 0.55.1
2023-08-16 01:58:06,838:INFO:            requests: 2.28.1
2023-08-16 01:58:06,838:INFO:          matplotlib: 3.5.2
2023-08-16 01:58:06,838:INFO:          scikitplot: 0.3.7
2023-08-16 01:58:06,838:INFO:         yellowbrick: 1.5
2023-08-16 01:58:06,838:INFO:              plotly: 5.9.0
2023-08-16 01:58:06,838:INFO:    plotly-resampler: Not installed
2023-08-16 01:58:06,839:INFO:             kaleido: 0.2.1
2023-08-16 01:58:06,839:INFO:           schemdraw: 0.15
2023-08-16 01:58:06,839:INFO:         statsmodels: 0.13.2
2023-08-16 01:58:06,839:INFO:              sktime: 0.21.0
2023-08-16 01:58:06,839:INFO:               tbats: 1.1.3
2023-08-16 01:58:06,839:INFO:            pmdarima: 2.0.3
2023-08-16 01:58:06,839:INFO:              psutil: 5.9.0
2023-08-16 01:58:06,839:INFO:          markupsafe: 2.0.1
2023-08-16 01:58:06,839:INFO:             pickle5: Not installed
2023-08-16 01:58:06,839:INFO:         cloudpickle: 2.0.0
2023-08-16 01:58:06,839:INFO:         deprecation: 2.1.0
2023-08-16 01:58:06,839:INFO:              xxhash: 3.3.0
2023-08-16 01:58:06,839:INFO:           wurlitzer: Not installed
2023-08-16 01:58:06,839:INFO:PyCaret optional dependencies:
2023-08-16 01:58:06,839:INFO:                shap: Not installed
2023-08-16 01:58:06,839:INFO:           interpret: Not installed
2023-08-16 01:58:06,839:INFO:                umap: Not installed
2023-08-16 01:58:06,839:INFO:    pandas_profiling: Not installed
2023-08-16 01:58:06,839:INFO:  explainerdashboard: Not installed
2023-08-16 01:58:06,839:INFO:             autoviz: Not installed
2023-08-16 01:58:06,839:INFO:           fairlearn: Not installed
2023-08-16 01:58:06,839:INFO:          deepchecks: Not installed
2023-08-16 01:58:06,839:INFO:             xgboost: Not installed
2023-08-16 01:58:06,839:INFO:            catboost: Not installed
2023-08-16 01:58:06,839:INFO:              kmodes: Not installed
2023-08-16 01:58:06,839:INFO:             mlxtend: Not installed
2023-08-16 01:58:06,839:INFO:       statsforecast: Not installed
2023-08-16 01:58:06,839:INFO:        tune_sklearn: Not installed
2023-08-16 01:58:06,839:INFO:                 ray: Not installed
2023-08-16 01:58:06,839:INFO:            hyperopt: Not installed
2023-08-16 01:58:06,840:INFO:              optuna: Not installed
2023-08-16 01:58:06,840:INFO:               skopt: Not installed
2023-08-16 01:58:06,840:INFO:              mlflow: Not installed
2023-08-16 01:58:06,840:INFO:              gradio: Not installed
2023-08-16 01:58:06,840:INFO:             fastapi: Not installed
2023-08-16 01:58:06,840:INFO:             uvicorn: Not installed
2023-08-16 01:58:06,840:INFO:              m2cgen: Not installed
2023-08-16 01:58:06,840:INFO:           evidently: Not installed
2023-08-16 01:58:06,840:INFO:               fugue: Not installed
2023-08-16 01:58:06,840:INFO:           streamlit: Not installed
2023-08-16 01:58:06,840:INFO:             prophet: Not installed
2023-08-16 01:58:06,840:INFO:None
2023-08-16 01:58:06,840:INFO:Set up data.
2023-08-16 01:58:06,848:INFO:Set up train/test split.
2023-08-16 01:58:06,856:INFO:Set up index.
2023-08-16 01:58:06,856:INFO:Set up folding strategy.
2023-08-16 01:58:06,856:INFO:Assigning column types.
2023-08-16 01:58:06,860:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-16 01:58:06,893:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-16 01:58:06,894:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:58:06,914:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:58:06,914:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:58:06,946:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-16 01:58:06,947:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:58:06,967:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:58:06,968:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:58:06,968:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-16 01:58:07,001:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:58:07,022:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:58:07,023:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:58:07,059:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-16 01:58:07,080:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:58:07,081:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:58:07,081:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-16 01:58:07,134:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:58:07,134:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:58:07,187:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:58:07,187:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:58:07,188:INFO:Preparing preprocessing pipeline...
2023-08-16 01:58:07,189:INFO:Set up simple imputation.
2023-08-16 01:58:07,207:INFO:Finished creating preprocessing pipeline.
2023-08-16 01:58:07,210:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\LMACCI~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['CATAG3', 'HEALTH2', 'ANYHLTI2',
                                             'INCOME', 'POVERTY3', 'TOBFLAG',
                                             'MRJFLAG', 'PYUD5MRJ', 'MJYRTOT',
                                             'ALCFLAG', 'COCFLAG', 'CRKFLAG',
                                             'HERFLAG', 'LSDFLAG',
                                             'METHAMFLAG'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose=0))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose=0)))],
         verbose=False)
2023-08-16 01:58:07,210:INFO:Creating final display dataframe.
2023-08-16 01:58:07,262:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          ADSMMDEA
2                   Target type            Binary
3           Original data shape       (20523, 16)
4        Transformed data shape       (20523, 16)
5   Transformed train set shape       (14366, 16)
6    Transformed test set shape        (6157, 16)
7              Numeric features                15
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              8c9b
2023-08-16 01:58:07,326:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:58:07,326:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:58:07,384:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:58:07,384:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-16 01:58:07,384:INFO:setup() successfully completed in 0.63s...............
2023-08-16 01:58:11,548:INFO:Initializing compare_models()
2023-08-16 01:58:11,548:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C0EC77C0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000214C0EC77C0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-16 01:58:11,548:INFO:Checking exceptions
2023-08-16 01:58:11,554:INFO:Preparing display monitor
2023-08-16 01:58:11,582:INFO:Initializing Logistic Regression
2023-08-16 01:58:11,582:INFO:Total runtime is 0.0 minutes
2023-08-16 01:58:11,585:INFO:SubProcess create_model() called ==================================
2023-08-16 01:58:11,585:INFO:Initializing create_model()
2023-08-16 01:58:11,585:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C0EC77C0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C12072B0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:58:11,585:INFO:Checking exceptions
2023-08-16 01:58:11,585:INFO:Importing libraries
2023-08-16 01:58:11,585:INFO:Copying training dataset
2023-08-16 01:58:11,591:INFO:Defining folds
2023-08-16 01:58:11,592:INFO:Declaring metric variables
2023-08-16 01:58:11,594:INFO:Importing untrained model
2023-08-16 01:58:11,596:INFO:Logistic Regression Imported successfully
2023-08-16 01:58:11,603:INFO:Starting cross validation
2023-08-16 01:58:11,605:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:58:12,947:INFO:Calculating mean and std
2023-08-16 01:58:12,948:INFO:Creating metrics dataframe
2023-08-16 01:58:13,068:INFO:Uploading results into container
2023-08-16 01:58:13,069:INFO:Uploading model into container now
2023-08-16 01:58:13,069:INFO:_master_model_container: 1
2023-08-16 01:58:13,069:INFO:_display_container: 2
2023-08-16 01:58:13,069:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-16 01:58:13,069:INFO:create_model() successfully completed......................................
2023-08-16 01:58:13,134:INFO:SubProcess create_model() end ==================================
2023-08-16 01:58:13,135:INFO:Creating metrics dataframe
2023-08-16 01:58:13,141:INFO:Initializing K Neighbors Classifier
2023-08-16 01:58:13,141:INFO:Total runtime is 0.025982991854349772 minutes
2023-08-16 01:58:13,144:INFO:SubProcess create_model() called ==================================
2023-08-16 01:58:13,144:INFO:Initializing create_model()
2023-08-16 01:58:13,144:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C0EC77C0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C12072B0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:58:13,145:INFO:Checking exceptions
2023-08-16 01:58:13,145:INFO:Importing libraries
2023-08-16 01:58:13,145:INFO:Copying training dataset
2023-08-16 01:58:13,151:INFO:Defining folds
2023-08-16 01:58:13,151:INFO:Declaring metric variables
2023-08-16 01:58:13,154:INFO:Importing untrained model
2023-08-16 01:58:13,156:INFO:K Neighbors Classifier Imported successfully
2023-08-16 01:58:13,161:INFO:Starting cross validation
2023-08-16 01:58:13,162:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:58:13,347:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:58:13,358:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:58:13,365:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:58:13,365:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:58:13,366:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:58:13,366:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:58:13,397:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:58:13,409:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:58:13,415:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:58:13,432:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:58:14,453:INFO:Calculating mean and std
2023-08-16 01:58:14,454:INFO:Creating metrics dataframe
2023-08-16 01:58:14,573:INFO:Uploading results into container
2023-08-16 01:58:14,574:INFO:Uploading model into container now
2023-08-16 01:58:14,574:INFO:_master_model_container: 2
2023-08-16 01:58:14,574:INFO:_display_container: 2
2023-08-16 01:58:14,575:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-16 01:58:14,575:INFO:create_model() successfully completed......................................
2023-08-16 01:58:14,639:INFO:SubProcess create_model() end ==================================
2023-08-16 01:58:14,639:INFO:Creating metrics dataframe
2023-08-16 01:58:14,647:INFO:Initializing Naive Bayes
2023-08-16 01:58:14,647:INFO:Total runtime is 0.05108557939529419 minutes
2023-08-16 01:58:14,649:INFO:SubProcess create_model() called ==================================
2023-08-16 01:58:14,649:INFO:Initializing create_model()
2023-08-16 01:58:14,650:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C0EC77C0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C12072B0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:58:14,650:INFO:Checking exceptions
2023-08-16 01:58:14,650:INFO:Importing libraries
2023-08-16 01:58:14,650:INFO:Copying training dataset
2023-08-16 01:58:14,655:INFO:Defining folds
2023-08-16 01:58:14,655:INFO:Declaring metric variables
2023-08-16 01:58:14,657:INFO:Importing untrained model
2023-08-16 01:58:14,660:INFO:Naive Bayes Imported successfully
2023-08-16 01:58:14,665:INFO:Starting cross validation
2023-08-16 01:58:14,666:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:58:15,705:INFO:Calculating mean and std
2023-08-16 01:58:15,706:INFO:Creating metrics dataframe
2023-08-16 01:58:15,824:INFO:Uploading results into container
2023-08-16 01:58:15,824:INFO:Uploading model into container now
2023-08-16 01:58:15,825:INFO:_master_model_container: 3
2023-08-16 01:58:15,825:INFO:_display_container: 2
2023-08-16 01:58:15,825:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-16 01:58:15,825:INFO:create_model() successfully completed......................................
2023-08-16 01:58:15,893:INFO:SubProcess create_model() end ==================================
2023-08-16 01:58:15,893:INFO:Creating metrics dataframe
2023-08-16 01:58:15,903:INFO:Initializing Decision Tree Classifier
2023-08-16 01:58:15,903:INFO:Total runtime is 0.07201294898986817 minutes
2023-08-16 01:58:15,905:INFO:SubProcess create_model() called ==================================
2023-08-16 01:58:15,905:INFO:Initializing create_model()
2023-08-16 01:58:15,906:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C0EC77C0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C12072B0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:58:15,906:INFO:Checking exceptions
2023-08-16 01:58:15,906:INFO:Importing libraries
2023-08-16 01:58:15,906:INFO:Copying training dataset
2023-08-16 01:58:15,913:INFO:Defining folds
2023-08-16 01:58:15,913:INFO:Declaring metric variables
2023-08-16 01:58:15,916:INFO:Importing untrained model
2023-08-16 01:58:15,918:INFO:Decision Tree Classifier Imported successfully
2023-08-16 01:58:15,922:INFO:Starting cross validation
2023-08-16 01:58:15,923:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:58:16,973:INFO:Calculating mean and std
2023-08-16 01:58:16,974:INFO:Creating metrics dataframe
2023-08-16 01:58:17,106:INFO:Uploading results into container
2023-08-16 01:58:17,107:INFO:Uploading model into container now
2023-08-16 01:58:17,107:INFO:_master_model_container: 4
2023-08-16 01:58:17,108:INFO:_display_container: 2
2023-08-16 01:58:17,108:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-08-16 01:58:17,108:INFO:create_model() successfully completed......................................
2023-08-16 01:58:17,178:INFO:SubProcess create_model() end ==================================
2023-08-16 01:58:17,178:INFO:Creating metrics dataframe
2023-08-16 01:58:17,184:INFO:Initializing SVM - Linear Kernel
2023-08-16 01:58:17,185:INFO:Total runtime is 0.09338043133417766 minutes
2023-08-16 01:58:17,187:INFO:SubProcess create_model() called ==================================
2023-08-16 01:58:17,187:INFO:Initializing create_model()
2023-08-16 01:58:17,187:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C0EC77C0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C12072B0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:58:17,187:INFO:Checking exceptions
2023-08-16 01:58:17,187:INFO:Importing libraries
2023-08-16 01:58:17,187:INFO:Copying training dataset
2023-08-16 01:58:17,194:INFO:Defining folds
2023-08-16 01:58:17,195:INFO:Declaring metric variables
2023-08-16 01:58:17,197:INFO:Importing untrained model
2023-08-16 01:58:17,199:INFO:SVM - Linear Kernel Imported successfully
2023-08-16 01:58:17,203:INFO:Starting cross validation
2023-08-16 01:58:17,204:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:58:17,322:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:58:17,340:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:58:17,351:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:58:17,354:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:58:17,356:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:58:17,367:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:58:17,367:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:58:17,374:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:58:17,404:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:58:17,408:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:58:17,410:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:58:18,289:INFO:Calculating mean and std
2023-08-16 01:58:18,290:INFO:Creating metrics dataframe
2023-08-16 01:58:18,416:INFO:Uploading results into container
2023-08-16 01:58:18,417:INFO:Uploading model into container now
2023-08-16 01:58:18,417:INFO:_master_model_container: 5
2023-08-16 01:58:18,417:INFO:_display_container: 2
2023-08-16 01:58:18,417:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-16 01:58:18,417:INFO:create_model() successfully completed......................................
2023-08-16 01:58:18,491:INFO:SubProcess create_model() end ==================================
2023-08-16 01:58:18,491:INFO:Creating metrics dataframe
2023-08-16 01:58:18,498:INFO:Initializing Ridge Classifier
2023-08-16 01:58:18,498:INFO:Total runtime is 0.11527440150578817 minutes
2023-08-16 01:58:18,501:INFO:SubProcess create_model() called ==================================
2023-08-16 01:58:18,501:INFO:Initializing create_model()
2023-08-16 01:58:18,501:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C0EC77C0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C12072B0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:58:18,501:INFO:Checking exceptions
2023-08-16 01:58:18,501:INFO:Importing libraries
2023-08-16 01:58:18,501:INFO:Copying training dataset
2023-08-16 01:58:18,508:INFO:Defining folds
2023-08-16 01:58:18,508:INFO:Declaring metric variables
2023-08-16 01:58:18,511:INFO:Importing untrained model
2023-08-16 01:58:18,513:INFO:Ridge Classifier Imported successfully
2023-08-16 01:58:18,518:INFO:Starting cross validation
2023-08-16 01:58:18,518:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:58:18,578:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:58:18,583:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:58:18,595:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:58:18,597:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:58:18,609:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:58:18,610:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:58:18,613:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:58:18,624:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:58:18,626:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:58:18,636:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:58:19,540:INFO:Calculating mean and std
2023-08-16 01:58:19,541:INFO:Creating metrics dataframe
2023-08-16 01:58:19,674:INFO:Uploading results into container
2023-08-16 01:58:19,675:INFO:Uploading model into container now
2023-08-16 01:58:19,675:INFO:_master_model_container: 6
2023-08-16 01:58:19,675:INFO:_display_container: 2
2023-08-16 01:58:19,675:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=123, solver='auto', tol=0.001)
2023-08-16 01:58:19,676:INFO:create_model() successfully completed......................................
2023-08-16 01:58:19,744:INFO:SubProcess create_model() end ==================================
2023-08-16 01:58:19,744:INFO:Creating metrics dataframe
2023-08-16 01:58:19,751:INFO:Initializing Random Forest Classifier
2023-08-16 01:58:19,751:INFO:Total runtime is 0.1361599604288737 minutes
2023-08-16 01:58:19,753:INFO:SubProcess create_model() called ==================================
2023-08-16 01:58:19,754:INFO:Initializing create_model()
2023-08-16 01:58:19,754:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C0EC77C0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C12072B0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:58:19,754:INFO:Checking exceptions
2023-08-16 01:58:19,754:INFO:Importing libraries
2023-08-16 01:58:19,754:INFO:Copying training dataset
2023-08-16 01:58:19,760:INFO:Defining folds
2023-08-16 01:58:19,760:INFO:Declaring metric variables
2023-08-16 01:58:19,762:INFO:Importing untrained model
2023-08-16 01:58:19,764:INFO:Random Forest Classifier Imported successfully
2023-08-16 01:58:19,769:INFO:Starting cross validation
2023-08-16 01:58:19,770:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:58:21,743:INFO:Calculating mean and std
2023-08-16 01:58:21,745:INFO:Creating metrics dataframe
2023-08-16 01:58:21,872:INFO:Uploading results into container
2023-08-16 01:58:21,872:INFO:Uploading model into container now
2023-08-16 01:58:21,873:INFO:_master_model_container: 7
2023-08-16 01:58:21,873:INFO:_display_container: 2
2023-08-16 01:58:21,873:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-08-16 01:58:21,873:INFO:create_model() successfully completed......................................
2023-08-16 01:58:21,948:INFO:SubProcess create_model() end ==================================
2023-08-16 01:58:21,948:INFO:Creating metrics dataframe
2023-08-16 01:58:21,955:INFO:Initializing Quadratic Discriminant Analysis
2023-08-16 01:58:21,955:INFO:Total runtime is 0.17289274533589682 minutes
2023-08-16 01:58:21,958:INFO:SubProcess create_model() called ==================================
2023-08-16 01:58:21,958:INFO:Initializing create_model()
2023-08-16 01:58:21,958:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C0EC77C0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C12072B0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:58:21,958:INFO:Checking exceptions
2023-08-16 01:58:21,958:INFO:Importing libraries
2023-08-16 01:58:21,958:INFO:Copying training dataset
2023-08-16 01:58:21,965:INFO:Defining folds
2023-08-16 01:58:21,965:INFO:Declaring metric variables
2023-08-16 01:58:21,968:INFO:Importing untrained model
2023-08-16 01:58:21,970:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-16 01:58:21,975:INFO:Starting cross validation
2023-08-16 01:58:21,975:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:58:23,081:INFO:Calculating mean and std
2023-08-16 01:58:23,082:INFO:Creating metrics dataframe
2023-08-16 01:58:23,213:INFO:Uploading results into container
2023-08-16 01:58:23,214:INFO:Uploading model into container now
2023-08-16 01:58:23,214:INFO:_master_model_container: 8
2023-08-16 01:58:23,214:INFO:_display_container: 2
2023-08-16 01:58:23,214:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-16 01:58:23,214:INFO:create_model() successfully completed......................................
2023-08-16 01:58:23,304:INFO:SubProcess create_model() end ==================================
2023-08-16 01:58:23,304:INFO:Creating metrics dataframe
2023-08-16 01:58:23,314:INFO:Initializing Ada Boost Classifier
2023-08-16 01:58:23,314:INFO:Total runtime is 0.19553493658701582 minutes
2023-08-16 01:58:23,317:INFO:SubProcess create_model() called ==================================
2023-08-16 01:58:23,317:INFO:Initializing create_model()
2023-08-16 01:58:23,317:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C0EC77C0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C12072B0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:58:23,317:INFO:Checking exceptions
2023-08-16 01:58:23,317:INFO:Importing libraries
2023-08-16 01:58:23,317:INFO:Copying training dataset
2023-08-16 01:58:23,325:INFO:Defining folds
2023-08-16 01:58:23,325:INFO:Declaring metric variables
2023-08-16 01:58:23,329:INFO:Importing untrained model
2023-08-16 01:58:23,332:INFO:Ada Boost Classifier Imported successfully
2023-08-16 01:58:23,336:INFO:Starting cross validation
2023-08-16 01:58:23,337:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:58:24,986:INFO:Calculating mean and std
2023-08-16 01:58:24,988:INFO:Creating metrics dataframe
2023-08-16 01:58:25,124:INFO:Uploading results into container
2023-08-16 01:58:25,125:INFO:Uploading model into container now
2023-08-16 01:58:25,125:INFO:_master_model_container: 9
2023-08-16 01:58:25,126:INFO:_display_container: 2
2023-08-16 01:58:25,126:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2023-08-16 01:58:25,126:INFO:create_model() successfully completed......................................
2023-08-16 01:58:25,199:INFO:SubProcess create_model() end ==================================
2023-08-16 01:58:25,199:INFO:Creating metrics dataframe
2023-08-16 01:58:25,206:INFO:Initializing Gradient Boosting Classifier
2023-08-16 01:58:25,206:INFO:Total runtime is 0.22707670529683432 minutes
2023-08-16 01:58:25,208:INFO:SubProcess create_model() called ==================================
2023-08-16 01:58:25,209:INFO:Initializing create_model()
2023-08-16 01:58:25,209:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C0EC77C0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C12072B0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:58:25,209:INFO:Checking exceptions
2023-08-16 01:58:25,209:INFO:Importing libraries
2023-08-16 01:58:25,209:INFO:Copying training dataset
2023-08-16 01:58:25,215:INFO:Defining folds
2023-08-16 01:58:25,215:INFO:Declaring metric variables
2023-08-16 01:58:25,217:INFO:Importing untrained model
2023-08-16 01:58:25,219:INFO:Gradient Boosting Classifier Imported successfully
2023-08-16 01:58:25,223:INFO:Starting cross validation
2023-08-16 01:58:25,224:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:58:27,094:INFO:Calculating mean and std
2023-08-16 01:58:27,095:INFO:Creating metrics dataframe
2023-08-16 01:58:27,227:INFO:Uploading results into container
2023-08-16 01:58:27,228:INFO:Uploading model into container now
2023-08-16 01:58:27,228:INFO:_master_model_container: 10
2023-08-16 01:58:27,228:INFO:_display_container: 2
2023-08-16 01:58:27,228:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-16 01:58:27,228:INFO:create_model() successfully completed......................................
2023-08-16 01:58:27,294:INFO:SubProcess create_model() end ==================================
2023-08-16 01:58:27,294:INFO:Creating metrics dataframe
2023-08-16 01:58:27,302:INFO:Initializing Linear Discriminant Analysis
2023-08-16 01:58:27,302:INFO:Total runtime is 0.2620074033737183 minutes
2023-08-16 01:58:27,305:INFO:SubProcess create_model() called ==================================
2023-08-16 01:58:27,305:INFO:Initializing create_model()
2023-08-16 01:58:27,305:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C0EC77C0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C12072B0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:58:27,305:INFO:Checking exceptions
2023-08-16 01:58:27,305:INFO:Importing libraries
2023-08-16 01:58:27,305:INFO:Copying training dataset
2023-08-16 01:58:27,311:INFO:Defining folds
2023-08-16 01:58:27,311:INFO:Declaring metric variables
2023-08-16 01:58:27,313:INFO:Importing untrained model
2023-08-16 01:58:27,315:INFO:Linear Discriminant Analysis Imported successfully
2023-08-16 01:58:27,320:INFO:Starting cross validation
2023-08-16 01:58:27,321:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:58:28,472:INFO:Calculating mean and std
2023-08-16 01:58:28,473:INFO:Creating metrics dataframe
2023-08-16 01:58:28,601:INFO:Uploading results into container
2023-08-16 01:58:28,602:INFO:Uploading model into container now
2023-08-16 01:58:28,602:INFO:_master_model_container: 11
2023-08-16 01:58:28,602:INFO:_display_container: 2
2023-08-16 01:58:28,603:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-16 01:58:28,603:INFO:create_model() successfully completed......................................
2023-08-16 01:58:28,671:INFO:SubProcess create_model() end ==================================
2023-08-16 01:58:28,671:INFO:Creating metrics dataframe
2023-08-16 01:58:28,679:INFO:Initializing Extra Trees Classifier
2023-08-16 01:58:28,679:INFO:Total runtime is 0.2849573373794556 minutes
2023-08-16 01:58:28,681:INFO:SubProcess create_model() called ==================================
2023-08-16 01:58:28,682:INFO:Initializing create_model()
2023-08-16 01:58:28,682:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C0EC77C0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C12072B0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:58:28,682:INFO:Checking exceptions
2023-08-16 01:58:28,682:INFO:Importing libraries
2023-08-16 01:58:28,682:INFO:Copying training dataset
2023-08-16 01:58:28,688:INFO:Defining folds
2023-08-16 01:58:28,688:INFO:Declaring metric variables
2023-08-16 01:58:28,690:INFO:Importing untrained model
2023-08-16 01:58:28,692:INFO:Extra Trees Classifier Imported successfully
2023-08-16 01:58:28,697:INFO:Starting cross validation
2023-08-16 01:58:28,698:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:58:30,868:INFO:Calculating mean and std
2023-08-16 01:58:30,869:INFO:Creating metrics dataframe
2023-08-16 01:58:30,998:INFO:Uploading results into container
2023-08-16 01:58:30,998:INFO:Uploading model into container now
2023-08-16 01:58:30,999:INFO:_master_model_container: 12
2023-08-16 01:58:30,999:INFO:_display_container: 2
2023-08-16 01:58:30,999:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-08-16 01:58:30,999:INFO:create_model() successfully completed......................................
2023-08-16 01:58:31,066:INFO:SubProcess create_model() end ==================================
2023-08-16 01:58:31,066:INFO:Creating metrics dataframe
2023-08-16 01:58:31,074:INFO:Initializing Light Gradient Boosting Machine
2023-08-16 01:58:31,074:INFO:Total runtime is 0.3248774647712708 minutes
2023-08-16 01:58:31,077:INFO:SubProcess create_model() called ==================================
2023-08-16 01:58:31,078:INFO:Initializing create_model()
2023-08-16 01:58:31,078:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C0EC77C0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C12072B0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:58:31,078:INFO:Checking exceptions
2023-08-16 01:58:31,078:INFO:Importing libraries
2023-08-16 01:58:31,078:INFO:Copying training dataset
2023-08-16 01:58:31,084:INFO:Defining folds
2023-08-16 01:58:31,084:INFO:Declaring metric variables
2023-08-16 01:58:31,087:INFO:Importing untrained model
2023-08-16 01:58:31,090:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-16 01:58:31,096:INFO:Starting cross validation
2023-08-16 01:58:31,097:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:58:33,315:INFO:Calculating mean and std
2023-08-16 01:58:33,317:INFO:Creating metrics dataframe
2023-08-16 01:58:33,455:INFO:Uploading results into container
2023-08-16 01:58:33,456:INFO:Uploading model into container now
2023-08-16 01:58:33,456:INFO:_master_model_container: 13
2023-08-16 01:58:33,456:INFO:_display_container: 2
2023-08-16 01:58:33,457:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-16 01:58:33,457:INFO:create_model() successfully completed......................................
2023-08-16 01:58:33,521:INFO:SubProcess create_model() end ==================================
2023-08-16 01:58:33,521:INFO:Creating metrics dataframe
2023-08-16 01:58:33,529:INFO:Initializing Dummy Classifier
2023-08-16 01:58:33,529:INFO:Total runtime is 0.3657835483551026 minutes
2023-08-16 01:58:33,531:INFO:SubProcess create_model() called ==================================
2023-08-16 01:58:33,531:INFO:Initializing create_model()
2023-08-16 01:58:33,531:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C0EC77C0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C12072B0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:58:33,531:INFO:Checking exceptions
2023-08-16 01:58:33,531:INFO:Importing libraries
2023-08-16 01:58:33,531:INFO:Copying training dataset
2023-08-16 01:58:33,537:INFO:Defining folds
2023-08-16 01:58:33,538:INFO:Declaring metric variables
2023-08-16 01:58:33,540:INFO:Importing untrained model
2023-08-16 01:58:33,543:INFO:Dummy Classifier Imported successfully
2023-08-16 01:58:33,547:INFO:Starting cross validation
2023-08-16 01:58:33,548:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:58:33,610:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:58:33,619:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:58:33,620:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:58:33,622:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:58:33,631:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:58:33,639:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:58:33,653:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:58:33,653:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:58:33,657:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:58:33,657:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:58:34,711:INFO:Calculating mean and std
2023-08-16 01:58:34,712:INFO:Creating metrics dataframe
2023-08-16 01:58:34,850:INFO:Uploading results into container
2023-08-16 01:58:34,850:INFO:Uploading model into container now
2023-08-16 01:58:34,850:INFO:_master_model_container: 14
2023-08-16 01:58:34,850:INFO:_display_container: 2
2023-08-16 01:58:34,851:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-08-16 01:58:34,851:INFO:create_model() successfully completed......................................
2023-08-16 01:58:34,916:INFO:SubProcess create_model() end ==================================
2023-08-16 01:58:34,916:INFO:Creating metrics dataframe
2023-08-16 01:58:34,932:INFO:Initializing create_model()
2023-08-16 01:58:34,932:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C0EC77C0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=123, solver='auto', tol=0.001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:58:34,932:INFO:Checking exceptions
2023-08-16 01:58:34,933:INFO:Importing libraries
2023-08-16 01:58:34,934:INFO:Copying training dataset
2023-08-16 01:58:34,939:INFO:Defining folds
2023-08-16 01:58:34,939:INFO:Declaring metric variables
2023-08-16 01:58:34,940:INFO:Importing untrained model
2023-08-16 01:58:34,940:INFO:Declaring custom model
2023-08-16 01:58:34,940:INFO:Ridge Classifier Imported successfully
2023-08-16 01:58:34,940:INFO:Cross validation set to False
2023-08-16 01:58:34,940:INFO:Fitting Model
2023-08-16 01:58:35,059:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=123, solver='auto', tol=0.001)
2023-08-16 01:58:35,059:INFO:create_model() successfully completed......................................
2023-08-16 01:58:35,151:INFO:_master_model_container: 14
2023-08-16 01:58:35,151:INFO:_display_container: 2
2023-08-16 01:58:35,151:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=123, solver='auto', tol=0.001)
2023-08-16 01:58:35,151:INFO:compare_models() successfully completed......................................
2023-08-16 01:58:50,940:INFO:Initializing compare_models()
2023-08-16 01:58:50,940:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C0EC77C0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000214C0EC77C0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-16 01:58:50,940:INFO:Checking exceptions
2023-08-16 01:58:50,944:INFO:Preparing display monitor
2023-08-16 01:58:50,971:INFO:Initializing Logistic Regression
2023-08-16 01:58:50,972:INFO:Total runtime is 0.0 minutes
2023-08-16 01:58:50,974:INFO:SubProcess create_model() called ==================================
2023-08-16 01:58:50,975:INFO:Initializing create_model()
2023-08-16 01:58:50,975:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C0EC77C0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C0B82EE0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:58:50,975:INFO:Checking exceptions
2023-08-16 01:58:50,975:INFO:Importing libraries
2023-08-16 01:58:50,975:INFO:Copying training dataset
2023-08-16 01:58:50,982:INFO:Defining folds
2023-08-16 01:58:50,982:INFO:Declaring metric variables
2023-08-16 01:58:50,984:INFO:Importing untrained model
2023-08-16 01:58:50,987:INFO:Logistic Regression Imported successfully
2023-08-16 01:58:50,991:INFO:Starting cross validation
2023-08-16 01:58:50,992:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:58:52,196:INFO:Calculating mean and std
2023-08-16 01:58:52,197:INFO:Creating metrics dataframe
2023-08-16 01:58:52,335:INFO:Uploading results into container
2023-08-16 01:58:52,335:INFO:Uploading model into container now
2023-08-16 01:58:52,336:INFO:_master_model_container: 15
2023-08-16 01:58:52,336:INFO:_display_container: 3
2023-08-16 01:58:52,336:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-16 01:58:52,336:INFO:create_model() successfully completed......................................
2023-08-16 01:58:52,404:INFO:SubProcess create_model() end ==================================
2023-08-16 01:58:52,404:INFO:Creating metrics dataframe
2023-08-16 01:58:52,410:INFO:Initializing K Neighbors Classifier
2023-08-16 01:58:52,410:INFO:Total runtime is 0.023973902066548664 minutes
2023-08-16 01:58:52,413:INFO:SubProcess create_model() called ==================================
2023-08-16 01:58:52,413:INFO:Initializing create_model()
2023-08-16 01:58:52,414:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C0EC77C0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C0B82EE0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:58:52,414:INFO:Checking exceptions
2023-08-16 01:58:52,414:INFO:Importing libraries
2023-08-16 01:58:52,414:INFO:Copying training dataset
2023-08-16 01:58:52,420:INFO:Defining folds
2023-08-16 01:58:52,420:INFO:Declaring metric variables
2023-08-16 01:58:52,422:INFO:Importing untrained model
2023-08-16 01:58:52,424:INFO:K Neighbors Classifier Imported successfully
2023-08-16 01:58:52,429:INFO:Starting cross validation
2023-08-16 01:58:52,430:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:58:52,572:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:58:52,617:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:58:52,657:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:58:52,672:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:58:52,678:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:58:52,691:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:58:52,693:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:58:52,719:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:58:52,749:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:58:52,772:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\neighbors\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)

2023-08-16 01:58:53,954:INFO:Calculating mean and std
2023-08-16 01:58:53,955:INFO:Creating metrics dataframe
2023-08-16 01:58:54,093:INFO:Uploading results into container
2023-08-16 01:58:54,093:INFO:Uploading model into container now
2023-08-16 01:58:54,094:INFO:_master_model_container: 16
2023-08-16 01:58:54,094:INFO:_display_container: 3
2023-08-16 01:58:54,094:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-16 01:58:54,094:INFO:create_model() successfully completed......................................
2023-08-16 01:58:54,163:INFO:SubProcess create_model() end ==================================
2023-08-16 01:58:54,165:INFO:Creating metrics dataframe
2023-08-16 01:58:54,171:INFO:Initializing Naive Bayes
2023-08-16 01:58:54,171:INFO:Total runtime is 0.05332634846369425 minutes
2023-08-16 01:58:54,174:INFO:SubProcess create_model() called ==================================
2023-08-16 01:58:54,174:INFO:Initializing create_model()
2023-08-16 01:58:54,174:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C0EC77C0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C0B82EE0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:58:54,174:INFO:Checking exceptions
2023-08-16 01:58:54,174:INFO:Importing libraries
2023-08-16 01:58:54,174:INFO:Copying training dataset
2023-08-16 01:58:54,181:INFO:Defining folds
2023-08-16 01:58:54,181:INFO:Declaring metric variables
2023-08-16 01:58:54,183:INFO:Importing untrained model
2023-08-16 01:58:54,185:INFO:Naive Bayes Imported successfully
2023-08-16 01:58:54,190:INFO:Starting cross validation
2023-08-16 01:58:54,191:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:58:55,409:INFO:Calculating mean and std
2023-08-16 01:58:55,410:INFO:Creating metrics dataframe
2023-08-16 01:58:55,555:INFO:Uploading results into container
2023-08-16 01:58:55,555:INFO:Uploading model into container now
2023-08-16 01:58:55,556:INFO:_master_model_container: 17
2023-08-16 01:58:55,556:INFO:_display_container: 3
2023-08-16 01:58:55,556:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-16 01:58:55,556:INFO:create_model() successfully completed......................................
2023-08-16 01:58:55,626:INFO:SubProcess create_model() end ==================================
2023-08-16 01:58:55,626:INFO:Creating metrics dataframe
2023-08-16 01:58:55,633:INFO:Initializing Decision Tree Classifier
2023-08-16 01:58:55,633:INFO:Total runtime is 0.07769615252812703 minutes
2023-08-16 01:58:55,636:INFO:SubProcess create_model() called ==================================
2023-08-16 01:58:55,636:INFO:Initializing create_model()
2023-08-16 01:58:55,636:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C0EC77C0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C0B82EE0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:58:55,636:INFO:Checking exceptions
2023-08-16 01:58:55,636:INFO:Importing libraries
2023-08-16 01:58:55,636:INFO:Copying training dataset
2023-08-16 01:58:55,642:INFO:Defining folds
2023-08-16 01:58:55,642:INFO:Declaring metric variables
2023-08-16 01:58:55,644:INFO:Importing untrained model
2023-08-16 01:58:55,646:INFO:Decision Tree Classifier Imported successfully
2023-08-16 01:58:55,650:INFO:Starting cross validation
2023-08-16 01:58:55,651:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:58:56,864:INFO:Calculating mean and std
2023-08-16 01:58:56,865:INFO:Creating metrics dataframe
2023-08-16 01:58:57,004:INFO:Uploading results into container
2023-08-16 01:58:57,005:INFO:Uploading model into container now
2023-08-16 01:58:57,005:INFO:_master_model_container: 18
2023-08-16 01:58:57,005:INFO:_display_container: 3
2023-08-16 01:58:57,006:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-08-16 01:58:57,006:INFO:create_model() successfully completed......................................
2023-08-16 01:58:57,077:INFO:SubProcess create_model() end ==================================
2023-08-16 01:58:57,077:INFO:Creating metrics dataframe
2023-08-16 01:58:57,084:INFO:Initializing SVM - Linear Kernel
2023-08-16 01:58:57,084:INFO:Total runtime is 0.10187312364578247 minutes
2023-08-16 01:58:57,087:INFO:SubProcess create_model() called ==================================
2023-08-16 01:58:57,087:INFO:Initializing create_model()
2023-08-16 01:58:57,087:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C0EC77C0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C0B82EE0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:58:57,087:INFO:Checking exceptions
2023-08-16 01:58:57,087:INFO:Importing libraries
2023-08-16 01:58:57,087:INFO:Copying training dataset
2023-08-16 01:58:57,093:INFO:Defining folds
2023-08-16 01:58:57,093:INFO:Declaring metric variables
2023-08-16 01:58:57,095:INFO:Importing untrained model
2023-08-16 01:58:57,097:INFO:SVM - Linear Kernel Imported successfully
2023-08-16 01:58:57,102:INFO:Starting cross validation
2023-08-16 01:58:57,102:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:58:57,178:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:58:57,181:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:58:57,186:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:58:57,258:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:58:57,260:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:58:57,267:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:58:57,275:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:58:57,286:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:58:57,287:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:58:57,295:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:58:57,333:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\utils\metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-16 01:58:58,296:INFO:Calculating mean and std
2023-08-16 01:58:58,297:INFO:Creating metrics dataframe
2023-08-16 01:58:58,450:INFO:Uploading results into container
2023-08-16 01:58:58,450:INFO:Uploading model into container now
2023-08-16 01:58:58,450:INFO:_master_model_container: 19
2023-08-16 01:58:58,451:INFO:_display_container: 3
2023-08-16 01:58:58,451:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-16 01:58:58,451:INFO:create_model() successfully completed......................................
2023-08-16 01:58:58,523:INFO:SubProcess create_model() end ==================================
2023-08-16 01:58:58,523:INFO:Creating metrics dataframe
2023-08-16 01:58:58,531:INFO:Initializing Ridge Classifier
2023-08-16 01:58:58,531:INFO:Total runtime is 0.12599631150563556 minutes
2023-08-16 01:58:58,533:INFO:SubProcess create_model() called ==================================
2023-08-16 01:58:58,534:INFO:Initializing create_model()
2023-08-16 01:58:58,534:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C0EC77C0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C0B82EE0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:58:58,534:INFO:Checking exceptions
2023-08-16 01:58:58,534:INFO:Importing libraries
2023-08-16 01:58:58,534:INFO:Copying training dataset
2023-08-16 01:58:58,540:INFO:Defining folds
2023-08-16 01:58:58,540:INFO:Declaring metric variables
2023-08-16 01:58:58,542:INFO:Importing untrained model
2023-08-16 01:58:58,544:INFO:Ridge Classifier Imported successfully
2023-08-16 01:58:58,550:INFO:Starting cross validation
2023-08-16 01:58:58,551:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:58:58,625:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:58:58,628:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:58:58,642:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:58:58,643:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:58:58,647:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:58:58,653:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:58:58,657:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:58:58,662:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:58:58,670:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:58:58,671:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\lmacciomaretto\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-16 01:58:59,788:INFO:Calculating mean and std
2023-08-16 01:58:59,789:INFO:Creating metrics dataframe
2023-08-16 01:58:59,925:INFO:Uploading results into container
2023-08-16 01:58:59,926:INFO:Uploading model into container now
2023-08-16 01:58:59,926:INFO:_master_model_container: 20
2023-08-16 01:58:59,926:INFO:_display_container: 3
2023-08-16 01:58:59,926:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=123, solver='auto', tol=0.001)
2023-08-16 01:58:59,926:INFO:create_model() successfully completed......................................
2023-08-16 01:58:59,996:INFO:SubProcess create_model() end ==================================
2023-08-16 01:58:59,996:INFO:Creating metrics dataframe
2023-08-16 01:59:00,003:INFO:Initializing Random Forest Classifier
2023-08-16 01:59:00,003:INFO:Total runtime is 0.15052982171376544 minutes
2023-08-16 01:59:00,005:INFO:SubProcess create_model() called ==================================
2023-08-16 01:59:00,005:INFO:Initializing create_model()
2023-08-16 01:59:00,006:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C0EC77C0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C0B82EE0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:59:00,006:INFO:Checking exceptions
2023-08-16 01:59:00,006:INFO:Importing libraries
2023-08-16 01:59:00,006:INFO:Copying training dataset
2023-08-16 01:59:00,014:INFO:Defining folds
2023-08-16 01:59:00,015:INFO:Declaring metric variables
2023-08-16 01:59:00,018:INFO:Importing untrained model
2023-08-16 01:59:00,021:INFO:Random Forest Classifier Imported successfully
2023-08-16 01:59:00,026:INFO:Starting cross validation
2023-08-16 01:59:00,026:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:59:01,533:INFO:Calculating mean and std
2023-08-16 01:59:01,534:INFO:Creating metrics dataframe
2023-08-16 01:59:01,673:INFO:Uploading results into container
2023-08-16 01:59:01,674:INFO:Uploading model into container now
2023-08-16 01:59:01,674:INFO:_master_model_container: 21
2023-08-16 01:59:01,674:INFO:_display_container: 3
2023-08-16 01:59:01,675:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-08-16 01:59:01,675:INFO:create_model() successfully completed......................................
2023-08-16 01:59:01,742:INFO:SubProcess create_model() end ==================================
2023-08-16 01:59:01,743:INFO:Creating metrics dataframe
2023-08-16 01:59:01,750:INFO:Initializing Quadratic Discriminant Analysis
2023-08-16 01:59:01,750:INFO:Total runtime is 0.1796477158864339 minutes
2023-08-16 01:59:01,753:INFO:SubProcess create_model() called ==================================
2023-08-16 01:59:01,753:INFO:Initializing create_model()
2023-08-16 01:59:01,753:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C0EC77C0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C0B82EE0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:59:01,753:INFO:Checking exceptions
2023-08-16 01:59:01,753:INFO:Importing libraries
2023-08-16 01:59:01,753:INFO:Copying training dataset
2023-08-16 01:59:01,760:INFO:Defining folds
2023-08-16 01:59:01,760:INFO:Declaring metric variables
2023-08-16 01:59:01,762:INFO:Importing untrained model
2023-08-16 01:59:01,765:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-16 01:59:01,769:INFO:Starting cross validation
2023-08-16 01:59:01,770:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:59:02,991:INFO:Calculating mean and std
2023-08-16 01:59:02,992:INFO:Creating metrics dataframe
2023-08-16 01:59:03,127:INFO:Uploading results into container
2023-08-16 01:59:03,128:INFO:Uploading model into container now
2023-08-16 01:59:03,128:INFO:_master_model_container: 22
2023-08-16 01:59:03,129:INFO:_display_container: 3
2023-08-16 01:59:03,129:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-16 01:59:03,129:INFO:create_model() successfully completed......................................
2023-08-16 01:59:03,198:INFO:SubProcess create_model() end ==================================
2023-08-16 01:59:03,199:INFO:Creating metrics dataframe
2023-08-16 01:59:03,206:INFO:Initializing Ada Boost Classifier
2023-08-16 01:59:03,206:INFO:Total runtime is 0.20392017364501952 minutes
2023-08-16 01:59:03,209:INFO:SubProcess create_model() called ==================================
2023-08-16 01:59:03,209:INFO:Initializing create_model()
2023-08-16 01:59:03,209:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C0EC77C0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C0B82EE0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:59:03,209:INFO:Checking exceptions
2023-08-16 01:59:03,209:INFO:Importing libraries
2023-08-16 01:59:03,209:INFO:Copying training dataset
2023-08-16 01:59:03,215:INFO:Defining folds
2023-08-16 01:59:03,215:INFO:Declaring metric variables
2023-08-16 01:59:03,217:INFO:Importing untrained model
2023-08-16 01:59:03,219:INFO:Ada Boost Classifier Imported successfully
2023-08-16 01:59:03,224:INFO:Starting cross validation
2023-08-16 01:59:03,224:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:59:04,499:INFO:Calculating mean and std
2023-08-16 01:59:04,500:INFO:Creating metrics dataframe
2023-08-16 01:59:04,642:INFO:Uploading results into container
2023-08-16 01:59:04,642:INFO:Uploading model into container now
2023-08-16 01:59:04,643:INFO:_master_model_container: 23
2023-08-16 01:59:04,643:INFO:_display_container: 3
2023-08-16 01:59:04,643:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2023-08-16 01:59:04,643:INFO:create_model() successfully completed......................................
2023-08-16 01:59:04,713:INFO:SubProcess create_model() end ==================================
2023-08-16 01:59:04,713:INFO:Creating metrics dataframe
2023-08-16 01:59:04,721:INFO:Initializing Gradient Boosting Classifier
2023-08-16 01:59:04,721:INFO:Total runtime is 0.229168967405955 minutes
2023-08-16 01:59:04,724:INFO:SubProcess create_model() called ==================================
2023-08-16 01:59:04,725:INFO:Initializing create_model()
2023-08-16 01:59:04,726:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C0EC77C0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C0B82EE0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:59:04,726:INFO:Checking exceptions
2023-08-16 01:59:04,726:INFO:Importing libraries
2023-08-16 01:59:04,726:INFO:Copying training dataset
2023-08-16 01:59:04,736:INFO:Defining folds
2023-08-16 01:59:04,736:INFO:Declaring metric variables
2023-08-16 01:59:04,741:INFO:Importing untrained model
2023-08-16 01:59:04,744:INFO:Gradient Boosting Classifier Imported successfully
2023-08-16 01:59:04,751:INFO:Starting cross validation
2023-08-16 01:59:04,752:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:59:06,070:INFO:Calculating mean and std
2023-08-16 01:59:06,071:INFO:Creating metrics dataframe
2023-08-16 01:59:06,215:INFO:Uploading results into container
2023-08-16 01:59:06,215:INFO:Uploading model into container now
2023-08-16 01:59:06,216:INFO:_master_model_container: 24
2023-08-16 01:59:06,216:INFO:_display_container: 3
2023-08-16 01:59:06,216:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-16 01:59:06,217:INFO:create_model() successfully completed......................................
2023-08-16 01:59:06,284:INFO:SubProcess create_model() end ==================================
2023-08-16 01:59:06,284:INFO:Creating metrics dataframe
2023-08-16 01:59:06,293:INFO:Initializing Linear Discriminant Analysis
2023-08-16 01:59:06,293:INFO:Total runtime is 0.2553674499193827 minutes
2023-08-16 01:59:06,296:INFO:SubProcess create_model() called ==================================
2023-08-16 01:59:06,296:INFO:Initializing create_model()
2023-08-16 01:59:06,296:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C0EC77C0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C0B82EE0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:59:06,296:INFO:Checking exceptions
2023-08-16 01:59:06,296:INFO:Importing libraries
2023-08-16 01:59:06,296:INFO:Copying training dataset
2023-08-16 01:59:06,304:INFO:Defining folds
2023-08-16 01:59:06,304:INFO:Declaring metric variables
2023-08-16 01:59:06,307:INFO:Importing untrained model
2023-08-16 01:59:06,309:INFO:Linear Discriminant Analysis Imported successfully
2023-08-16 01:59:06,314:INFO:Starting cross validation
2023-08-16 01:59:06,315:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:59:07,566:INFO:Calculating mean and std
2023-08-16 01:59:07,567:INFO:Creating metrics dataframe
2023-08-16 01:59:07,703:INFO:Uploading results into container
2023-08-16 01:59:07,703:INFO:Uploading model into container now
2023-08-16 01:59:07,704:INFO:_master_model_container: 25
2023-08-16 01:59:07,704:INFO:_display_container: 3
2023-08-16 01:59:07,704:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-16 01:59:07,704:INFO:create_model() successfully completed......................................
2023-08-16 01:59:07,771:INFO:SubProcess create_model() end ==================================
2023-08-16 01:59:07,771:INFO:Creating metrics dataframe
2023-08-16 01:59:07,780:INFO:Initializing Extra Trees Classifier
2023-08-16 01:59:07,781:INFO:Total runtime is 0.2801667809486389 minutes
2023-08-16 01:59:07,784:INFO:SubProcess create_model() called ==================================
2023-08-16 01:59:07,784:INFO:Initializing create_model()
2023-08-16 01:59:07,784:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C0EC77C0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C0B82EE0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:59:07,784:INFO:Checking exceptions
2023-08-16 01:59:07,784:INFO:Importing libraries
2023-08-16 01:59:07,784:INFO:Copying training dataset
2023-08-16 01:59:07,790:INFO:Defining folds
2023-08-16 01:59:07,791:INFO:Declaring metric variables
2023-08-16 01:59:07,793:INFO:Importing untrained model
2023-08-16 01:59:07,796:INFO:Extra Trees Classifier Imported successfully
2023-08-16 01:59:07,800:INFO:Starting cross validation
2023-08-16 01:59:07,800:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:59:09,357:INFO:Calculating mean and std
2023-08-16 01:59:09,358:INFO:Creating metrics dataframe
2023-08-16 01:59:09,507:INFO:Uploading results into container
2023-08-16 01:59:09,508:INFO:Uploading model into container now
2023-08-16 01:59:09,508:INFO:_master_model_container: 26
2023-08-16 01:59:09,508:INFO:_display_container: 3
2023-08-16 01:59:09,509:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='auto',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-08-16 01:59:09,509:INFO:create_model() successfully completed......................................
2023-08-16 01:59:09,583:INFO:SubProcess create_model() end ==================================
2023-08-16 01:59:09,583:INFO:Creating metrics dataframe
2023-08-16 01:59:09,592:INFO:Initializing Light Gradient Boosting Machine
2023-08-16 01:59:09,592:INFO:Total runtime is 0.31034003098805746 minutes
2023-08-16 01:59:09,594:INFO:SubProcess create_model() called ==================================
2023-08-16 01:59:09,594:INFO:Initializing create_model()
2023-08-16 01:59:09,594:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C0EC77C0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C0B82EE0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:59:09,594:INFO:Checking exceptions
2023-08-16 01:59:09,594:INFO:Importing libraries
2023-08-16 01:59:09,595:INFO:Copying training dataset
2023-08-16 01:59:09,601:INFO:Defining folds
2023-08-16 01:59:09,601:INFO:Declaring metric variables
2023-08-16 01:59:09,603:INFO:Importing untrained model
2023-08-16 01:59:09,606:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-16 01:59:09,612:INFO:Starting cross validation
2023-08-16 01:59:09,613:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:59:10,988:INFO:Calculating mean and std
2023-08-16 01:59:10,989:INFO:Creating metrics dataframe
2023-08-16 01:59:11,122:INFO:Uploading results into container
2023-08-16 01:59:11,123:INFO:Uploading model into container now
2023-08-16 01:59:11,123:INFO:_master_model_container: 27
2023-08-16 01:59:11,123:INFO:_display_container: 3
2023-08-16 01:59:11,124:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-16 01:59:11,124:INFO:create_model() successfully completed......................................
2023-08-16 01:59:11,189:INFO:SubProcess create_model() end ==================================
2023-08-16 01:59:11,189:INFO:Creating metrics dataframe
2023-08-16 01:59:11,198:INFO:Initializing Dummy Classifier
2023-08-16 01:59:11,198:INFO:Total runtime is 0.33711142937342325 minutes
2023-08-16 01:59:11,201:INFO:SubProcess create_model() called ==================================
2023-08-16 01:59:11,202:INFO:Initializing create_model()
2023-08-16 01:59:11,202:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C0EC77C0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000214C0B82EE0>, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:59:11,202:INFO:Checking exceptions
2023-08-16 01:59:11,202:INFO:Importing libraries
2023-08-16 01:59:11,202:INFO:Copying training dataset
2023-08-16 01:59:11,209:INFO:Defining folds
2023-08-16 01:59:11,209:INFO:Declaring metric variables
2023-08-16 01:59:11,211:INFO:Importing untrained model
2023-08-16 01:59:11,213:INFO:Dummy Classifier Imported successfully
2023-08-16 01:59:11,218:INFO:Starting cross validation
2023-08-16 01:59:11,218:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-16 01:59:11,292:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:59:11,295:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:59:11,307:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:59:11,312:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:59:11,322:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:59:11,324:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:59:11,324:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:59:11,329:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:59:11,332:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 01:59:12,404:INFO:Calculating mean and std
2023-08-16 01:59:12,405:INFO:Creating metrics dataframe
2023-08-16 01:59:12,539:INFO:Uploading results into container
2023-08-16 01:59:12,539:INFO:Uploading model into container now
2023-08-16 01:59:12,540:INFO:_master_model_container: 28
2023-08-16 01:59:12,540:INFO:_display_container: 3
2023-08-16 01:59:12,540:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-08-16 01:59:12,540:INFO:create_model() successfully completed......................................
2023-08-16 01:59:12,605:INFO:SubProcess create_model() end ==================================
2023-08-16 01:59:12,606:INFO:Creating metrics dataframe
2023-08-16 01:59:12,621:INFO:Initializing create_model()
2023-08-16 01:59:12,621:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C0EC77C0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=123, solver='auto', tol=0.001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-16 01:59:12,621:INFO:Checking exceptions
2023-08-16 01:59:12,623:INFO:Importing libraries
2023-08-16 01:59:12,623:INFO:Copying training dataset
2023-08-16 01:59:12,629:INFO:Defining folds
2023-08-16 01:59:12,629:INFO:Declaring metric variables
2023-08-16 01:59:12,629:INFO:Importing untrained model
2023-08-16 01:59:12,629:INFO:Declaring custom model
2023-08-16 01:59:12,629:INFO:Ridge Classifier Imported successfully
2023-08-16 01:59:12,630:INFO:Cross validation set to False
2023-08-16 01:59:12,630:INFO:Fitting Model
2023-08-16 01:59:12,745:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=123, solver='auto', tol=0.001)
2023-08-16 01:59:12,745:INFO:create_model() successfully completed......................................
2023-08-16 01:59:12,831:INFO:_master_model_container: 28
2023-08-16 01:59:12,831:INFO:_display_container: 3
2023-08-16 01:59:12,832:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=123, solver='auto', tol=0.001)
2023-08-16 01:59:12,832:INFO:compare_models() successfully completed......................................
2023-08-16 02:00:06,100:INFO:Initializing plot_model()
2023-08-16 02:00:06,100:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, normalize='deprecated', positive=False,
                random_state=123, solver='auto', tol=0.001), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000214C0EC77C0>, system=True)
2023-08-16 02:00:06,100:INFO:Checking exceptions
2023-08-16 02:00:06,105:INFO:Preloading libraries
2023-08-16 02:00:06,106:INFO:Copying training dataset
2023-08-16 02:00:06,106:INFO:Plot type: confusion_matrix
2023-08-16 02:00:06,170:INFO:Fitting Model
2023-08-16 02:00:06,170:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but RidgeClassifier was fitted with feature names
  warnings.warn(

2023-08-16 02:00:06,170:INFO:Scoring test/hold-out set
2023-08-16 02:00:06,243:INFO:Visual Rendered Successfully
2023-08-16 02:00:06,328:INFO:plot_model() successfully completed......................................
2023-08-16 02:06:00,489:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-16 02:06:00,489:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-16 02:06:00,489:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-16 02:06:00,489:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-16 02:35:19,374:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:878: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-16 02:35:19,377:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 02:35:19,377:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:903: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-16 02:35:19,378:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:906: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-16 02:35:19,381:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 02:35:19,384:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 02:35:19,385:WARNING:c:\Users\lmacciomaretto\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-16 02:36:31,916:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-16 02:36:31,916:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-16 02:36:31,916:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-16 02:36:31,916:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-16 02:40:39,689:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-16 02:40:39,689:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-16 02:40:39,689:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-16 02:40:39,689:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
