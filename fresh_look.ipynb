{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.23-246-g3d31191b-gcc_10_3_0.dll\n",
      "c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.23-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RandomForestClassifier from sklearn.ensemble\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Import other stuff\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/NSDUH_2021_Tab.txt'\n",
    "\n",
    "data = pd.read_csv(file_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_path = 'data/dataframe.csv'\n",
    "\n",
    "df = pd.read_csv(dataframe_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIGEVER</th>\n",
       "      <th>MJEVER</th>\n",
       "      <th>ALCEVER</th>\n",
       "      <th>COCEVER</th>\n",
       "      <th>CRKEVER</th>\n",
       "      <th>HEREVER</th>\n",
       "      <th>LSD</th>\n",
       "      <th>METHAMEVR</th>\n",
       "      <th>IRIMPREMEM</th>\n",
       "      <th>ADDPREV</th>\n",
       "      <th>IRSUIPLANYR</th>\n",
       "      <th>ASDSREL2</th>\n",
       "      <th>IRAMDEYR</th>\n",
       "      <th>IRDSTCHR12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CIGEVER  MJEVER  ALCEVER  COCEVER  CRKEVER  HEREVER  LSD  METHAMEVR  \\\n",
       "0        1       1        1        0        0        0    0          0   \n",
       "1        1       0        1        0        0        0    0          0   \n",
       "2        0       0        1        0        0        0    0          0   \n",
       "3        1       1        1        0        0        0    0          0   \n",
       "4        0       0        0        0        0        0    0          0   \n",
       "\n",
       "   IRIMPREMEM  ADDPREV  IRSUIPLANYR  ASDSREL2  IRAMDEYR  IRDSTCHR12  \n",
       "0           2        2          0.0       NaN       0.0          99  \n",
       "1          99        2          0.0       NaN       0.0          99  \n",
       "2           1        2          0.0       NaN       0.0           4  \n",
       "3           2        1          0.0       NaN       0.0          99  \n",
       "4          99        2          0.0       NaN       0.0          99  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'IRIMPREMEM', # DIFFICULTY REMEMBERING ONE MO IN PST 12 MOS - IMP REV (495) --> BINARY!\n",
    "# 'ADDPREV', # SEVERAL DAYS OR LNGR WHEN FELT SAD/EMPTY/DPRSD (506) --> BINARY!\n",
    "# 'IRSUIPLANYR', # ADULT MADE PLANS TO KILL SELF IN PST YR - IMP REV (499)\n",
    "# 'ASDSREL2', # ADULT: DEP FEELINGS ROLE IMPAIRMENT - CLOSE RELATIONSHIPS (520)\n",
    "# 'IRAMDEYR', # ADULT: PAST YEAR MAJOR DEPRESSIVE EPISODE (MDE) - IMP REV\n",
    "# 'IRDSTCHR12' # HOW OFTEN FELT COULDN'T BE CHEERED UP WRST MONTH - IMP REV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Thought: Taking all of the target variables above and making an aggregate target variable. This will be the target variable for the model.\n",
    "\n",
    "### You could take an average of the 6 target variables and scale them to a 0-1 scale. This would be the target variable for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IRIMPREMEM \n",
    "# 1 = No difficulty ................................................................................................................. 17389 29.96\n",
    "# 2 = Mild difficulty............................................................................................................... 12505 21.55\n",
    "# 3 = Moderate difficulty ....................................................................................................... 5745 9.90\n",
    "# 4 = Severe difficulty............................................................................................................ 1839 3.17\n",
    "# 99 = LEGITIMATE SKIP................................................................................................... 20556 35.42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99    20397\n",
       "1     17342\n",
       "2     12461\n",
       "3      5708\n",
       "4      1828\n",
       "Name: IRIMPREMEM, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.IRIMPREMEM.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    17342\n",
       "2    12461\n",
       "3     5708\n",
       "4     1828\n",
       "Name: IRIMPREMEM, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop all 99s from the field above and run model with field as target (Difficulty Remembering)\n",
    "\n",
    "# Drop all irrelevant targets\n",
    "memory_df = df.drop(['ADDPREV', 'IRSUIPLANYR', 'ASDSREL2',\n",
    "       'IRAMDEYR', 'IRDSTCHR12'], axis=1)\n",
    "\n",
    "# Drop all 99s from the target field\n",
    "memory_df = memory_df[memory_df['IRIMPREMEM'] != 99]\n",
    "\n",
    "# Inspect\n",
    "memory_df.IRIMPREMEM.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the classifier\n",
    "rfc = RandomForestClassifier(n_estimators=150, random_state=42)\n",
    "\n",
    "# Define X and y\n",
    "X = memory_df.drop(columns=['IRIMPREMEM'])\n",
    "y = memory_df['IRIMPREMEM']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_prob = rfc.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5709892846695729"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import ROCAUC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Calculate the ROC AUC score of y_test and y_pred_prob\n",
    "roc_auc_score(y_test, y_pred_prob, multi_class='ovr') # 'ovr' stands for 'one-vs-rest' and it is sensitive to class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.92      0.63      4305\n",
      "           2       0.37      0.11      0.17      3124\n",
      "           3       0.28      0.01      0.02      1446\n",
      "           4       0.00      0.00      0.00       460\n",
      "\n",
      "    accuracy                           0.46      9335\n",
      "   macro avg       0.28      0.26      0.21      9335\n",
      "weighted avg       0.39      0.46      0.35      9335\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Insect balanced classifier\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "# Return a ckassification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make this feature importance code into function later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>feature_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MJEVER</td>\n",
       "      <td>0.369779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>METHAMEVR</td>\n",
       "      <td>0.130593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LSD</td>\n",
       "      <td>0.108513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COCEVER</td>\n",
       "      <td>0.104935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HEREVER</td>\n",
       "      <td>0.090615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CIGEVER</td>\n",
       "      <td>0.083960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALCEVER</td>\n",
       "      <td>0.059896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CRKEVER</td>\n",
       "      <td>0.051709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature  feature_importance\n",
       "1     MJEVER            0.369779\n",
       "7  METHAMEVR            0.130593\n",
       "6        LSD            0.108513\n",
       "3    COCEVER            0.104935\n",
       "5    HEREVER            0.090615\n",
       "0    CIGEVER            0.083960\n",
       "2    ALCEVER            0.059896\n",
       "4    CRKEVER            0.051709"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create feature importance dataframe to analyze the importance of each feature\n",
    "fi_values = rfc.feature_importances_\n",
    "features = X_train.columns\n",
    "\n",
    "# Create dataframe\n",
    "feature_importance_df = pd.DataFrame({\"feature\": features, \"feature_importance\": fi_values})\n",
    "\n",
    "# Sort in descending order\n",
    "feature_importance_df = feature_importance_df.sort_values(by=\"feature_importance\", ascending = False)\n",
    "\n",
    "# View dataframe\n",
    "feature_importance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now using RandomOverSampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52148\n",
      "52148\n"
     ]
    }
   ],
   "source": [
    "# Resample from training data\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Print the length of resampled data\n",
    "print(len(X_resampled))\n",
    "print(len(y_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5585268619191814"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrain data with resampled data\n",
    "rfc.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_prob = rfc.predict_proba(X_test)\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "# Calculate the ROC AUC score of y_test and y_pred_prob\n",
    "roc_auc_score(y_test, y_pred_prob, multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.53      0.53      4305\n",
      "           2       0.35      0.06      0.10      3124\n",
      "           3       0.17      0.39      0.24      1446\n",
      "           4       0.09      0.26      0.13       460\n",
      "\n",
      "    accuracy                           0.33      9335\n",
      "   macro avg       0.29      0.31      0.25      9335\n",
      "weighted avg       0.40      0.33      0.32      9335\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Return a ckassification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2     29452\n",
       "1     15988\n",
       "99    10609\n",
       "98     1519\n",
       "97      105\n",
       "94       57\n",
       "85        6\n",
       "Name: ADDPREV, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ADDPREV.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 = Yes................................................................................................................................ 16069 27.69\n",
    "# 2 = No................................................................................................................................. 29524 50.87\n",
    "# 85 = BAD DATA Logically assigned ................................................................................. 7 0.01\n",
    "# 94 = DON'T KNOW........................................................................................................... 59 0.10\n",
    "# 97 = REFUSED .................................................................................................................. 108 0.19\n",
    "# 98 = BLANK (NO ANSWER) ........................................................................................... 1524 2.63\n",
    "# 99 = LEGITIMATE SKIP................................................................................................... 10743 18.51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIGEVER</th>\n",
       "      <th>MJEVER</th>\n",
       "      <th>ALCEVER</th>\n",
       "      <th>COCEVER</th>\n",
       "      <th>CRKEVER</th>\n",
       "      <th>HEREVER</th>\n",
       "      <th>LSD</th>\n",
       "      <th>METHAMEVR</th>\n",
       "      <th>ADDPREV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CIGEVER  MJEVER  ALCEVER  COCEVER  CRKEVER  HEREVER  LSD  METHAMEVR  \\\n",
       "0        1       1        1        0        0        0    0          0   \n",
       "1        1       0        1        0        0        0    0          0   \n",
       "2        0       0        1        0        0        0    0          0   \n",
       "3        1       1        1        0        0        0    0          0   \n",
       "4        0       0        0        0        0        0    0          0   \n",
       "\n",
       "   ADDPREV  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        1  \n",
       "4        0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean data\n",
    "addprev_df = df.drop(['IRIMPREMEM', 'IRSUIPLANYR', 'ASDSREL2',\n",
    "       'IRAMDEYR', 'IRDSTCHR12'], axis=1)\n",
    "\n",
    "# Keep only 1s and 2s\n",
    "addprev_df = addprev_df[(addprev_df['ADDPREV'] == 1) | (addprev_df['ADDPREV'] == 2)]\n",
    "\n",
    "# Change all 2s to 0s\n",
    "addprev_df['ADDPREV'] = addprev_df['ADDPREV'].replace(2, 0)\n",
    "\n",
    "# Inspect\n",
    "addprev_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    29452\n",
       "1    15988\n",
       "Name: ADDPREV, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addprev_df.ADDPREV.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note this one is binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
    "\n",
    "# Define X and y\n",
    "X = addprev_df.drop('ADDPREV', axis=1)\n",
    "y = addprev_df['ADDPREV']\n",
    "\n",
    "# Split data into train and test subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Fit model\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_prob = rfc.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6215317751076487"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate ROC AUC\n",
    "ROCAUC = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "# Print ROC AUC\n",
    "ROCAUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.98      0.79      5961\n",
      "           1       0.57      0.06      0.10      3127\n",
      "\n",
      "    accuracy                           0.66      9088\n",
      "   macro avg       0.61      0.52      0.45      9088\n",
      "weighted avg       0.63      0.66      0.55      9088\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predications\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy resampling methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46982\n",
      "46982\n"
     ]
    }
   ],
   "source": [
    "# Resample from training data\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Print the length of resampled data\n",
    "print(len(X_resampled))\n",
    "print(len(y_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain model with resampled data and test on test set\n",
    "rfc.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_prob = rfc.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6214763031445146"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate ROC AUC\n",
    "ROCAUC = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "# Print ROC AUC\n",
    "ROCAUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.57      0.64      5961\n",
      "           1       0.43      0.64      0.52      3127\n",
      "\n",
      "    accuracy                           0.59      9088\n",
      "   macro avg       0.59      0.60      0.58      9088\n",
      "weighted avg       0.64      0.59      0.60      9088\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get classification report\n",
    "\n",
    "# Make predications\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model yet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>feature_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MJEVER</td>\n",
       "      <td>0.316249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LSD</td>\n",
       "      <td>0.234333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALCEVER</td>\n",
       "      <td>0.162075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COCEVER</td>\n",
       "      <td>0.144317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>METHAMEVR</td>\n",
       "      <td>0.071169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CIGEVER</td>\n",
       "      <td>0.054404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HEREVER</td>\n",
       "      <td>0.011620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CRKEVER</td>\n",
       "      <td>0.005832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature  feature_importance\n",
       "1     MJEVER            0.316249\n",
       "6        LSD            0.234333\n",
       "2    ALCEVER            0.162075\n",
       "3    COCEVER            0.144317\n",
       "7  METHAMEVR            0.071169\n",
       "0    CIGEVER            0.054404\n",
       "5    HEREVER            0.011620\n",
       "4    CRKEVER            0.005832"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create feature importance dataframe to analyze the importance of each feature\n",
    "fi_values = rfc.feature_importances_\n",
    "features = X_train.columns\n",
    "\n",
    "# Create dataframe\n",
    "feature_importance_df = pd.DataFrame({\"feature\": features, \"feature_importance\": fi_values})\n",
    "\n",
    "# Sort in descending order\n",
    "feature_importance_df = feature_importance_df.sort_values(by=\"feature_importance\", ascending = False)\n",
    "\n",
    "# View dataframe\n",
    "feature_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ADDPREV      1.000000\n",
       "MJEVER       0.199090\n",
       "LSD          0.141680\n",
       "COCEVER      0.130175\n",
       "ALCEVER      0.114207\n",
       "CIGEVER      0.100959\n",
       "METHAMEVR    0.098456\n",
       "HEREVER      0.072134\n",
       "CRKEVER      0.065931\n",
       "Name: ADDPREV, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# q: How do I get the correlation coefficient between each feature and the target in a dataframe?\n",
    "# a: df.corr()['target'].sort_values(ascending=False)\n",
    "\n",
    "addprev_df.corr()['ADDPREV'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CIGEVER', 'MJEVER', 'ALCEVER', 'COCEVER', 'CRKEVER', 'HEREVER', 'LSD',\n",
       "       'METHAMEVR', 'IRIMPREMEM', 'ADDPREV', 'IRSUIPLANYR', 'ASDSREL2',\n",
       "       'IRAMDEYR', 'IRDSTCHR12'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    46168\n",
       "1.0      959\n",
       "Name: IRSUIPLANYR, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ADULT MADE PLANS TO KILL SELF IN PST YR - IMP REV (499)\n",
    "df.IRSUIPLANYR.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIGEVER</th>\n",
       "      <th>MJEVER</th>\n",
       "      <th>ALCEVER</th>\n",
       "      <th>COCEVER</th>\n",
       "      <th>CRKEVER</th>\n",
       "      <th>HEREVER</th>\n",
       "      <th>LSD</th>\n",
       "      <th>METHAMEVR</th>\n",
       "      <th>IRSUIPLANYR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CIGEVER  MJEVER  ALCEVER  COCEVER  CRKEVER  HEREVER  LSD  METHAMEVR  \\\n",
       "0        1       1        1        0        0        0    0          0   \n",
       "1        1       0        1        0        0        0    0          0   \n",
       "2        0       0        1        0        0        0    0          0   \n",
       "3        1       1        1        0        0        0    0          0   \n",
       "4        0       0        0        0        0        0    0          0   \n",
       "\n",
       "   IRSUIPLANYR  \n",
       "0          0.0  \n",
       "1          0.0  \n",
       "2          0.0  \n",
       "3          0.0  \n",
       "4          0.0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a suicide_df\n",
    "\n",
    "suicide_df = df.drop(['IRIMPREMEM', 'ADDPREV', 'ASDSREL2',\n",
    "       'IRAMDEYR', 'IRDSTCHR12'], axis=1)\n",
    "\n",
    "# Inspect\n",
    "suicide_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 57736 entries, 0 to 57735\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   CIGEVER      57736 non-null  int64  \n",
      " 1   MJEVER       57736 non-null  int64  \n",
      " 2   ALCEVER      57736 non-null  int64  \n",
      " 3   COCEVER      57736 non-null  int64  \n",
      " 4   CRKEVER      57736 non-null  int64  \n",
      " 5   HEREVER      57736 non-null  int64  \n",
      " 6   LSD          57736 non-null  int64  \n",
      " 7   METHAMEVR    57736 non-null  int64  \n",
      " 8   IRSUIPLANYR  47127 non-null  float64\n",
      "dtypes: float64(1), int64(8)\n",
      "memory usage: 4.0 MB\n"
     ]
    }
   ],
   "source": [
    "suicide_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 47127 entries, 0 to 57735\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype\n",
      "---  ------       --------------  -----\n",
      " 0   CIGEVER      47127 non-null  int64\n",
      " 1   MJEVER       47127 non-null  int64\n",
      " 2   ALCEVER      47127 non-null  int64\n",
      " 3   COCEVER      47127 non-null  int64\n",
      " 4   CRKEVER      47127 non-null  int64\n",
      " 5   HEREVER      47127 non-null  int64\n",
      " 6   LSD          47127 non-null  int64\n",
      " 7   METHAMEVR    47127 non-null  int64\n",
      " 8   IRSUIPLANYR  47127 non-null  int32\n",
      "dtypes: int32(1), int64(8)\n",
      "memory usage: 3.4 MB\n"
     ]
    }
   ],
   "source": [
    "# Drop null values\n",
    "suicide_df = suicide_df.dropna()\n",
    "\n",
    "# Convert to integer\n",
    "suicide_df['IRSUIPLANYR'] = suicide_df['IRSUIPLANYR'].astype(int)\n",
    "\n",
    "# Reinspect\n",
    "suicide_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run RandomForestClassifier on suicide_df\n",
    "\n",
    "# Instantiate the classifier\n",
    "rfc = RandomForestClassifier(n_estimators=150, random_state=42)\n",
    "\n",
    "# Define X and y\n",
    "X = suicide_df.drop(columns=['IRSUIPLANYR'])\n",
    "y = suicide_df['IRSUIPLANYR']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_prob = rfc.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6184031376336953"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate ROC AUC\n",
    "ROCAUC = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "# Print ROC AUC\n",
    "ROCAUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     11546\n",
      "           1       0.00      0.00      0.00       236\n",
      "\n",
      "    accuracy                           0.98     11782\n",
      "   macro avg       0.49      0.50      0.49     11782\n",
      "weighted avg       0.96      0.98      0.97     11782\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Get y_pred\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "# Return classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Address class imbalance with resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69244\n",
      "69244\n"
     ]
    }
   ],
   "source": [
    "# Resample from training data\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Print the length of resampled data\n",
    "print(len(X_resampled))\n",
    "print(len(y_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain model with resampled data and test on test set\n",
    "rfc.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_prob = rfc.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6145497229945363"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get ROC AUC score\n",
    "roc_auc_score(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.72      0.83     11546\n",
      "           1       0.03      0.43      0.06       236\n",
      "\n",
      "    accuracy                           0.72     11782\n",
      "   macro avg       0.51      0.58      0.45     11782\n",
      "weighted avg       0.97      0.72      0.82     11782\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Return another classification report\n",
    "\n",
    "# Get y_pred\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "# Return classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopping here as breakpoint.\n",
    "\n",
    "### 1. Having working rfcs for the following:\n",
    "### 'IRIMPREMEM', 'ADDPREV', 'IRSUIPLANYR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'ASDSREL2', # ADULT: DEP FEELINGS ROLE IMPAIRMENT - CLOSE RELATIONSHIPS (520)\n",
    "# 'IRAMDEYR', # ADULT: PAST YEAR MAJOR DEPRESSIVE EPISODE (MDE) - IMP REV\n",
    "# 'IRDSTCHR12' # HOW OFTEN FELT COULDN'T BE CHEERED UP WRST MONTH - IMP REV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CIGEVER', 'MJEVER', 'ALCEVER', 'COCEVER', 'CRKEVER', 'HEREVER', 'LSD',\n",
       "       'METHAMEVR', 'IRIMPREMEM', 'ADDPREV', 'IRSUIPLANYR', 'ASDSREL2',\n",
       "       'IRAMDEYR', 'IRDSTCHR12'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0    1875\n",
       "4.0    1718\n",
       "2.0     829\n",
       "5.0     501\n",
       "1.0     186\n",
       "Name: ASDSREL2, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ASDSREL2 # ADULT: DEP FEELINGS ROLE IMPAIRMENT - CLOSE RELATIONSHIPS (520)\n",
    "\n",
    "# Make relationship_df\n",
    "relationship_df = df.drop(['IRIMPREMEM', 'ADDPREV', 'IRSUIPLANYR', 'IRAMDEYR', 'IRDSTCHR12'], axis=1)\n",
    "\n",
    "# Inspect target\n",
    "relationship_df.ASDSREL2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 57736 entries, 0 to 57735\n",
      "Data columns (total 9 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   CIGEVER    57736 non-null  int64  \n",
      " 1   MJEVER     57736 non-null  int64  \n",
      " 2   ALCEVER    57736 non-null  int64  \n",
      " 3   COCEVER    57736 non-null  int64  \n",
      " 4   CRKEVER    57736 non-null  int64  \n",
      " 5   HEREVER    57736 non-null  int64  \n",
      " 6   LSD        57736 non-null  int64  \n",
      " 7   METHAMEVR  57736 non-null  int64  \n",
      " 8   ASDSREL2   5109 non-null   float64\n",
      "dtypes: float64(1), int64(8)\n",
      "memory usage: 4.0 MB\n"
     ]
    }
   ],
   "source": [
    "relationship_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NA from ASDSREL2\n",
    "\n",
    "relationship_df = relationship_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5109 entries, 9 to 57724\n",
      "Data columns (total 9 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   CIGEVER    5109 non-null   int64  \n",
      " 1   MJEVER     5109 non-null   int64  \n",
      " 2   ALCEVER    5109 non-null   int64  \n",
      " 3   COCEVER    5109 non-null   int64  \n",
      " 4   CRKEVER    5109 non-null   int64  \n",
      " 5   HEREVER    5109 non-null   int64  \n",
      " 6   LSD        5109 non-null   int64  \n",
      " 7   METHAMEVR  5109 non-null   int64  \n",
      " 8   ASDSREL2   5109 non-null   float64\n",
      "dtypes: float64(1), int64(8)\n",
      "memory usage: 399.1 KB\n"
     ]
    }
   ],
   "source": [
    "relationship_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# . = Aged 12-17/Unkn/Legit Skip (Otherwise)..................................................................... 52894 91.14\n",
    "# 1 = None (ADPSRELS=0).................................................................................................. 186 0.32\n",
    "# 2 = Mild (ADPSRELS=1,2,3)............................................................................................. 833 1.44\n",
    "# 3 = Moderate (ADPSRELS=4,5,6) ..................................................................................... 1883 3.24\n",
    "# 4 = Severe (ADPSRELS=7,8,9).......................................................................................... 1733 2.99\n",
    "# 5 = Very Severe (ADPSRELS=10)..................................................................................... 505 0.87"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the classifier\n",
    "rfc = RandomForestClassifier(n_estimators=150, random_state=42)\n",
    "\n",
    "# Define X and y\n",
    "X = relationship_df.drop(columns=['ASDSREL2'])\n",
    "y = relationship_df['ASDSREL2']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_prob = rfc.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.542572058168723"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the ROC AUC score of y_test and y_pred_prob\n",
    "roc_auc_score(y_test, y_pred_prob, multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        40\n",
      "         2.0       0.00      0.00      0.00       210\n",
      "         3.0       0.39      0.79      0.52       480\n",
      "         4.0       0.35      0.25      0.29       412\n",
      "         5.0       0.00      0.00      0.00       136\n",
      "\n",
      "    accuracy                           0.38      1278\n",
      "   macro avg       0.15      0.21      0.16      1278\n",
      "weighted avg       0.26      0.38      0.29      1278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Calculate y_pred and return a classification report\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "# Print report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.540092738652541"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use over sampling then retest the model\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Retrain the model\n",
    "rfc.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Predict the test data\n",
    "y_pred_prob = rfc.predict_proba(X_test)\n",
    "\n",
    "# Return the ROC AUC score\n",
    "roc_auc_score(y_test, y_pred_prob, multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.04      0.38      0.07        40\n",
      "         2.0       0.22      0.22      0.22       210\n",
      "         3.0       0.39      0.24      0.30       480\n",
      "         4.0       0.21      0.06      0.09       412\n",
      "         5.0       0.11      0.21      0.15       136\n",
      "\n",
      "    accuracy                           0.18      1278\n",
      "   macro avg       0.20      0.22      0.16      1278\n",
      "weighted avg       0.27      0.18      0.19      1278\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate y_pred and return classification report\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "# Print report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes: Even retrained with oversampled data, the Random Forest Classifier for Relationship Role Impairment performs very poorly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IRAMDEYR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IRDSTCHR12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section II: AutoSklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breakpoint: For the sake of time, use AutoML on the most promising target variable, 'ADDPREV' in addprev_df, to test several models and find the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'autosklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Import autosklearn classification model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mautosklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mclassification\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'autosklearn'"
     ]
    }
   ],
   "source": [
    "# Import autosklearn classification model\n",
    "import autosklearn.classification\n",
    "import sklearn.model_selection\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "\n",
    "# Define X and y\n",
    "X = addprev_df.drop('ADDPREV', axis=1)\n",
    "y = addprev_df['ADDPREV']\n",
    "\n",
    "# Split data into train and test subsets\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Create an AutoSklearnClassifier instance\n",
    "automl = autosklearn.classification.AutoSklearnClassifier(\n",
    "    time_left_for_this_task=120,  # Maximum time in seconds\n",
    "    per_run_time_limit=30,        # Maximum time for each model in seconds\n",
    "    include_estimators=['random_forest', 'extra_trees', 'gradient_boosting'],\n",
    "    exclude_preprocessors=['no_preprocessing'],\n",
    "    ensemble_size=1,              # Number of models in the ensemble\n",
    "    ensemble_nbest=1              # Number of models selected for the ensemble\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "automl.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Get the best performing model\n",
    "best_model = automl.get_best_estimator()\n",
    "\n",
    "# Predict\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Print accuracy score\n",
    "print(\"Accuracy score\", sklearn.metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIGEVER</th>\n",
       "      <th>MJEVER</th>\n",
       "      <th>ALCEVER</th>\n",
       "      <th>COCEVER</th>\n",
       "      <th>CRKEVER</th>\n",
       "      <th>HEREVER</th>\n",
       "      <th>LSD</th>\n",
       "      <th>METHAMEVR</th>\n",
       "      <th>IRSUIPLANYR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CIGEVER  MJEVER  ALCEVER  COCEVER  CRKEVER  HEREVER  LSD  METHAMEVR  \\\n",
       "0        1       1        1        0        0        0    0          0   \n",
       "1        1       0        1        0        0        0    0          0   \n",
       "2        0       0        1        0        0        0    0          0   \n",
       "3        1       1        1        0        0        0    0          0   \n",
       "4        0       0        0        0        0        0    0          0   \n",
       "\n",
       "   IRSUIPLANYR  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import sweetviz\n",
    "import sweetviz as sv\n",
    "np.bool = np.bool_\n",
    "\n",
    "# Analyze the dataset with IRSUIPLANYR as the target variable and all EVER variables as features\n",
    "\n",
    "# Subset the dataframe to include the first 7 columns and IRSUIPLANYR\n",
    "sui_df = df.iloc[:, 0:8]\n",
    "sui_df['IRSUIPLANYR'] = df['IRSUIPLANYR']\n",
    "\n",
    "# Drop all null values\n",
    "sui_df = sui_df.dropna()\n",
    "\n",
    "# Set IRSUIPLANYR's data type to int\n",
    "sui_df['IRSUIPLANYR'] = sui_df['IRSUIPLANYR'].astype(int)\n",
    "\n",
    "# Inspect dataframe\n",
    "sui_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 47127 entries, 0 to 57735\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype\n",
      "---  ------       --------------  -----\n",
      " 0   CIGEVER      47127 non-null  int64\n",
      " 1   MJEVER       47127 non-null  int64\n",
      " 2   ALCEVER      47127 non-null  int64\n",
      " 3   COCEVER      47127 non-null  int64\n",
      " 4   CRKEVER      47127 non-null  int64\n",
      " 5   HEREVER      47127 non-null  int64\n",
      " 6   LSD          47127 non-null  int64\n",
      " 7   METHAMEVR    47127 non-null  int64\n",
      " 8   IRSUIPLANYR  47127 non-null  int32\n",
      "dtypes: int32(1), int64(8)\n",
      "memory usage: 3.4 MB\n"
     ]
    }
   ],
   "source": [
    "# Inspect sui_df info()\n",
    "sui_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sweetviz\\dataframe_report.py:74: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  all_source_names = [cur_name for cur_name, cur_series in source_df.iteritems()]\n",
      "c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sweetviz\\dataframe_report.py:109: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  filtered_series_names_in_source = [cur_name for cur_name, cur_series in source_df.iteritems()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e230f14c1df46178e2b918ae4cefc58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                                             |          | [  0%]   00:00 -> (? left)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sweetviz\\series_analyzer_cat.py:28: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for item in category_counts.iteritems():\n",
      "c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sweetviz\\series_analyzer_cat.py:28: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for item in category_counts.iteritems():\n",
      "c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sweetviz\\series_analyzer_cat.py:28: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for item in category_counts.iteritems():\n",
      "c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sweetviz\\series_analyzer_cat.py:28: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for item in category_counts.iteritems():\n",
      "c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sweetviz\\series_analyzer_cat.py:28: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for item in category_counts.iteritems():\n",
      "c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sweetviz\\series_analyzer_cat.py:28: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for item in category_counts.iteritems():\n",
      "c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sweetviz\\series_analyzer_cat.py:28: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for item in category_counts.iteritems():\n",
      "c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sweetviz\\series_analyzer_cat.py:28: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for item in category_counts.iteritems():\n",
      "c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sweetviz\\series_analyzer_cat.py:28: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for item in category_counts.iteritems():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report sui_report.html was generated! NOTEBOOK/COLAB USERS: the web browser MAY not pop up, regardless, the report IS saved in your notebook/colab files.\n"
     ]
    }
   ],
   "source": [
    "# Run report\n",
    "sui_report = sv.analyze(sui_df, target_feat='IRSUIPLANYR')\n",
    "\n",
    "# Save report as HTML file\n",
    "sui_report.show_html('sui_report.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    46168\n",
       "1.0      959\n",
       "Name: IRSUIPLANYR, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check value_counts() again before building model\n",
    "df.IRSUIPLANYR.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There is a serious class imbalance in the dataset that will need to be addressed using resampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import scikit-learn LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Instantiate the classifier\n",
    "clf = LogisticRegression()\n",
    "\n",
    "# Define X and y\n",
    "X = sui_df.drop(['IRSUIPLANYR'], axis=1)\n",
    "y = sui_df['IRSUIPLANYR']\n",
    "\n",
    "# Break data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Fit the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     18449\n",
      "           1       0.00      0.00      0.00       402\n",
      "\n",
      "    accuracy                           0.98     18851\n",
      "   macro avg       0.49      0.50      0.49     18851\n",
      "weighted avg       0.96      0.98      0.97     18851\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rectify the class imbalance with oversampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return confusion matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ax1 = sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, cmap='Blues', fmt='g')\n",
    "plt.show(ax1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0    1875\n",
       "4.0    1718\n",
       "2.0     829\n",
       "5.0     501\n",
       "1.0     186\n",
       "Name: ASDSREL2, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ASDSREL2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    41736\n",
       "1.0     5391\n",
       "Name: IRAMDEYR, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.IRAMDEYR.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99    40436\n",
       "3      4317\n",
       "4      3814\n",
       "5      3631\n",
       "2      3511\n",
       "1      2027\n",
       "Name: IRDSTCHR12, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.IRDSTCHR12.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
