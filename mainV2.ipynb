{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.23-246-g3d31191b-gcc_10_3_0.dll\n",
      "c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.23-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import matplotlib and seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section I: Summary of Data Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\e.a.wright\\AppData\\Local\\Temp\\ipykernel_30512\\2103078997.py:3: DtypeWarning: Columns (2792) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(file_path, sep='\\t')\n"
     ]
    }
   ],
   "source": [
    "# Read in the original dataset for the NSDUH 2021 survey \n",
    "# Purpose for importing is to get descriptive statistics on much data was preserved after cleaning\n",
    "file_path = 'data/NSDUH_2021_Tab.txt'\n",
    "\n",
    "data = pd.read_csv(file_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 58034 rows and 2988 columns in the original dataset.\n"
     ]
    }
   ],
   "source": [
    "# Save shape of data\n",
    "N_rows = data.shape[0]\n",
    "N_cols = data.shape[1]\n",
    "\n",
    "# Print shape of data in sentence\n",
    "print(f\"There were {N_rows} rows and {N_cols} columns in the original dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the pre-process subset of data to be used for modeling\n",
    "subset = pd.read_csv('data/model_subset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 53896 entries, 0 to 53895\n",
      "Data columns (total 16 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   CATAG3      53896 non-null  int64  \n",
      " 1   HEALTH2     53896 non-null  float64\n",
      " 2   ANYHLTI2    53896 non-null  int64  \n",
      " 3   INCOME      53896 non-null  int64  \n",
      " 4   POVERTY3    53896 non-null  float64\n",
      " 5   TOBFLAG     53896 non-null  int64  \n",
      " 6   MRJFLAG     53896 non-null  int64  \n",
      " 7   PYUD5MRJ    53896 non-null  float64\n",
      " 8   MJYRTOT     53896 non-null  int64  \n",
      " 9   ALCFLAG     53896 non-null  int64  \n",
      " 10  COCFLAG     53896 non-null  int64  \n",
      " 11  CRKFLAG     53896 non-null  int64  \n",
      " 12  HERFLAG     53896 non-null  int64  \n",
      " 13  LSDFLAG     53896 non-null  int64  \n",
      " 14  METHAMFLAG  53896 non-null  int64  \n",
      " 15  DEP         53896 non-null  int64  \n",
      "dtypes: float64(3), int64(13)\n",
      "memory usage: 6.6 MB\n"
     ]
    }
   ],
   "source": [
    "# Inspect subset\n",
    "subset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After cleaning and pre-processing, we were left with 53896 rows and 16 columns in our experimental dataframe.\n",
      "This means that 92.87% of the original dataset's rows (individuals) was preserved.\n"
     ]
    }
   ],
   "source": [
    "# Save shape of data\n",
    "n_rows = subset.shape[0]\n",
    "n_cols = subset.shape[1]\n",
    "\n",
    "# Print shape of data in sentence\n",
    "print(f\"After cleaning and pre-processing, we were left with {n_rows} rows and {n_cols} columns in our experimental dataframe.\")\n",
    "# Print the percentage of individuals (rows) that were preserved\n",
    "print(f\"This means that {round((n_rows/N_rows)*100, 2)}% of the original dataset's rows (individuals) was preserved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target: DEP - SCORE OF SYMPTOM INDICATORS 1 THRU 9 (For Depression)\n",
    "\n",
    "### Note: DEP is a calculated variable combining the values of the Adult and Youth Depression Fields: \"df['DEP'] = np.where((df['ADSMMDEA'] == 1) | (df['YODSMMDE'] == 1), 1, 0)\" \n",
    "\n",
    "### 1 = Has 5 or more symptoms of depression\n",
    "### 0 = Does not have 5 or more symptoms of depression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section II: Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Gradient Boosting Classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Import SMOTE for oversampling of the minority class\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Import StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Import train_test_split and metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Import RandomOverSampler\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    42771\n",
       "1    11125\n",
       "Name: DEP, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for class imbalance in the target variable\n",
    "subset.DEP.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a Gradient Boosting Classifier\n",
    "gbt = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Define X and y\n",
    "X = subset.drop('DEP', axis=1)\n",
    "y = subset['DEP']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Apply SMOTE to oversample the minority class\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform both training and testing sets\n",
    "X_train_resampled_scaled = scaler.fit_transform(X_train_resampled) # Here the resampled X_train data is scaled\n",
    "X_test_scaled = scaler.transform(X_test) # Here the original X_test data is scaled as it was not resampled\n",
    "\n",
    "# Note: you do not need to scale the target variable (y).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATAG3</th>\n",
       "      <th>HEALTH2</th>\n",
       "      <th>ANYHLTI2</th>\n",
       "      <th>INCOME</th>\n",
       "      <th>POVERTY3</th>\n",
       "      <th>TOBFLAG</th>\n",
       "      <th>MRJFLAG</th>\n",
       "      <th>PYUD5MRJ</th>\n",
       "      <th>MJYRTOT</th>\n",
       "      <th>ALCFLAG</th>\n",
       "      <th>COCFLAG</th>\n",
       "      <th>CRKFLAG</th>\n",
       "      <th>HERFLAG</th>\n",
       "      <th>LSDFLAG</th>\n",
       "      <th>METHAMFLAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.611073</td>\n",
       "      <td>-0.407494</td>\n",
       "      <td>-0.273951</td>\n",
       "      <td>1.071703</td>\n",
       "      <td>0.707423</td>\n",
       "      <td>-0.989459</td>\n",
       "      <td>-0.969245</td>\n",
       "      <td>-0.322622</td>\n",
       "      <td>-0.373269</td>\n",
       "      <td>-1.680605</td>\n",
       "      <td>-0.363807</td>\n",
       "      <td>-0.160774</td>\n",
       "      <td>-0.130895</td>\n",
       "      <td>-0.323715</td>\n",
       "      <td>-0.210746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.836589</td>\n",
       "      <td>-0.407494</td>\n",
       "      <td>-0.273951</td>\n",
       "      <td>-0.655087</td>\n",
       "      <td>-1.893003</td>\n",
       "      <td>-0.989459</td>\n",
       "      <td>-0.969245</td>\n",
       "      <td>-0.322622</td>\n",
       "      <td>-0.373269</td>\n",
       "      <td>-1.680605</td>\n",
       "      <td>-0.363807</td>\n",
       "      <td>-0.160774</td>\n",
       "      <td>-0.130895</td>\n",
       "      <td>-0.323715</td>\n",
       "      <td>-0.210746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.611073</td>\n",
       "      <td>0.673268</td>\n",
       "      <td>-0.273951</td>\n",
       "      <td>0.208308</td>\n",
       "      <td>-0.592790</td>\n",
       "      <td>1.010653</td>\n",
       "      <td>1.031731</td>\n",
       "      <td>-0.322622</td>\n",
       "      <td>0.143338</td>\n",
       "      <td>0.595024</td>\n",
       "      <td>-0.363807</td>\n",
       "      <td>-0.160774</td>\n",
       "      <td>-0.130895</td>\n",
       "      <td>-0.323715</td>\n",
       "      <td>-0.210746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.112758</td>\n",
       "      <td>-0.407494</td>\n",
       "      <td>-0.273951</td>\n",
       "      <td>1.071703</td>\n",
       "      <td>0.707423</td>\n",
       "      <td>1.010653</td>\n",
       "      <td>1.031731</td>\n",
       "      <td>-0.322622</td>\n",
       "      <td>-0.351743</td>\n",
       "      <td>0.595024</td>\n",
       "      <td>2.748707</td>\n",
       "      <td>-0.160774</td>\n",
       "      <td>-0.130895</td>\n",
       "      <td>-0.323715</td>\n",
       "      <td>-0.210746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.560419</td>\n",
       "      <td>1.754029</td>\n",
       "      <td>-0.273951</td>\n",
       "      <td>-1.518482</td>\n",
       "      <td>-1.893003</td>\n",
       "      <td>1.010653</td>\n",
       "      <td>1.031731</td>\n",
       "      <td>-0.322622</td>\n",
       "      <td>-0.373269</td>\n",
       "      <td>0.595024</td>\n",
       "      <td>-0.363807</td>\n",
       "      <td>-0.160774</td>\n",
       "      <td>-0.130895</td>\n",
       "      <td>-0.323715</td>\n",
       "      <td>-0.210746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     CATAG3   HEALTH2  ANYHLTI2    INCOME  POVERTY3   TOBFLAG   MRJFLAG  \\\n",
       "0 -0.611073 -0.407494 -0.273951  1.071703  0.707423 -0.989459 -0.969245   \n",
       "1  0.836589 -0.407494 -0.273951 -0.655087 -1.893003 -0.989459 -0.969245   \n",
       "2 -0.611073  0.673268 -0.273951  0.208308 -0.592790  1.010653  1.031731   \n",
       "3  0.112758 -0.407494 -0.273951  1.071703  0.707423  1.010653  1.031731   \n",
       "4  1.560419  1.754029 -0.273951 -1.518482 -1.893003  1.010653  1.031731   \n",
       "\n",
       "   PYUD5MRJ   MJYRTOT   ALCFLAG   COCFLAG   CRKFLAG   HERFLAG   LSDFLAG  \\\n",
       "0 -0.322622 -0.373269 -1.680605 -0.363807 -0.160774 -0.130895 -0.323715   \n",
       "1 -0.322622 -0.373269 -1.680605 -0.363807 -0.160774 -0.130895 -0.323715   \n",
       "2 -0.322622  0.143338  0.595024 -0.363807 -0.160774 -0.130895 -0.323715   \n",
       "3 -0.322622 -0.351743  0.595024  2.748707 -0.160774 -0.130895 -0.323715   \n",
       "4 -0.322622 -0.373269  0.595024 -0.363807 -0.160774 -0.130895 -0.323715   \n",
       "\n",
       "   METHAMFLAG  \n",
       "0   -0.210746  \n",
       "1   -0.210746  \n",
       "2   -0.210746  \n",
       "3   -0.210746  \n",
       "4   -0.210746  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert X_train_resampled_scaled to dataframe for inspection\n",
    "X_train_resampled_scaled_df = pd.DataFrame(X_train_resampled_scaled, columns=X_train.columns)\n",
    "\n",
    "# Inspect X_train_resampled_scaled_df\n",
    "X_train_resampled_scaled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    32087\n",
       "0    32087\n",
       "Name: DEP, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect y_train_resampled for evidence of successful resampling\n",
    "y_train_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the oversampled training data\n",
    "gbt.fit(X_train_resampled_scaled, y_train_resampled)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = gbt.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.72      0.78     10684\n",
      "           1       0.34      0.55      0.42      2790\n",
      "\n",
      "    accuracy                           0.68     13474\n",
      "   macro avg       0.60      0.64      0.60     13474\n",
      "weighted avg       0.75      0.68      0.71     13474\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Return a classification report for the model\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print a pretty confusion matrix\n",
    "ax1 = sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, cmap='Blues', fmt='g')\n",
    "plt.show(ax1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>feature_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HEALTH2</td>\n",
       "      <td>0.362204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CATAG3</td>\n",
       "      <td>0.266727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MRJFLAG</td>\n",
       "      <td>0.115889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PYUD5MRJ</td>\n",
       "      <td>0.080821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POVERTY3</td>\n",
       "      <td>0.056055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANYHLTI2</td>\n",
       "      <td>0.040701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ALCFLAG</td>\n",
       "      <td>0.029343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MJYRTOT</td>\n",
       "      <td>0.027589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INCOME</td>\n",
       "      <td>0.011978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TOBFLAG</td>\n",
       "      <td>0.005321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>METHAMFLAG</td>\n",
       "      <td>0.001268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CRKFLAG</td>\n",
       "      <td>0.000789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>COCFLAG</td>\n",
       "      <td>0.000675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LSDFLAG</td>\n",
       "      <td>0.000640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HERFLAG</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature  feature_importance\n",
       "1      HEALTH2            0.362204\n",
       "0       CATAG3            0.266727\n",
       "6      MRJFLAG            0.115889\n",
       "7     PYUD5MRJ            0.080821\n",
       "4     POVERTY3            0.056055\n",
       "2     ANYHLTI2            0.040701\n",
       "9      ALCFLAG            0.029343\n",
       "8      MJYRTOT            0.027589\n",
       "3       INCOME            0.011978\n",
       "5      TOBFLAG            0.005321\n",
       "14  METHAMFLAG            0.001268\n",
       "11     CRKFLAG            0.000789\n",
       "10     COCFLAG            0.000675\n",
       "13     LSDFLAG            0.000640\n",
       "12     HERFLAG            0.000000"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create feature importance dataframe to analyze the importance of each feature\n",
    "fi_values = gbt.feature_importances_\n",
    "features = X_train.columns\n",
    "# Create dataframe\n",
    "feature_importance_df = pd.DataFrame({\"feature\": features, \"feature_importance\": fi_values})\n",
    "# Sort in descending order\n",
    "feature_importance_df = feature_importance_df.sort_values(by=\"feature_importance\", ascending = False)\n",
    "# View dataframe\n",
    "feature_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Next step will be to eliminate features with low feature importance values to, theoretically, prevent overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section III: Confirming Validity of DEP against age-specific depression targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before proceeding, use CATAG3 to create an ADULT dataframe and a YOUTH dataframe each with their appropriate target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in subset_three_targets.csv\n",
    "df = pd.read_csv('data/subset_three_targets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ADULT dataframe (CATAG3 == 2, 3, or 4)\n",
    "ADULT = df[df['CATAG3'].isin([2,3,4])]\n",
    "\n",
    "# Drop the YODSMMDE and DEP columns from ADULT dataframe\n",
    "ADULT = ADULT.drop(['YODSMMDE', 'DEP'], axis=1)\n",
    "\n",
    "# Create YOUTH dataframe (CATAG3 == 1)\n",
    "YOUTH = df[df['CATAG3'].isin([1])]\n",
    "\n",
    "# Drop the ADSMMDEA and DEP columns from YOUTH dataframe\n",
    "YOUTH = YOUTH.drop(['ADSMMDEA', 'DEP'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    25813\n",
       "1     7364\n",
       "Name: ADSMMDEA, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the value counts of the target variables for ADULT\n",
    "adultVC = ADULT.ADSMMDEA.value_counts()\n",
    "\n",
    "adultVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of Adults with Depression: 22.0%\n"
     ]
    }
   ],
   "source": [
    "# Percent Adult's with Depression\n",
    "percent_adults_depression = round(adultVC[1]/(adultVC[0]+adultVC[1]), 2)*100 # Round to 2 decimal places\n",
    "\n",
    "# Print\n",
    "print(f\"Percent of Adults with Depression: {percent_adults_depression}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7684\n",
       "1    2557\n",
       "Name: YODSMMDE, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the value counts of the target variables for YOUTH\n",
    "youthVC = YOUTH.YODSMMDE.value_counts()\n",
    "\n",
    "youthVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of Adults with Depression: 25.0%\n"
     ]
    }
   ],
   "source": [
    "# Percent YOUTH with Depression\n",
    "percent_youth_depression = round(youthVC[1]/(youthVC[0]+youthVC[1]), 2)*100 # Round to 2 decimal places\n",
    "\n",
    "# Print\n",
    "print(f\"Percent of Adults with Depression: {percent_youth_depression}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test a model on ADULT dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a Gradient Boosting Classifier\n",
    "gbt = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Define X and y\n",
    "X = ADULT.drop('ADSMMDEA', axis=1)\n",
    "y = ADULT['ADSMMDEA']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Apply SMOTE to oversample the minority class\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform both training and testing sets\n",
    "X_train_resampled_scaled = scaler.fit_transform(X_train_resampled) # Here the resampled X_train data is scaled\n",
    "X_test_scaled = scaler.transform(X_test) # Here the original X_test data is scaled as it was not resampled\n",
    "\n",
    "# Note: you do not need to scale the target variable (y).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the oversampled training data\n",
    "gbt.fit(X_train_resampled_scaled, y_train_resampled)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = gbt.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.70      0.77      6423\n",
      "           1       0.35      0.53      0.42      1872\n",
      "\n",
      "    accuracy                           0.67      8295\n",
      "   macro avg       0.59      0.62      0.59      8295\n",
      "weighted avg       0.73      0.67      0.69      8295\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Return a classification report for the model\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>adult_feature_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HEALTH2</td>\n",
       "      <td>0.440975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MRJFLAG</td>\n",
       "      <td>0.145312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PYUD5MRJ</td>\n",
       "      <td>0.090688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CATAG3</td>\n",
       "      <td>0.083567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POVERTY3</td>\n",
       "      <td>0.072345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANYHLTI2</td>\n",
       "      <td>0.064079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MJYRTOT</td>\n",
       "      <td>0.040727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INCOME</td>\n",
       "      <td>0.025015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ALCFLAG</td>\n",
       "      <td>0.021143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TOBFLAG</td>\n",
       "      <td>0.009005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>COCFLAG</td>\n",
       "      <td>0.002758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LSDFLAG</td>\n",
       "      <td>0.002035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>METHAMFLAG</td>\n",
       "      <td>0.001904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HERFLAG</td>\n",
       "      <td>0.000448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CRKFLAG</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature  adult_feature_importance\n",
       "1      HEALTH2                  0.440975\n",
       "6      MRJFLAG                  0.145312\n",
       "7     PYUD5MRJ                  0.090688\n",
       "0       CATAG3                  0.083567\n",
       "4     POVERTY3                  0.072345\n",
       "2     ANYHLTI2                  0.064079\n",
       "8      MJYRTOT                  0.040727\n",
       "3       INCOME                  0.025015\n",
       "9      ALCFLAG                  0.021143\n",
       "5      TOBFLAG                  0.009005\n",
       "10     COCFLAG                  0.002758\n",
       "13     LSDFLAG                  0.002035\n",
       "14  METHAMFLAG                  0.001904\n",
       "12     HERFLAG                  0.000448\n",
       "11     CRKFLAG                  0.000000"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create feature importance dataframe to analyze the importance of each feature\n",
    "fi_values = gbt.feature_importances_\n",
    "features = X_train.columns\n",
    "# Create dataframe\n",
    "adult_feature_importance_df = pd.DataFrame({\"feature\": features, \"adult_feature_importance\": fi_values})\n",
    "# Sort in descending order\n",
    "adult_feature_importance_df = adult_feature_importance_df.sort_values(by=\"adult_feature_importance\", ascending = False)\n",
    "# View dataframe\n",
    "adult_feature_importance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test a model with YOUTH dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.70      0.76      1937\n",
      "           1       0.37      0.56      0.45       624\n",
      "\n",
      "    accuracy                           0.67      2561\n",
      "   macro avg       0.60      0.63      0.60      2561\n",
      "weighted avg       0.72      0.67      0.68      2561\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a Gradient Boosting Classifier\n",
    "gbt = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Define X and y\n",
    "X = YOUTH.drop('YODSMMDE', axis=1)\n",
    "y = YOUTH['YODSMMDE']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Apply SMOTE to oversample the minority class\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform both training and testing sets\n",
    "X_train_resampled_scaled = scaler.fit_transform(X_train_resampled) # Here the resampled X_train data is scaled\n",
    "X_test_scaled = scaler.transform(X_test) # Here the original X_test data is scaled as it was not resampled\n",
    "\n",
    "# Note: you do not need to scale the target variable (y).\n",
    "\n",
    "# Fit the model to the oversampled training data\n",
    "gbt.fit(X_train_resampled_scaled, y_train_resampled)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = gbt.predict(X_test_scaled)\n",
    "\n",
    "# Return a classification report for the model\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>youth_feature_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HEALTH2</td>\n",
       "      <td>0.499813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ALCFLAG</td>\n",
       "      <td>0.244815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MRJFLAG</td>\n",
       "      <td>0.070116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POVERTY3</td>\n",
       "      <td>0.041385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MJYRTOT</td>\n",
       "      <td>0.039888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PYUD5MRJ</td>\n",
       "      <td>0.034001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INCOME</td>\n",
       "      <td>0.026361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANYHLTI2</td>\n",
       "      <td>0.017742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TOBFLAG</td>\n",
       "      <td>0.016949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>COCFLAG</td>\n",
       "      <td>0.004962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>METHAMFLAG</td>\n",
       "      <td>0.001536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HERFLAG</td>\n",
       "      <td>0.001112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LSDFLAG</td>\n",
       "      <td>0.000852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CRKFLAG</td>\n",
       "      <td>0.000470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CATAG3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature  youth_feature_importance\n",
       "1      HEALTH2                  0.499813\n",
       "9      ALCFLAG                  0.244815\n",
       "6      MRJFLAG                  0.070116\n",
       "4     POVERTY3                  0.041385\n",
       "8      MJYRTOT                  0.039888\n",
       "7     PYUD5MRJ                  0.034001\n",
       "3       INCOME                  0.026361\n",
       "2     ANYHLTI2                  0.017742\n",
       "5      TOBFLAG                  0.016949\n",
       "10     COCFLAG                  0.004962\n",
       "14  METHAMFLAG                  0.001536\n",
       "12     HERFLAG                  0.001112\n",
       "13     LSDFLAG                  0.000852\n",
       "11     CRKFLAG                  0.000470\n",
       "0       CATAG3                  0.000000"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create feature importance dataframe to analyze the importance of each feature\n",
    "fi_values = gbt.feature_importances_\n",
    "features = X_train.columns\n",
    "# Create dataframe\n",
    "youth_feature_importance_df = pd.DataFrame({\"feature\": features, \"youth_feature_importance\": fi_values})\n",
    "# Sort in descending order\n",
    "youth_feature_importance_df = youth_feature_importance_df.sort_values(by=\"youth_feature_importance\", ascending = False)\n",
    "# View dataframe\n",
    "youth_feature_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>adult_feature_importance</th>\n",
       "      <th>youth_feature_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HEALTH2</td>\n",
       "      <td>0.440975</td>\n",
       "      <td>0.499813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MRJFLAG</td>\n",
       "      <td>0.145312</td>\n",
       "      <td>0.070116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PYUD5MRJ</td>\n",
       "      <td>0.090688</td>\n",
       "      <td>0.034001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CATAG3</td>\n",
       "      <td>0.083567</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POVERTY3</td>\n",
       "      <td>0.072345</td>\n",
       "      <td>0.041385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ANYHLTI2</td>\n",
       "      <td>0.064079</td>\n",
       "      <td>0.017742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MJYRTOT</td>\n",
       "      <td>0.040727</td>\n",
       "      <td>0.039888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>INCOME</td>\n",
       "      <td>0.025015</td>\n",
       "      <td>0.026361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ALCFLAG</td>\n",
       "      <td>0.021143</td>\n",
       "      <td>0.244815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TOBFLAG</td>\n",
       "      <td>0.009005</td>\n",
       "      <td>0.016949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>COCFLAG</td>\n",
       "      <td>0.002758</td>\n",
       "      <td>0.004962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LSDFLAG</td>\n",
       "      <td>0.002035</td>\n",
       "      <td>0.000852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>METHAMFLAG</td>\n",
       "      <td>0.001904</td>\n",
       "      <td>0.001536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>HERFLAG</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.001112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CRKFLAG</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature  adult_feature_importance  youth_feature_importance\n",
       "0      HEALTH2                  0.440975                  0.499813\n",
       "1      MRJFLAG                  0.145312                  0.070116\n",
       "2     PYUD5MRJ                  0.090688                  0.034001\n",
       "3       CATAG3                  0.083567                  0.000000\n",
       "4     POVERTY3                  0.072345                  0.041385\n",
       "5     ANYHLTI2                  0.064079                  0.017742\n",
       "6      MJYRTOT                  0.040727                  0.039888\n",
       "7       INCOME                  0.025015                  0.026361\n",
       "8      ALCFLAG                  0.021143                  0.244815\n",
       "9      TOBFLAG                  0.009005                  0.016949\n",
       "10     COCFLAG                  0.002758                  0.004962\n",
       "11     LSDFLAG                  0.002035                  0.000852\n",
       "12  METHAMFLAG                  0.001904                  0.001536\n",
       "13     HERFLAG                  0.000448                  0.001112\n",
       "14     CRKFLAG                  0.000000                  0.000470"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the two feature importance dataframes (adult_feature_importance_df and youth_feature_importance_df) on ['feature']\n",
    "\n",
    "FEATURE_IMPORTANCES = pd.merge(adult_feature_importance_df, youth_feature_importance_df, on=['feature'], how='outer')\n",
    "\n",
    "# Inspect\n",
    "FEATURE_IMPORTANCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HEALTH2',\n",
       " 'MRJFLAG',\n",
       " 'PYUD5MRJ',\n",
       " 'CATAG3',\n",
       " 'POVERTY3',\n",
       " 'ANYHLTI2',\n",
       " 'MJYRTOT',\n",
       " 'INCOME',\n",
       " 'ALCFLAG']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pull the top 9 most important features from each model and create new dataframes with them\n",
    "\n",
    "# Select first 9 features from adult_feature_importance_df\n",
    "Top9_adult = adult_feature_importance_df['feature'][:9]\n",
    "\n",
    "# Convert into list\n",
    "Top9_adult = Top9_adult.tolist()\n",
    "\n",
    "# Inspect\n",
    "Top9_adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.69      0.76      6423\n",
      "           1       0.34      0.54      0.42      1872\n",
      "\n",
      "    accuracy                           0.66      8295\n",
      "   macro avg       0.59      0.62      0.59      8295\n",
      "weighted avg       0.73      0.66      0.68      8295\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Retrain and test model using Top9_adult as X\n",
    "\n",
    "# Instantiate a Gradient Boosting Classifier\n",
    "gbt = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Define X and y\n",
    "X = ADULT[['HEALTH2',\n",
    "            'MRJFLAG',\n",
    "            'PYUD5MRJ',\n",
    "            'CATAG3',\n",
    "            'POVERTY3',\n",
    "            'ANYHLTI2',\n",
    "            'MJYRTOT',\n",
    "            'INCOME',\n",
    "            'ALCFLAG']]\n",
    "y = ADULT['ADSMMDEA']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Apply SMOTE to oversample the minority class\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform both training and testing sets\n",
    "X_train_resampled_scaled = scaler.fit_transform(X_train_resampled) # Here the resampled X_train data is scaled\n",
    "X_test_scaled = scaler.transform(X_test) # Here the original X_test data is scaled as it was not resampled\n",
    "\n",
    "# Note: you do not need to scale the target variable (y).  \n",
    "\n",
    "# Fit the model to the oversampled training data\n",
    "gbt.fit(X_train_resampled_scaled, y_train_resampled)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = gbt.predict(X_test_scaled)\n",
    "\n",
    "# Return a classification report for the model\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Taking a break here after making some tangible progress but no model performance improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Ensembled sampling\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from imblearn.ensemble import RUSBoostClassifier\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "from imblearn.ensemble import BalancedBaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = subset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 53896 entries, 0 to 53911\n",
      "Data columns (total 19 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   CATAG3      53896 non-null  int64  \n",
      " 1   HEALTH2     53896 non-null  float64\n",
      " 2   ANYHLTI2    53896 non-null  int64  \n",
      " 3   INCOME      53896 non-null  int64  \n",
      " 4   POVERTY3    53896 non-null  float64\n",
      " 5   TOBFLAG     53896 non-null  int64  \n",
      " 6   MRJFLAG     53896 non-null  int64  \n",
      " 7   PYUD5MRJ    53896 non-null  float64\n",
      " 8   MJYRTOT     53896 non-null  int64  \n",
      " 9   ALCFLAG     53896 non-null  int64  \n",
      " 10  COCFLAG     53896 non-null  int64  \n",
      " 11  CRKFLAG     53896 non-null  int64  \n",
      " 12  HERFLAG     53896 non-null  int64  \n",
      " 13  LSDFLAG     53896 non-null  int64  \n",
      " 14  METHAMFLAG  53896 non-null  int64  \n",
      " 15  ADDPREV     53896 non-null  int64  \n",
      " 16  ADSMMDEA    53896 non-null  int64  \n",
      " 17  YODSMMDE    53896 non-null  int64  \n",
      " 18  DEP         53896 non-null  int64  \n",
      "dtypes: float64(3), int64(16)\n",
      "memory usage: 8.2 MB\n"
     ]
    }
   ],
   "source": [
    "subset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y\n",
    "X = subset.drop('DEP', axis=1)\n",
    "y = subset['DEP']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.000 +/- 0.000\n"
     ]
    }
   ],
   "source": [
    "# Train the balanced random forest model\n",
    "brf = BalancedRandomForestClassifier(random_state=42)\n",
    "brf_model_cv = cross_validate(brf, X_train, y_train, cv = 5, n_jobs = -1, scoring=\"precision\")\n",
    "\n",
    "# Check the model performance\n",
    "print(f\"{brf_model_cv['test_score'].mean():.3f} +/- {brf_model_cv['test_score'].std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\imblearn\\utils\\fixes.py\", line 85, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\imblearn\\ensemble\\_bagging.py\", line 422, in fit\n    return super().fit(X, y)\n           ^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sklearn\\ensemble\\_bagging.py\", line 337, in fit\n    return self._fit(X, y, self.max_samples, sample_weight=sample_weight)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\imblearn\\ensemble\\_bagging.py\", line 437, in _fit\n    return super()._fit(X, y, self.max_samples, sample_weight=None)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sklearn\\ensemble\\_bagging.py\", line 472, in _fit\n    all_results = Parallel(\n                  ^^^^^^^^^\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 63, in __call__\n    return super().__call__(iterable_with_config)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\joblib\\parallel.py\", line 1085, in __call__\n    if self.dispatch_one_batch(iterator):\n       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n    self._dispatch(tasks)\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n    result = ImmediateResult(func)\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 597, in __init__\n    self.results = batch()\n                   ^^^^^^^\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n    return [func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n    return [func(*args, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 123, in __call__\n    return self.function(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sklearn\\ensemble\\_bagging.py\", line 144, in _parallel_build_estimators\n    estimator_fit(X_, y[indices])\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\imblearn\\pipeline.py\", line 293, in fit\n    Xt, yt = self._fit(X, y, **fit_params_steps)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\imblearn\\pipeline.py\", line 250, in _fit\n    X, y, fitted_transformer = fit_resample_one_cached(\n                               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\imblearn\\pipeline.py\", line 422, in _fit_resample_one\n    X_res, y_res = sampler.fit_resample(X, y, **fit_params)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\imblearn\\base.py\", line 208, in fit_resample\n    return super().fit_resample(X, y)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\imblearn\\base.py\", line 112, in fit_resample\n    output = self._fit_resample(X, y)\n             ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py\", line 269, in _fit_resample\n    dist_vec, idx_vec = self.nn_ver3_.kneighbors(\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 824, in kneighbors\n    results = ArgKmin.compute(\n              ^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 277, in compute\n    return ArgKmin64.compute(\n           ^^^^^^^^^^^^^^^^^^\n  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_argkmin.pyx\", line 95, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sklearn\\utils\\fixes.py\", line 139, in threadpool_limits\n    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\threadpoolctl.py\", line 171, in __init__\n    self._original_info = self._set_threadpool_limits()\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\threadpoolctl.py\", line 268, in _set_threadpool_limits\n    modules = _ThreadpoolInfo(prefixes=self._prefixes,\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\threadpoolctl.py\", line 340, in __init__\n    self._load_modules()\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\threadpoolctl.py\", line 373, in _load_modules\n    self._find_modules_with_enum_process_module_ex()\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\threadpoolctl.py\", line 485, in _find_modules_with_enum_process_module_ex\n    self._make_module_from_path(filepath)\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\threadpoolctl.py\", line 515, in _make_module_from_path\n    module = module_class(filepath, prefix, user_api, internal_api)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\threadpoolctl.py\", line 606, in __init__\n    self.version = self.get_version()\n                   ^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\threadpoolctl.py\", line 646, in get_version\n    config = get_config().split()\n             ^^^^^^^^^^^^^^^^^^\nAttributeError: 'NoneType' object has no attribute 'split'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Train the balanced bagging classifier model using near miss under sampling\u001b[39;00m\n\u001b[0;32m      2\u001b[0m bbc_nm \u001b[39m=\u001b[39m BalancedBaggingClassifier(random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m, sampler\u001b[39m=\u001b[39m(NearMiss(version\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)))\n\u001b[1;32m----> 3\u001b[0m bbc_nm_model_cv \u001b[39m=\u001b[39m cross_validate(bbc_nm, X_train, y_train, cv \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m, n_jobs \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, scoring\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrecall\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[39m# Check the model performance\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mbbc_nm_model_cv[\u001b[39m'\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmean()\u001b[39m:\u001b[39;00m\u001b[39m.3f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m +/- \u001b[39m\u001b[39m{\u001b[39;00mbbc_nm_model_cv[\u001b[39m'\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mstd()\u001b[39m:\u001b[39;00m\u001b[39m.3f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:285\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m    266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    268\u001b[0m         clone(estimator),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m cv\u001b[39m.\u001b[39msplit(X, y, groups)\n\u001b[0;32m    283\u001b[0m )\n\u001b[1;32m--> 285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(scoring):\n",
      "File \u001b[1;32mc:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[39mif\u001b[39;00m num_failed_fits \u001b[39m==\u001b[39m num_fits:\n\u001b[0;32m    361\u001b[0m     all_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mAll the \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIt is very likely that your model is misconfigured.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou can try to debug the error by setting error_score=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    369\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     some_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[0;32m    371\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnum_failed_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed out of a total of \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe score on these train-test partitions for these parameters\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\imblearn\\utils\\fixes.py\", line 85, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\imblearn\\ensemble\\_bagging.py\", line 422, in fit\n    return super().fit(X, y)\n           ^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sklearn\\ensemble\\_bagging.py\", line 337, in fit\n    return self._fit(X, y, self.max_samples, sample_weight=sample_weight)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\imblearn\\ensemble\\_bagging.py\", line 437, in _fit\n    return super()._fit(X, y, self.max_samples, sample_weight=None)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sklearn\\ensemble\\_bagging.py\", line 472, in _fit\n    all_results = Parallel(\n                  ^^^^^^^^^\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 63, in __call__\n    return super().__call__(iterable_with_config)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\joblib\\parallel.py\", line 1085, in __call__\n    if self.dispatch_one_batch(iterator):\n       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n    self._dispatch(tasks)\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n    result = ImmediateResult(func)\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 597, in __init__\n    self.results = batch()\n                   ^^^^^^^\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n    return [func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n    return [func(*args, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 123, in __call__\n    return self.function(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sklearn\\ensemble\\_bagging.py\", line 144, in _parallel_build_estimators\n    estimator_fit(X_, y[indices])\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\imblearn\\pipeline.py\", line 293, in fit\n    Xt, yt = self._fit(X, y, **fit_params_steps)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\imblearn\\pipeline.py\", line 250, in _fit\n    X, y, fitted_transformer = fit_resample_one_cached(\n                               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\imblearn\\pipeline.py\", line 422, in _fit_resample_one\n    X_res, y_res = sampler.fit_resample(X, y, **fit_params)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\imblearn\\base.py\", line 208, in fit_resample\n    return super().fit_resample(X, y)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\imblearn\\base.py\", line 112, in fit_resample\n    output = self._fit_resample(X, y)\n             ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py\", line 269, in _fit_resample\n    dist_vec, idx_vec = self.nn_ver3_.kneighbors(\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 824, in kneighbors\n    results = ArgKmin.compute(\n              ^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 277, in compute\n    return ArgKmin64.compute(\n           ^^^^^^^^^^^^^^^^^^\n  File \"sklearn\\metrics\\_pairwise_distances_reduction\\_argkmin.pyx\", line 95, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\sklearn\\utils\\fixes.py\", line 139, in threadpool_limits\n    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\threadpoolctl.py\", line 171, in __init__\n    self._original_info = self._set_threadpool_limits()\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\threadpoolctl.py\", line 268, in _set_threadpool_limits\n    modules = _ThreadpoolInfo(prefixes=self._prefixes,\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\threadpoolctl.py\", line 340, in __init__\n    self._load_modules()\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\threadpoolctl.py\", line 373, in _load_modules\n    self._find_modules_with_enum_process_module_ex()\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\threadpoolctl.py\", line 485, in _find_modules_with_enum_process_module_ex\n    self._make_module_from_path(filepath)\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\threadpoolctl.py\", line 515, in _make_module_from_path\n    module = module_class(filepath, prefix, user_api, internal_api)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\threadpoolctl.py\", line 606, in __init__\n    self.version = self.get_version()\n                   ^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\e.a.wright\\anaconda3\\envs\\datascience\\Lib\\site-packages\\threadpoolctl.py\", line 646, in get_version\n    config = get_config().split()\n             ^^^^^^^^^^^^^^^^^^\nAttributeError: 'NoneType' object has no attribute 'split'\n"
     ]
    }
   ],
   "source": [
    "# Train the balanced bagging classifier model using near miss under sampling\n",
    "bbc_nm = BalancedBaggingClassifier(random_state=42, sampler=(NearMiss(version=3)))\n",
    "bbc_nm_model_cv = cross_validate(bbc_nm, X_train, y_train, cv = 5, n_jobs = -1, scoring=\"recall\")\n",
    "\n",
    "# Check the model performance\n",
    "print(f\"{bbc_nm_model_cv['test_score'].mean():.3f} +/- {bbc_nm_model_cv['test_score'].std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the balanced random forest model\n",
    "brf = BalancedRandomForestClassifier(random_state=42)\n",
    "brf_model = brf.fit(X_train, y_train)\n",
    "brf_prediction = brf_model.predict(X_test)\n",
    "\n",
    "# Check the model performance\n",
    "print(classification_report(y_test, brf_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sweet Sweet Victory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write subset to a csv file\n",
    "df.to_csv('data/model_subset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
